### Linear Mixed Model: Predicting P(Choose Correct) ###
Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
Formula: mean_p_choose_corr ~ InattentionW_bin * OVcate_2 + (1 | sub_id)
   Data: agg_data

REML criterion at convergence: -46.7

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.3726 -0.5110  0.2133  0.5943  2.8411 

Random effects:
 Groups   Name        Variance Std.Dev.
 sub_id   (Intercept) 0.005805 0.07619 
 Residual             0.039627 0.19907 
Number of obs: 310, groups:  sub_id, 21

Fixed effects:
                                  Estimate Std. Error        df t value Pr(>|t|)    
(Intercept)                        0.94552    0.04651 241.05225  20.328  < 2e-16 ***
InattentionW_bin2                 -0.08908    0.06223 275.41753  -1.431 0.153441    
InattentionW_bin3                 -0.18450    0.06143 275.07921  -3.003 0.002917 ** 
InattentionW_bin4                 -0.25623    0.06143 275.07921  -4.171 4.07e-05 ***
InattentionW_bin5                 -0.22209    0.06223 275.41763  -3.569 0.000423 ***
OVcate_2medium                     0.02095    0.06143 275.07921   0.341 0.733292    
OVcate_2high                      -0.06030    0.06143 275.07921  -0.982 0.327178    
InattentionW_bin2:OVcate_2medium   0.07561    0.08802 275.43780   0.859 0.391076    
InattentionW_bin3:OVcate_2medium   0.12985    0.08688 275.07921   1.495 0.136160    
InattentionW_bin4:OVcate_2medium   0.19365    0.08688 275.07921   2.229 0.026627 *  
InattentionW_bin5:OVcate_2medium   0.10518    0.08864 275.61918   1.187 0.236390    
InattentionW_bin2:OVcate_2high     0.12433    0.08745 275.25085   1.422 0.156241    
InattentionW_bin3:OVcate_2high     0.14633    0.08688 275.07921   1.684 0.093261 .  
InattentionW_bin4:OVcate_2high     0.07197    0.08688 275.07921   0.828 0.408150    
InattentionW_bin5:OVcate_2high    -0.07344    0.08745 275.25090  -0.840 0.401769    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

### Pairwise Comparisons (Bonferroni-adjusted) - Inattention Weight Bins Within OV Levels ###
$emmeans
OVcate_2 = low:
 InattentionW_bin emmean     SE  df lower.CL upper.CL
 1                 0.946 0.0465 241    0.854    1.037
 2                 0.856 0.0476 246    0.763    0.950
 3                 0.761 0.0465 241    0.669    0.853
 4                 0.689 0.0465 241    0.598    0.781
 5                 0.723 0.0476 246    0.630    0.817

OVcate_2 = medium:
 InattentionW_bin emmean     SE  df lower.CL upper.CL
 1                 0.966 0.0465 241    0.875    1.058
 2                 0.953 0.0476 246    0.859    1.047
 3                 0.912 0.0465 241    0.820    1.003
 4                 0.904 0.0465 241    0.812    0.996
 5                 0.850 0.0487 251    0.754    0.946

OVcate_2 = high:
 InattentionW_bin emmean     SE  df lower.CL upper.CL
 1                 0.885 0.0465 241    0.794    0.977
 2                 0.920 0.0465 241    0.829    1.012
 3                 0.847 0.0465 241    0.755    0.939
 4                 0.701 0.0465 241    0.609    0.793
 5                 0.590 0.0465 241    0.498    0.681

Degrees-of-freedom method: kenward-roger 
Confidence level used: 0.95 

$contrasts
OVcate_2 = low:
 contrast                              estimate     SE  df t.ratio p.value
 InattentionW_bin1 - InattentionW_bin2  0.08908 0.0622 275   1.431  1.0000
 InattentionW_bin1 - InattentionW_bin3  0.18450 0.0614 275   3.003  0.0292
 InattentionW_bin1 - InattentionW_bin4  0.25623 0.0614 275   4.171  0.0004
 InattentionW_bin1 - InattentionW_bin5  0.22209 0.0622 275   3.568  0.0042
 InattentionW_bin2 - InattentionW_bin3  0.09542 0.0622 275   1.533  1.0000
 InattentionW_bin2 - InattentionW_bin4  0.16715 0.0622 275   2.686  0.0768
 InattentionW_bin2 - InattentionW_bin5  0.13300 0.0630 276   2.110  0.3577
 InattentionW_bin3 - InattentionW_bin4  0.07173 0.0614 275   1.168  1.0000
 InattentionW_bin3 - InattentionW_bin5  0.03759 0.0622 275   0.604  1.0000
 InattentionW_bin4 - InattentionW_bin5 -0.03415 0.0622 275  -0.549  1.0000

OVcate_2 = medium:
 contrast                              estimate     SE  df t.ratio p.value
 InattentionW_bin1 - InattentionW_bin2  0.01348 0.0622 275   0.217  1.0000
 InattentionW_bin1 - InattentionW_bin3  0.05465 0.0614 275   0.890  1.0000
 InattentionW_bin1 - InattentionW_bin4  0.06259 0.0614 275   1.019  1.0000
 InattentionW_bin1 - InattentionW_bin5  0.11690 0.0631 276   1.852  0.6506
 InattentionW_bin2 - InattentionW_bin3  0.04117 0.0622 275   0.662  1.0000
 InattentionW_bin2 - InattentionW_bin4  0.04911 0.0622 275   0.789  1.0000
 InattentionW_bin2 - InattentionW_bin5  0.10343 0.0639 276   1.618  1.0000
 InattentionW_bin3 - InattentionW_bin4  0.00794 0.0614 275   0.129  1.0000
 InattentionW_bin3 - InattentionW_bin5  0.06226 0.0631 276   0.986  1.0000
 InattentionW_bin4 - InattentionW_bin5  0.05432 0.0631 276   0.861  1.0000

OVcate_2 = high:
 contrast                              estimate     SE  df t.ratio p.value
 InattentionW_bin1 - InattentionW_bin2 -0.03524 0.0614 275  -0.574  1.0000
 InattentionW_bin1 - InattentionW_bin3  0.03817 0.0614 275   0.621  1.0000
 InattentionW_bin1 - InattentionW_bin4  0.18426 0.0614 275   2.999  0.0295
 InattentionW_bin1 - InattentionW_bin5  0.29552 0.0614 275   4.810  <.0001
 InattentionW_bin2 - InattentionW_bin3  0.07341 0.0614 275   1.195  1.0000
 InattentionW_bin2 - InattentionW_bin4  0.21950 0.0614 275   3.573  0.0042
 InattentionW_bin2 - InattentionW_bin5  0.33076 0.0614 275   5.384  <.0001
 InattentionW_bin3 - InattentionW_bin4  0.14609 0.0614 275   2.378  0.1809
 InattentionW_bin3 - InattentionW_bin5  0.25735 0.0614 275   4.189  0.0004
 InattentionW_bin4 - InattentionW_bin5  0.11126 0.0614 275   1.811  0.7121

Degrees-of-freedom method: kenward-roger 
P value adjustment: bonferroni method for 10 tests 


### Pairwise Comparisons (Bonferroni-adjusted) - OV Levels Within Each Bin ###
$emmeans
InattentionW_bin = 1:
 OVcate_2 emmean     SE  df lower.CL upper.CL
 low       0.946 0.0465 241    0.854    1.037
 medium    0.966 0.0465 241    0.875    1.058
 high      0.885 0.0465 241    0.794    0.977

InattentionW_bin = 2:
 OVcate_2 emmean     SE  df lower.CL upper.CL
 low       0.856 0.0476 246    0.763    0.950
 medium    0.953 0.0476 246    0.859    1.047
 high      0.920 0.0465 241    0.829    1.012

InattentionW_bin = 3:
 OVcate_2 emmean     SE  df lower.CL upper.CL
 low       0.761 0.0465 241    0.669    0.853
 medium    0.912 0.0465 241    0.820    1.003
 high      0.847 0.0465 241    0.755    0.939

InattentionW_bin = 4:
 OVcate_2 emmean     SE  df lower.CL upper.CL
 low       0.689 0.0465 241    0.598    0.781
 medium    0.904 0.0465 241    0.812    0.996
 high      0.701 0.0465 241    0.609    0.793

InattentionW_bin = 5:
 OVcate_2 emmean     SE  df lower.CL upper.CL
 low       0.723 0.0476 246    0.630    0.817
 medium    0.850 0.0487 251    0.754    0.946
 high      0.590 0.0465 241    0.498    0.681

Degrees-of-freedom method: kenward-roger 
Confidence level used: 0.95 

$contrasts
InattentionW_bin = 1:
 contrast      estimate     SE  df t.ratio p.value
 low - medium   -0.0210 0.0614 275  -0.341  1.0000
 low - high      0.0603 0.0614 275   0.982  0.9815
 medium - high   0.0813 0.0614 275   1.323  0.5611

InattentionW_bin = 2:
 contrast      estimate     SE  df t.ratio p.value
 low - medium   -0.0966 0.0630 276  -1.532  0.3802
 low - high     -0.0640 0.0622 275  -1.029  0.9135
 medium - high   0.0325 0.0622 275   0.523  1.0000

InattentionW_bin = 3:
 contrast      estimate     SE  df t.ratio p.value
 low - medium   -0.1508 0.0614 275  -2.455  0.0441
 low - high     -0.0860 0.0614 275  -1.400  0.4876
 medium - high   0.0648 0.0614 275   1.054  0.8778

InattentionW_bin = 4:
 contrast      estimate     SE  df t.ratio p.value
 low - medium   -0.2146 0.0614 275  -3.493  0.0017
 low - high     -0.0117 0.0614 275  -0.190  1.0000
 medium - high   0.2029 0.0614 275   3.303  0.0032

InattentionW_bin = 5:
 contrast      estimate     SE  df t.ratio p.value
 low - medium   -0.1261 0.0639 276  -1.974  0.1482
 low - high      0.1337 0.0622 275   2.149  0.0976
 medium - high   0.2599 0.0631 276   4.117  0.0002

Degrees-of-freedom method: kenward-roger 
P value adjustment: bonferroni method for 3 tests 


### Model Comparison: Does OV Level Influence InattentionW Weight Effects? ###
Data: agg_data
Models:
lmm_no_OV: mean_p_choose_corr ~ InattentionW_bin + (1 | sub_id)
lmm_model: mean_p_choose_corr ~ InattentionW_bin * OVcate_2 + (1 | sub_id)
          npar    AIC     BIC logLik deviance Chisq Df Pr(>Chisq)    
lmm_no_OV    7 -56.36 -30.204  35.18   -70.36                        
lmm_model   17 -78.22 -14.698  56.11  -112.22 41.86 10  7.942e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

### Linear Mixed Model (Continuous InattentionW Weight) ###
Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
Formula: corr ~ InattentionW_bin * OVcate_2 + (1 | sub_id)
   Data: data

REML criterion at convergence: 2155.7

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-3.04187 -0.02511  0.27316  0.57268  1.84687 

Random effects:
 Groups   Name        Variance Std.Dev.
 sub_id   (Intercept) 0.008277 0.09098 
 Residual             0.122856 0.35051 
Number of obs: 2757, groups:  sub_id, 21

Fixed effects:
                                   Estimate Std. Error         df t value Pr(>|t|)    
(Intercept)                         0.95125    0.02891   72.28902  32.900  < 2e-16 ***
InattentionW_bin2                  -0.09411    0.03309 2733.53357  -2.844  0.00449 ** 
InattentionW_bin3                  -0.19156    0.03187 2725.98763  -6.011 2.09e-09 ***
InattentionW_bin4                  -0.27257    0.03154 2725.97058  -8.643  < 2e-16 ***
InattentionW_bin5                  -0.23803    0.03188 2730.39259  -7.467 1.10e-13 ***
OVcate_2medium                      0.02179    0.03326 2728.13584   0.655  0.51243    
OVcate_2high                       -0.06067    0.03266 2724.88688  -1.858  0.06332 .  
InattentionW_bin2:OVcate_2medium    0.06719    0.05041 2726.26488   1.333  0.18270    
InattentionW_bin3:OVcate_2medium    0.12549    0.05013 2723.49305   2.503  0.01237 *  
InattentionW_bin4:OVcate_2medium    0.19611    0.04976 2723.49636   3.941 8.32e-05 ***
InattentionW_bin5:OVcate_2medium    0.09789    0.05028 2727.16259   1.947  0.05168 .  
InattentionW_bin2:OVcate_2high      0.11868    0.05014 2725.50104   2.367  0.01801 *  
InattentionW_bin3:OVcate_2high      0.13841    0.04921 2723.52100   2.813  0.00495 ** 
InattentionW_bin4:OVcate_2high      0.06995    0.04829 2723.43792   1.449  0.14757    
InattentionW_bin5:OVcate_2high     -0.09171    0.04868 2725.23814  -1.884  0.05968 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
