---
title: "Behavioural Data Analysis"
output: html_notebook
---

```{r}
# this code reads in the Gracia file which has information for every participant
# 1. Accuracy Analysis - Is performance between LE, EE, ES different? Focus is on the ES-EE compa
# 2. Check particular assumptions for one way-repeated measueres ANOVA
# 2. Run the repeated measures ANOVA and post-hoc tests to compare accuracy and RT between the phases of the experiment (LE,ES,EE)
# 3. Do the same for reaction time data
# libraries
library(tidyverse)
library(rstatix)
library(ggpubr)
library(lme4)
library(lmerTest)
library(ggplot2)
library(dplyr)
library(effsize)  # for Cohen's d
install.packages("afex")
library(afex)


file <- "D:/Aberdeen_Uni_June24/cap/THESIS/OV_Analysis/data/data_sets/OVParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"

data <- read.csv(file)

```

```{r}
# libraries

# phases
phases<- c("LE", "ES", "EE")
excluded_subs <- c(6)   # exclusion of participants from behavioral data: Nr.6 stopped experiment at the start, 99 is me; if we exclude participants due to lack of eye-tracking data, it would be 4,5,6,14     1, 4, 5, 6, 14, 99

data_filt <- data %>%
  filter(phase %in% phases & !sub_id %in% excluded_subs)

# get mean accuracy per participant and phase
accuracy_df <- data_filt %>%
  group_by(sub_id, phase) %>%
  summarise(Mean_Accuracy = mean(corr), .groups = "drop")

# remove outliers
outliers <- accuracy_df %>%
  group_by(phase) %>%
  identify_outliers(Mean_Accuracy)
accuracy_df <- accuracy_df %>%
  filter(!(sub_id %in% outliers$sub_id[outliers$is.extreme]))

# normality assumption
shapiro_results_corr <- accuracy_df %>%
  group_by(phase) %>%
  summarise(Shapiro_p = shapiro.test(Mean_Accuracy)$p.value)
```

```{r}
shapiro_results_corr

```

shapiro_results

```{r}
# repeated measures ANOVA
anova_results <- accuracy_df %>%
  anova_test(dv = Mean_Accuracy, wid = sub_id, within = phase)
anova_table <- get_anova_table(anova_results)
anova_table

fig_out <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/Figures/Garcia_EXP_Mean_Acc_LE_ES_EE_NEW.pdf"

# Make sure phase is a factor with ordered levels
accuracy_df <- accuracy_df %>%
  mutate(phase = factor(phase, levels = c("LE", "ES", "EE")))

# Define custom colors for phases
phase_colors <- c("EE" = "steelblue1", "ES" = "darkorchid", "LE" = "rosybrown")

# Add a column for positioning the asterisks (means)
accuracy_summary <- accuracy_df %>%
  group_by(phase) %>%
  summarise(
    mean_accuracy = mean(Mean_Accuracy),
    .groups = 'drop'
  )

# Plot with overlaid asterisks at means
accuracy_plot <- ggplot(accuracy_df, aes(x = phase, y = Mean_Accuracy, fill = phase)) +
  geom_boxplot(width = 0.5) +
  geom_jitter(color = "black", alpha = 0.6, width = 0.2) +
  geom_line(aes(group = sub_id), color = "gray", alpha = 0.5) +
  geom_point(size = 2, color = "black") +  # Points for individual data
  # Add mean asterisks
  geom_text(data = accuracy_summary, aes(x = phase, y = mean_accuracy, label = "*"),
            color = "red", size = 13, fontface = "bold", inherit.aes = FALSE) +
  scale_fill_manual(values = phase_colors) +
  labs(title = "Mean Accuracy Across Phases",
       x = "Phase", 
       y = "Mean Accuracy (%)") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 23, face = "bold"),
    axis.title.x = element_text(size = 17, face = "bold"),
    axis.title.y = element_text(size = 17, face = "bold"),
    axis.text.x = element_text(size = 15, face = "bold", color = "black"),
    axis.text.y = element_text(size = 15, color = "black")
  )

# Save + show
ggsave(filename = fig_out, plot = accuracy_plot, width = 8, height = 6, dpi = 300)
accuracy_plot



anova_results %>% get_anova_table()

anova_afex <- aov_ez(id = "sub_id", dv = "Mean_Accuracy", within = "phase", data = accuracy_df)
summary(anova_afex)

library(dplyr)

# Calculate mean and SEM for each phase
accuracy_summary <- accuracy_df %>%
  group_by(phase) %>%
  summarise(
    mean_accuracy = mean(Mean_Accuracy),
    sd_accuracy = sd(Mean_Accuracy),
    n = n(),
    sem_accuracy = sd_accuracy / sqrt(n)
  )

# Print the summary table
print(accuracy_summary)
```


```{r}
install.packages("Rmisc")
library(Rmisc)

accuracy_summary <- summarySE(data = accuracy_df, measurevar = "Mean_Accuracy", groupvars = "phase")

```


```{r}
accuracy_median_summary <- accuracy_df %>%
  dplyr::group_by(phase) %>%
  dplyr::summarise(
    median_accuracy = median(Mean_Accuracy),
    n = dplyr::n()
  )

print(accuracy_median_summary)

```


```{r}
anova_table
```
```{r}
# Bonferroni post hoc tests
posthoc_results <- accuracy_df %>%
  pairwise_t_test(Mean_Accuracy ~ phase, paired = TRUE, p.adjust.method = "bonferroni", detailed = TRUE)

```

```{r}
posthoc_results
posthoc_results %>% select(group1, group2, p.adj, effsize)

```
```{r}
library(effsize)
library(tidyr)
library(dplyr)

# Reshape to wide format
wide_df <- accuracy_df %>%
  pivot_wider(names_from = phase, values_from = Mean_Accuracy)

# Run paired Cohen's d for each comparison
cohen.d(wide_df$LE, wide_df$ES, paired = TRUE)  # LE vs ES
cohen.d(wide_df$LE, wide_df$EE, paired = TRUE)  # LE vs EE
cohen.d(wide_df$ES, wide_df$EE, paired = TRUE)  # ES vs EE

```


```{r}
# For comparing accuracy just between ES and EE 
es_ee_data <- accuracy_df %>%
  filter(phase %in% c("ES", "EE") & !sub_id %in% excluded_subs)

# Noramlity check
shapiro_es <- shapiro.test(es_ee_data %>% filter(phase == "ES") %>% pull(Mean_Accuracy))
shapiro_ee <- shapiro.test(es_ee_data %>% filter(phase == "EE") %>% pull(Mean_Accuracy))
shapiro_es
shapiro_ee

#  test based on normality assumption
if (shapiro_es$p.value > 0.05 & shapiro_ee$p.value > 0.05) {
  test_result <- es_ee_data %>%
    pairwise_t_test(Mean_Accuracy ~ phase, paired = TRUE, p.adjust.method = "bonferroni")
} else {
  test_result <- es_ee_data %>%
    wilcox_test(Mean_Accuracy ~ phase, paired = TRUE, p.adjust.method = "bonferroni")
}

test_result

```
**Above chance performance?**

```{r}
# Load necessary packages
library(dplyr)
library(tidyr)
library(ggpubr)

file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"

data <- read.csv(file)


# exclude participants and filter phases of interest
phases<- c("LE", "ES", "EE")
excluded_subs <- c(6,99)   # exclusion of participants from behavioral data: Nr.6 stopped experiment at the start, 99 is me; if we exclude participants due to lack of eye-tracking data, it would be 4,5,6,14

data_filt <- data %>%
  filter(phase %in% phases & !sub_id %in% excluded_subs)

# get mean accuracy per participant and phase
accuracy_df <- data_filt %>%
  group_by(sub_id, phase) %>%
  summarise(Mean_Accuracy = mean(corr), .groups = "drop")


# Make sure phase is a factor with all levels
accuracy_df <- accuracy_df %>%
  mutate(phase = factor(phase, levels = c("LE", "ES", "EE")))

# One-sample t-tests for each phase against chance level (0.5)
t_test_results <- accuracy_df %>%
  group_by(phase) %>%
  summarise(
    mean_accuracy = mean(Mean_Accuracy),
    se = sd(Mean_Accuracy) / sqrt(n()),
    t_statistic = t.test(Mean_Accuracy, mu = 0.5)$statistic,
    df = t.test(Mean_Accuracy, mu = 0.5)$parameter,
    p_value = t.test(Mean_Accuracy, mu = 0.5)$p.value
  ) %>%
  mutate(
    significance = case_when(
      p_value < 0.001 ~ "***",
      p_value < 0.01 ~ "**",
      p_value < 0.05 ~ "*",
      TRUE ~ "n.s."
    )
  )

# Print the table
print(t_test_results)

```

**Reaction Time Analysis**

```{r}
# get mean rt per participant and phase
rt_df <- data_filt %>%
  group_by(sub_id, phase) %>%
  summarise(Mean_RT = mean(rtime), .groups = "drop")

# remove extreme outliers
outliers <- rt_df %>%
  group_by(phase) %>%
  identify_outliers(Mean_RT)
rt_df <- rt_df %>%
  filter(!(sub_id %in% outliers$sub_id[outliers$is.extreme]))

# normality assumption?
shapiro_results_rt <- rt_df %>%
  group_by(phase) %>%
  summarise(Shapiro_p = shapiro.test(Mean_RT)$p.value)

shapiro_results_rt


# Summary statistics for each phase
rt_summary <- rt_df %>%
  group_by(phase) %>%
  summarise(
    mean_rt = round(mean(Mean_RT), 3),
    sd_rt = round(sd(Mean_RT), 3),
    n = n(),
    sem_rt = round(sd_rt / sqrt(n), 3),
    .groups = "drop"
  )

print(rt_summary)

```

```{r}
library(afex)

aov_rt <- aov_ez(id = "sub_id", dv = "Mean_RT", within = "phase", data = rt_df)

summary(aov_rt)  # This includes Mauchly's test and corrections

```
```{r}
library(emmeans)

# Get estimated marginal means
emm <- emmeans(aov_rt, ~ phase)

# Pairwise comparisons with Bonferroni correction
pairwise_results <- pairs(emm, adjust = "bonferroni")
print(pairwise_results)

```
```{r}
library(effectsize)
library(purrr)
library(dplyr)

pairwise_results_df <- as.data.frame(pairwise_results)

# Add Cohen's d using t-values and degrees of freedom
pairwise_results_df <- pairwise_results_df %>%
  mutate(
    cohens_d = map2_dbl(t.ratio, df, ~ t_to_d(t = .x, df = .y, paired = TRUE)$Cohens_d)
  )

print(pairwise_results_df)

```
```{r}
rt_df$log_rt <- log(rt_df$Mean_RT)

aov_log_rt <- aov_ez(id = "sub_id", dv = "log_rt", within = "phase", data = rt_df)

summary(aov_log_rt)

# Followed by:
emm <- emmeans(aov_log_rt, ~ phase)
pairs(emm, adjust = "bonferroni")

```
```{r}
library(effectsize)

# Assuming this is your model:
eta_squared(aov_rt, partial = TRUE)   # partial eta squared (most common in APA)

```


```{r}
library(effectsize)
library(purrr)
library(dplyr)

# Define a safer extractor
safe_t_to_d <- possibly(
  function(t, df) {
    d_obj <- t_to_d(t = t, df = df, paired = TRUE)
    as.numeric(d_obj[[1]])  # get the numeric estimate
  },
  otherwise = NA_real_
)

# Now apply it
pairwise_results <- pairwise_results %>%
  mutate(
    cohens_d = map2_dbl(t.ratio, df, safe_t_to_d)
  )

print(pairwise_results)

```
```{r}
pairwise_results %>%
  select(contrast, t.ratio, df)

```



```{r}
# Wilcoxon signed-rank test with Bonferroni correction
wilcoxon_results <- rt_df %>%
  pairwise_wilcox_test(Mean_RT ~ phase, paired = TRUE, p.adjust.method = "bonferroni")

wilcoxon_results

```
```{r}
# Load required libraries
library(lme4)
library(lmerTest)  # for p-values
library(emmeans)   # for post hoc pairwise comparisons

# Step 1: Log-transform reaction times
rt_df$log_rt <- log(rt_df$Mean_RT)

# Step 2: Fit linear mixed-effects model
lme_model <- lmer(log_rt ~ phase + (1 | sub_id), data = rt_df)

# Step 3: Summarize model
summary(lme_model)

# Step 4: Post hoc pairwise comparisons (Tukey)
emmeans(lme_model, pairwise ~ phase, adjust = "bonferroni")

```

```{r}
rt_df <- data_filt %>%
  group_by(sub_id, phase) %>%
  summarise(Mean_RT = mean(rtime), .groups = "drop")


library(ggplot2)
ggplot(rt_df, aes(x = Mean_RT)) + 
  geom_histogram(bins = 20) + 
  facet_wrap(~phase)

# Or use log transform if skewed:
rt_df$logRT <- log(rt_df$Mean_RT)
library(afex)
aov_result <- aov_ez(
  id = "sub_id",
  dv = "Mean_RT",
  within = "phase",
  data = rt_df,
  type = 3
)

library(emmeans)
emm <- emmeans(aov_result, ~ phase)

library(effectsize)
pairs(emm, adjust = "bonferroni")  # or "tukey", "holm", etc.

summary(aov_result)

```

```{r}
library(dplyr)
library(effectsize)

# Get the contrast table
pairwise_results <- pairs(emm, adjust = "bonferroni") %>% 
  as.data.frame()

# Compute Cohen’s d for each contrast
pairwise_results_with_d <- pairwise_results %>%
  mutate(
    cohens_d = t_to_d(t = t.ratio, df = df, paired = TRUE)
  )

pairwise_results_with_d
pairwise_results_with_d <- pairwise_results %>%
  mutate(
    cohens_d = as.numeric(t_to_d(t = t.ratio, df = df, paired = TRUE))
  )


```


```{r}
rt_df <- rt_df %>%
  mutate(phase = factor(phase, levels = c("LE", "ES", "EE")))

phase_colors <- c("EE" = "steelblue1", "ES" = "darkorchid", "LE" = "peru")

rt_summary <- rt_df %>%
  group_by(phase) %>%
  summarise(
    mean_rt = mean(Mean_RT),
    .groups = "drop"
  )


rt_plot <- ggplot(rt_df, aes(x = phase, y = Mean_RT)) +
  geom_boxplot(aes(fill = phase), width = 0.5) +
  geom_jitter(color = "black", alpha = 0.6, width = 0.2) +
  geom_line(aes(group = sub_id), color = "gray", alpha = 0.5) +
  geom_point(size = 2, color = "black") +
  # Overlay asterisk at the mean for each phase
  geom_text(data = rt_summary, aes(x = phase, y = mean_rt, label = "*"),
            color = "red", size = 13, fontface = "bold", inherit.aes = FALSE) +
  scale_fill_manual(values = phase_colors) +
  labs(
    title = "Mean Reaction Time Across Phases",
    x = "Phase", 
    y = "Mean Reaction Time (seconds)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 23, face = "bold"),
    axis.title.x = element_text(size = 17, face = "bold"),
    axis.title.y = element_text(size = 17, face = "bold"),
    axis.text.x = element_text(size = 15, face = "bold", color = "black"),
    axis.text.y = element_text(size = 15, color = "black")
  )


# Save the figure
fig_out <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/Figures/Garcia_EXP_Mean_rt_LE_ES_EE_NEW.pdf"
ggsave(filename = fig_out, plot = rt_plot, width = 8, height = 6, dpi = 300)

# Display the plot
rt_plot


```
```{r}
outliers %>% filter(is.extreme) %>% distinct(sub_id)
# Summary statistics for mean RT per choice type
rtime_summary <- rtime_es %>%
  group_by(choice_type) %>%
  summarise(
    Mean = round(mean(Mean_rtime), 3),
    SD = round(sd(Mean_rtime), 3),
    .groups = "drop"
  )

rtime_summary

```

```{r}
install.packages("effsize")
library(effsize)

```



```{r}
# Filter ES phase
phases<- c("LE", "ES", "EE")
excluded_subs <- c(6,99)   # exclusion of participants from behavioral data: Nr.6 stopped experiment at the start, 99 is me; if we exclude participants due to lack of eye-tracking data, it would be 4,5,6,14     1, 4, 5, 6, 14, 99

data_filt <- data %>%
  filter(phase %in% phases & !sub_id %in% excluded_subs)

es_data <- data_filt %>%
  filter(phase == "ES") %>%
  mutate(choice_type = ifelse(stim_chosen == "E", "E", "S"))  

#mean accuracy per subject and choice
accuracy_es <- es_data %>%
  group_by(sub_id, choice_type) %>%
  summarise(Mean_Accuracy = mean(corr), .groups = "drop")

# Normality check
shapiro_e <- shapiro.test(accuracy_es %>% filter(choice_type == "E") %>% pull(Mean_Accuracy))
shapiro_s <- shapiro.test(accuracy_es %>% filter(choice_type == "S") %>% pull(Mean_Accuracy))

shapiro_e
shapiro_s

# normality assumption hold
if (shapiro_e$p.value > 0.05 & shapiro_s$p.value > 0.05) {
  test_accuracy <- accuracy_es %>%
    pairwise_t_test(Mean_Accuracy ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
} else {
  test_accuracy <- accuracy_es %>%
    wilcox_test(Mean_Accuracy ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
}

test_accuracy

custom_colors <- c("S" = "#C2185B", 
                   "E" = "#0077B6") 

#plot
acc_es_plot <- ggplot(accuracy_es, aes(x = choice_type, y = Mean_Accuracy, fill = choice_type)) +
  geom_boxplot(width = 0.5, alpha = 0.7) +
  geom_jitter(color = "black", alpha = 0.6, width = 0.2) +
  geom_line(aes(group = sub_id), color = "gray", alpha = 0.5) +
  geom_point(aes(color = sub_id), size = 2) +
  scale_fill_manual(values = custom_colors) +
  labs(title = "Accuracy in ES Phase: E vs. S Choices",
       x = "Choice Type", y = "Mean Accuracy") +
  theme_minimal()

fig_out <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/Figures/Garcia_EXP_Mean_Acc_E_S_options.pdf"
ggsave(filename = fig_out, plot = acc_es_plot, width = 8, height = 6, dpi = 300)

acc_es_plot

accuracy_es %>%
  group_by(choice_type) %>%
  summarise(
    mean_acc = mean(Mean_Accuracy),
    sem_acc = sd(Mean_Accuracy) / sqrt(n())
  )

t.test(
  x = accuracy_es %>% filter(choice_type == "E") %>% pull(Mean_Accuracy),
  y = accuracy_es %>% filter(choice_type == "S") %>% pull(Mean_Accuracy),
  paired = TRUE
)

e_values <- accuracy_es %>% filter(choice_type == "E") %>% pull(Mean_Accuracy)
s_values <- accuracy_es %>% filter(choice_type == "S") %>% pull(Mean_Accuracy)


effect_size <- cohen.d(e_values, s_values, paired = TRUE)
print(effect_size)
```
```{r}
custom_colors <- c("S" = "#C2185B", "E" = "#0077B6")

acc_es_plot <- ggplot(accuracy_es, aes(x = choice_type, y = Mean_Accuracy, fill = choice_type)) +
  geom_boxplot(width = 0.5, alpha = 0.7) +
  geom_jitter(color = "black", alpha = 0.6, width = 0.2) +
  geom_line(aes(group = sub_id), color = "black", alpha = 0.3) +  # Just like RT plot
  geom_point(size = 2, color = "black") +  # Remove subject-specific coloring
  scale_fill_manual(values = custom_colors) +
  labs(
    title = "Accuracy in ES Phase: E vs. S Choices",
    x = "Choice Type",
    y = "Mean Accuracy",
    fill = "Choice Type"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.title.x = element_text(size = 18, face = "bold"),
    axis.title.y = element_text(size = 18, face = "bold", color = "black"),
    axis.text.x = element_text(size = 17, face = "bold", color = "black"),
    axis.text.y = element_text(size = 15, color = "black"),
    legend.text = element_text(size = 14),
    legend.title = element_text(size = 14, face = "bold")
  )

# Save the plot
fig_out <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/Figures/Garcia_EXP_Mean_Acc_E_S_options_matched.pdf"
ggsave(filename = fig_out, plot = acc_es_plot, width = 8, height = 6, dpi = 300)

# Display
acc_es_plot

```
```{r}
# Summary statistics for mean accuracy per choice type
accuracy_summary <- accuracy_es %>%
  group_by(choice_type) %>%
  summarise(
    Mean = round(mean(Mean_Accuracy), 3),
    SD = round(sd(Mean_Accuracy), 3),
    .groups = "drop"
  )

accuracy_summary

```


```{r}
# Same filter for ES
es_data <- data_filt %>%
  filter(phase == "ES") %>%
  mutate(choice_type = ifelse(stim_chosen == "E", "E", "S"))

# mean accuracy for each subject and choice
rtime_es <- es_data %>%
  group_by(sub_id, choice_type) %>%
  summarise(Mean_rtime = mean(rtime), .groups = "drop")

# Normality
shapiro_e <- shapiro.test(rtime_es %>% filter(choice_type == "E") %>% pull(Mean_rtime))
shapiro_s <- shapiro.test(rtime_es %>% filter(choice_type == "S") %>% pull(Mean_rtime))
shapiro_e
shapiro_s

if (shapiro_e$p.value > 0.05 & shapiro_s$p.value > 0.05) {
  test_rtime <- rtime_es %>%
    pairwise_t_test(Mean_rtime ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
} else {
  test_rtime <- rtime_es %>%
    wilcox_test(Mean_rtime ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
}

test_rtime
custom_colors <- c("S" = "#C2185B", 
                   "E" = "#0077B6")


rt_es_plot <- ggplot(rtime_es, aes(x = choice_type, y = Mean_rtime, fill = choice_type)) +
  geom_boxplot(width = 0.5, alpha = 0.7) +
  geom_jitter(color = "black", alpha = 0.6, width = 0.2) +
  geom_line(aes(group = sub_id), color = "black", alpha = 0.3) +  # Keep lines but set a fixed black color
  geom_point(size = 2, color = "black") +  # Keep points but ensure they are all black
  scale_fill_manual(values = custom_colors) +
  labs(title = "Reaction Time (RT) in ES Phase: E vs. S Choices",
       x = "Choice Type", y = "Mean RT (seconds)", fill = "Choice Type") + # Ensure legend title is meaningful
  theme_minimal() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),  # Increase title size
    axis.title.x = element_text(size = 18, face = "bold"), # Increase x-axis label size
    axis.title.y = element_text(size = 18, face = "bold", color = "black"), # Increase y-axis label size
    axis.text.x = element_text(size = 17, face = "bold", color = "black"), # Increase x-axis tick labels (E & S)
    axis.text.y = element_text(size = 15, color = "black"), # Increase y-axis tick label size
    legend.text = element_text(size = 14), # Increase legend text size (E and S labels)
    legend.title = element_text(size = 14, face = "bold") # Increase legend title size
  )

# Save the figure
fig_out <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/Figures/Garcia_EXP_Mean_rt_E_S_options_presi.pdf"
ggsave(filename = fig_out, plot = rt_es_plot, width = 8, height = 6, dpi = 300)

rt_es_plot

rtime_es %>%
  group_by(choice_type) %>%
  summarise(
    mean_rt = mean(Mean_rtime),
    sem_rt = sd(Mean_rtime) / sqrt(n())
  )


```

```{r}

# Filter ES phase and define choice type
es_data <- data_filt %>%
  filter(phase == "ES") %>%
  mutate(choice_type = ifelse(stim_chosen == "E", "E", "S"))  

# Mean RT per subject and choice type
rt_es <- es_data %>%
  group_by(sub_id, choice_type) %>%
  summarise(Mean_RT = mean(RT), .groups = "drop")

# Normality check
shapiro_e <- shapiro.test(rt_es %>% filter(choice_type == "E") %>% pull(Mean_RT))
shapiro_s <- shapiro.test(rt_es %>% filter(choice_type == "S") %>% pull(Mean_RT))

shapiro_e
shapiro_s

# Statistical test choice
if (shapiro_e$p.value > 0.05 & shapiro_s$p.value > 0.05) {
  test_rt <- rt_es %>%
    pairwise_t_test(Mean_RT ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
} else {
  test_rt <- rt_es %>%
    wilcox_test(Mean_RT ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
}

test_rt

# Plot with updated styling
rt_es_plot <- ggplot(rt_es, aes(x = choice_type, y = Mean_RT)) +
  geom_boxplot(width = 0.5, fill = "gray", alpha = 0.7) +
  geom_jitter(color = "black", alpha = 0.6, width = 0.2) +
  geom_line(aes(group = sub_id), color = "black", alpha = 0.5) +  # Lines now black
  geom_point(color = "black", size = 2) +  # Points are also black
  labs(title = "Reaction Time (RT) in ES Phase: E vs. S Choices",
       x = "Choice Type", 
       y = "Mean RT (in seconds)") +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14, face = "bold"),  # Enlarged x-axis label
    axis.title.y = element_text(size = 14, face = "bold"),  # Enlarged y-axis label
    axis.text.x = element_text(size = 12, face = "bold"),  # Larger E and S labels
    axis.text.y = element_text(size = 12)
  )

fig_out <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/Figures/Garcia_EXP_Mean_RT_E_S_options.pdf"
ggsave(filename = fig_out, plot = rt_es_plot, width = 8, height = 6, dpi = 300)

rt_es_plot
```


```{r}
```
```{r}
mean_rt_by_choice <- es_data %>%
  group_by(stim_chosen) %>%
  summarise(Mean_RT = mean(rtime, na.rm = TRUE), .groups = "drop")

mean_rt_by_choice

```


```{r}
# Filter ES phase and group by choice type
es_data <- data_filt %>%
  filter(phase == "ES") %>%
  mutate(choice_type = ifelse(stim_chosen == "E", "E", "S"))  # Create a new factor variable

# Compute mean accuracy per subject and choice type
rtime_es <- es_data %>%
  group_by(sub_id, choice_type) %>%
  summarise(Median_rtime = median(rtime), .groups = "drop")

# Normality check for E and S choices separately
shapiro_e <- shapiro.test(rtime_es %>% filter(choice_type == "E") %>% pull(Median_rtime))
shapiro_s <- shapiro.test(rtime_es %>% filter(choice_type == "S") %>% pull(Median_rtime))

shapiro_e
shapiro_s

# Check if normality assumption holds
if (shapiro_e$p.value > 0.05 & shapiro_s$p.value > 0.05) {
  test_rtime <- rtime_es %>%
    pairwise_t_test(Median_rtime ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
} else {
  test_rtime <- rtime_es %>%
    wilcox_test(Median_rtime ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
}

test_rtime

custom_colors <- c("S" = "#C2185B", 
                   "E" = "#0077B6")


rt_es_plot <- ggplot(rtime_es, aes(x = choice_type, y = Median_rtime, fill = choice_type)) +
  geom_boxplot(width = 0.5, alpha = 0.7) +
  geom_jitter(color = "black", alpha = 0.6, width = 0.2) +
  geom_line(aes(group = sub_id), color = "gray", alpha = 0.5) +
  geom_point(aes(color = sub_id), size = 2) +
  scale_fill_manual(values = custom_colors) +
  labs(title = "RT in ES Phase: E vs. S Choices",
       x = "Choice Type", y = "Median RT") +
  theme_minimal()

fig_out <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/Figures/Garcia_EXP_Median_rt_E_S_options.pdf"
ggsave(filename = fig_out, plot = rt_es_plot, width = 8, height = 6, dpi = 300)

rt_es_plot
```
```{r}
median_rt_by_choice <- es_data %>%
  group_by(stim_chosen) %>%
  summarise(Median_RT = median(rtime, na.rm = TRUE), .groups = "drop")

median_rt_by_choice
```

```{r}
# 1. Filter ES phase and define choice types
es_data <- data_filt %>%
  filter(phase == "ES") %>%
  mutate(choice_type = ifelse(stim_chosen == "E", "E", "S"))

# 2. Compute log-transformed mean RT for each participant
rtime_es <- es_data %>%
  group_by(sub_id, choice_type) %>%
  summarise(
    Mean_rtime = mean(rtime),
    Log_rtime = log(mean(rtime)),
    .groups = "drop"
  )

# 3. Normality check on log-transformed data
shapiro_e <- shapiro.test(rtime_es %>% filter(choice_type == "E") %>% pull(Log_rtime))
shapiro_s <- shapiro.test(rtime_es %>% filter(choice_type == "S") %>% pull(Log_rtime))

shapiro_e
shapiro_s

# 4. Choose test based on normality of log-transformed data
if (shapiro_e$p.value > 0.05 & shapiro_s$p.value > 0.05) {
  test_log_rt <- rtime_es %>%
    pairwise_t_test(Log_rtime ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
} else {
  test_log_rt <- rtime_es %>%
    wilcox_test(Log_rtime ~ choice_type, paired = TRUE, p.adjust.method = "bonferroni")
}

test_log_rt

# 5. Plot (log RT)
custom_colors <- c("S" = "#C2185B", "E" = "#0077B6")

rt_es_log_plot <- ggplot(rtime_es, aes(x = choice_type, y = Log_rtime, fill = choice_type)) +
  geom_boxplot(width = 0.5, alpha = 0.7) +
  geom_jitter(color = "black", alpha = 0.6, width = 0.2) +
  geom_line(aes(group = sub_id), color = "black", alpha = 0.3) +
  geom_point(size = 2, color = "black") +
  scale_fill_manual(values = custom_colors) +
  labs(
    title = "Log-Transformed Reaction Time (RT) in ES Phase: E vs. S Choices",
    x = "Choice Type", y = "Log(RT in seconds)", fill = "Choice Type"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.title.x = element_text(size = 18, face = "bold"),
    axis.title.y = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(size = 17, face = "bold", color = "black"),
    axis.text.y = element_text(size = 15, color = "black"),
    legend.text = element_text(size = 14),
    legend.title = element_text(size = 14, face = "bold")
  )

# Save the log RT plot
fig_out_log <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/Figures/Garcia_EXP_LogRT_E_S_options.pdf"
ggsave(filename = fig_out_log, plot = rt_es_log_plot, width = 8, height = 6, dpi = 300)

# Show plot
rt_es_log_plot

# 6. Summary statistics (log RT)
rtime_es %>%
  group_by(choice_type) %>%
  summarise(
    mean_log_rt = mean(Log_rtime),
    sem_log_rt = sd(Log_rtime) / sqrt(n())
  )
test_log_rt <- rtime_es %>%
  pairwise_t_test(
    Log_rtime ~ choice_type,
    paired = TRUE,
    p.adjust.method = "bonferroni",
    detailed = TRUE
  )

library(effectsize)

# Compute Cohen's d for paired samples
cohens_d_result <- t_test(
  data = rtime_es,
  formula = Log_rtime ~ choice_type,
  paired = TRUE,
  detailed = TRUE
) %>%
  cohens_d(Log_rtime ~ choice_type, paired = TRUE)

print(cohens_d_result)


```
```{r}
library(effectsize)

# Make sure you're comparing values from the same subjects
e_vals <- rtime_es %>% filter(choice_type == "E") %>% arrange(sub_id) %>% pull(Log_rtime)
s_vals <- rtime_es %>% filter(choice_type == "S") %>% arrange(sub_id) %>% pull(Log_rtime)

# Compute paired Cohen's d
cohens_d_result <- cohens_d(x = e_vals, y = s_vals, paired = TRUE)

print(cohens_d_result)


```


# Slope Comparisons from Behavioural MATLAB data

```{r}
# Read the data
slope_data <- read.csv("D:/Aberdeen_Uni_June24/cap/THESIS/Basile_Garcia/RetrieveAndCompareAnalysis-cleaning_VW/RetrieveAndCompareAnalysis-cleaning/data/stats/Fig2D_with_SP.csv")

# factor data
slope_data <- slope_data %>%
  mutate(
    subject = as.factor(subject),
    modality = factor(modality, levels = c("ES", "EE", "SP"))  
  )

# identify outliers
slope_data %>%
  group_by(modality) %>%
  identify_outliers(slope)

# normality assumption?
slope_data %>%
  group_by(modality) %>%
  summarise(p_value = shapiro.test(slope)$p.value)

# anova
anova_result <- slope_data %>%
  anova_test(dv = slope, wid = subject, within = modality)

# anova table
anova_table <- get_anova_table(anova_result)
print(anova_table)

# check sphericity
anova_result$`Sphericity Corrections`

posthoc <- slope_data %>%
  pairwise_t_test(
    slope ~ modality,
    paired = TRUE,
    p.adjust.method = "bonferroni"
  )

print(posthoc)

slope_data %>%
  group_by(modality) %>%
  summarise(
    M = round(mean(slope), 2),
    SD = round(sd(slope), 2)
  )

test_log_rt <- rtime_es %>%
  pairwise_t_test(
    Log_rtime ~ choice_type,
    paired = TRUE,
    p.adjust.method = "bonferroni",
    detailed = TRUE
  )
```

```{r}
# Load necessary libraries
library(dplyr)
library(rstatix)
library(effectsize)
library(purrr)

# Load and prep data
data <- read.csv("D:/Aberdeen_Uni_June24/cap/THESIS/Basile_Garcia/RetrieveAndCompareAnalysis-cleaning_VW/RetrieveAndCompareAnalysis-cleaning/data/stats/Fig2C_with_SP.csv") %>%
  mutate(
    subject = as.factor(subject),
    modality = as.factor(modality)
  )

one_sample_tests <- data %>%
  group_by(modality, p_obj) %>%
  summarise(
    t_test = list(t.test(p_est, mu = as.numeric(as.character(unique(p_obj))))),
    d = list(effectsize::cohens_d(p_est, mu = unique(p_obj))),
    sem = sd(p_est) / sqrt(n()),
    .groups = 'drop'
  ) %>%
  mutate(
    t_statistic = map_dbl(t_test, ~ .x$statistic),
    df = map_dbl(t_test, ~ .x$parameter),  # degrees of freedom
    p_value = map_dbl(t_test, ~ .x$p.value),
    mean_estimate = map_dbl(t_test, ~ mean(.x$data)),
    ci_low = map_dbl(t_test, ~ .x$conf.int[1]),
    ci_high = map_dbl(t_test, ~ .x$conf.int[2]),
    cohen_d = map_dbl(d, ~ if ("Cohens_d" %in% names(.x)) .x$Cohens_d else NA_real_),
    magnitude = map_chr(d, ~ if ("magnitude" %in% names(.x)) .x$magnitude else NA_character_)
  ) %>%
  select(
    modality, p_obj, mean_estimate, sem, ci_low, ci_high,
    t_statistic, df, p_value, cohen_d, magnitude
  )


print(one_sample_tests)

one_sample_tests
```
```{r}
# Load packages
library(dplyr)
library(tidyr)
library(rstatix)
library(effectsize)
library(purrr)

# Load and prep data
data <- read.csv("D:/Aberdeen_Uni_June24/cap/THESIS/Basile_Garcia/RetrieveAndCompareAnalysis-cleaning_VW/RetrieveAndCompareAnalysis-cleaning/data/stats/Fig2C_with_SP.csv") %>%
  mutate(
    subject = as.factor(subject),
    modality = as.factor(modality)
  )

# Step 1: Nest data by modality and p_obj
nested_data <- data %>%
  group_by(modality, p_obj) %>%
  nest()

# Step 2: Apply t-test and Cohen's d per group
final_results <- nested_data %>%
  mutate(
    t_result = map2(data, p_obj, ~ t_test(.x, p_est ~ 1, mu = .y, detailed = TRUE)),
    d_result = map2(data, p_obj, ~ cohens_d(x = .x$p_est, mu = .y))
  ) %>%
  unnest(cols = c(t_result, d_result)) %>%
  select(modality, p_obj, n, mean = estimate, statistic, df, p, cohen.d = effsize, magnitude)

# Step 3: View results
print(final_results)


```


```{r}
library(dplyr)
library(rstatix)
library(tidyr)

# Load and prep your data
data <- read.csv("D:/Aberdeen_Uni_June24/cap/THESIS/Basile_Garcia/RetrieveAndCompareAnalysis-cleaning_VW/RetrieveAndCompareAnalysis-cleaning/data/stats/Fig2C_with_SP.csv") %>%
  mutate(
    subject = as.factor(subject),
    modality = as.factor(modality)
  )

# One-sample t-tests
t_test_results <- data %>%
  group_by(modality, p_obj) %>%
  summarise(
    t_result = list(t_test(
      data = cur_data(),
      formula = p_est ~ 1,
      mu = unique(p_obj),
      detailed = TRUE
    )),
    .groups = "drop"
  ) %>%
  unnest(cols = t_result)

# Effect sizes
cohen_d_results <- data %>%
  group_by(modality, p_obj) %>%
  summarise(
    d_result = list(cohens_d(
      data = cur_data(),
      formula = p_est ~ 1,
      mu = unique(p_obj)
    )),
    .groups = "drop"
  ) %>%
  unnest(cols = d_result) %>%
  select(modality, p_obj, cohen.d = effsize, magnitude)

# Mean + SE per group
se_summary <- data %>%
  group_by(modality, p_obj) %>%
  summarise(
    Mean = mean(p_est),
    SE = sd(p_est) / sqrt(n()),
    N = n(),
    .groups = "drop"
  )

# Join all results
final_results <- t_test_results %>%
  left_join(cohen_d_results, by = c("modality", "p_obj")) %>%
  left_join(se_summary, by = c("modality", "p_obj"))

# View APA-ready results
print(final_results)


```


```{r}
## Repeated Measures Anova

normality_tests <- data %>%
  group_by(modality, p_obj) %>%
  summarise(
    shapiro_test = list(shapiro.test(p_est)),
    .groups = 'drop'
  ) %>%
  mutate(
    shapiro_p = map_dbl(shapiro_test, ~ .x$p.value)
  ) %>%
  select(-shapiro_test)

print(normality_tests)


```
```{r}
anova_results <- data %>%
  group_by(p_obj) %>%
  anova_test(
    dv = p_est,
    wid = subject,
    within = modality
  ) %>%
  get_anova_table()

print(anova_results)

```
```{r}
posthoc_results <- data %>%
  group_by(p_obj) %>%
  pairwise_t_test(
    p_est ~ modality,
    paired = TRUE,
    p.adjust.method = "bonferroni"
  )

print(posthoc_results)

```
```{r}
ggplot(data, aes(x = p_obj, y = p_est, color = modality, group = modality)) +
  geom_point(position = position_jitter(width = 0.1), alpha = 0.6) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  labs(
    title = "Subjective Probability Estimates by Modality",
    x = "Objective Probability (%)",
    y = "Subjective Estimate (%)"
  ) +
  theme_minimal(base_size = 14)

```


```{r}
# Load necessary libraries
library(tidyverse)
library(rstatix)
library(ggpubr)
library(lme4)

# Load the data
file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file)

# Filter only the ES phase and exclude participants 6 and 99
data <- data %>%
  filter(phase == "ES" & !sub_id %in% c(6, 99))

# Convert relevant columns to categorical factors
data <- data %>%
  mutate(
    stim_chosen = as.factor(stim_chosen),
    sub_id = as.factor(sub_id),  # Participant ID
    p1 = factor(p1, levels = c(0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8, 0.9)),  # E-image probability (excluding 0.5)
    p2 = factor(p2, levels = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9))  # Pie chart probabilities (9 levels)
  )

# Compute P(choose E) for each (p2, p1) combination
agg_data <- data %>%
  group_by(p2, p1) %>%
  summarise(
    p_choose_E = mean(stim_chosen == "E"),  # Compute probability of choosing E
    n = n(),  # Count trials
    .groups = 'drop'
  ) 

# Compute 95% CI using binomial proportion
agg_data <- agg_data %>%
  mutate(
    se = sqrt((p_choose_E * (1 - p_choose_E)) / n),
    ci_upper = pmin(1, p_choose_E + 1.96 * se),  # Ensure upper bound does not exceed 1
    ci_lower = pmax(0, p_choose_E - 1.96 * se)   # Ensure lower bound is not below 0
  )

# ---- Plot Choice Probabilities ----
ggplot(agg_data, aes(x = p2, y = p_choose_E, color = p1, group = p1)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper, fill = p1), alpha = 0.2) +
  scale_color_viridis_d(name = "E-image Probability (p1)") +
  scale_fill_viridis_d(name = "E-image Probability (p1)") +
  labs(
    title = "Choice Probability of Experiential Option (E) (Excluding P6, P99)",
    x = "Pie Chart Objective Probability (p2)",
    y = "P(Choose E Option)"
  ) +
  theme_minimal(base_size = 14)

# Aggregate data per participant and condition
data_agg <- data %>%
  mutate(stim_chosen_numeric = ifelse(stim_chosen == "E", 1, 0)) %>%
  group_by(sub_id, p1, p2) %>%
  summarise(stim_chosen_numeric = mean(stim_chosen_numeric), .groups = "drop")  # Compute mean choice per condition

# Run repeated-measures ANOVA
anova_results <- anova_test(
  data = data_agg, 
  dv = stim_chosen_numeric, 
  wid = sub_id, 
  within = c(p2, p1)
)

print(anova_results)

data <- data %>%
  mutate(stim_chosen_numeric = ifelse(stim_chosen == "E", 1, 0))

# Run post-hoc Wilcoxon tests within each p2 level
posthoc_results <- data %>%
  group_by(p2) %>%  # Perform separate comparisons within each p2 level
  pairwise_wilcox_test(stim_chosen_numeric ~ p1, paired = TRUE, p.adjust.method = "bonferroni") %>%
  ungroup()  # Remove grouping afterward

print(posthoc_results)

# Show results in a clean format
posthoc_results %>%
  select(p2, group1, group2, p, p.adj, p.adj.signif) %>%
  arrange(p2, p.adj) %>%
  as.data.frame()


# ---- Logistic Regression Model ----
#logit_model <- glmer(stim_chosen ~ p1 * p2 + (1 | sub_id), 
#                     data = data, 
#                     family = binomial)
#
#summary(logit_model)
```

```{r}
# ---- Logistic Regression Model ----
logit_model <- glmer(stim_chosen ~ p1 * p2 + (1 | sub_id), 
                     data = data, 
                     family = binomial)

summary(logit_model)
```


** Mean Accuracy for OVcate_2 **



```{r}
# Load data
file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file)

# Define subjects to exclude
excluded_subs <- c(99, 6)

# Remove empty `OVcate_2` levels and NaNs, filter ES phase, exclude unwanted subjects
es_agg <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs & OVcate_2 != "" & !is.na(OVcate_2)) %>%
  group_by(sub_id, OVcate_2) %>%
  summarise(
    Mean_Accuracy = mean(corr, na.rm = TRUE),
    Mean_RT = mean(rtime, na.rm = TRUE),
    .groups = "drop"
  )


shapiro_results <- es_agg %>%
  group_by(OVcate_2) %>%
  summarise(
    Shapiro_Accuracy = shapiro.test(Mean_Accuracy)$p.value,
    Shapiro_RT = shapiro.test(Mean_RT)$p.value
  )

print(shapiro_results)
kruskal_accuracy <- es_agg %>%
  kruskal_test(Mean_Accuracy ~ OVcate_2)

kruskal_rt <- es_agg %>%
  kruskal_test(Mean_RT ~ OVcate_2)

print(kruskal_accuracy)
print(kruskal_rt)

posthoc_accuracy <- es_agg %>%
  pairwise_wilcox_test(Mean_Accuracy ~ OVcate_2, paired = TRUE, p.adjust.method = "bonferroni")

posthoc_rt <- es_agg %>%
  pairwise_wilcox_test(Mean_RT ~ OVcate_2, paired = TRUE, p.adjust.method = "bonferroni")

print(posthoc_accuracy)
print(posthoc_rt)

```
```{r}


unique(es_agg$OVcate_2)

mean_values <- es_agg %>%
  group_by(OVcate_2) %>%
  summarise(
    Mean_Accuracy = mean(Mean_Accuracy, na.rm = TRUE),
    Mean_RT = mean(Mean_RT, na.rm = TRUE),
    .groups = "drop"
  )

# Display the summary
print(mean_values)

```

########################################################################################





```{r}

#install.packages("effects")

library(Matrix)
library(lmerTest)
library(lme4)       # For linear mixed models
library(lmerTest)   # Provides p-values for lme4 models
library(ggplot2)    # For visualization
library(sjPlot)  
library(carData)                  # For plotting mixed models
library(effects)    # For visualizing model effects

```

```{r}

install.packages("Hmisc")
library("Hmisc")

```

```{r}
# Load dataset

library(tidyverse)
library(rstatix)
library(ggpubr)


file <- "D:/Aberdeen_Uni_June24/cap/THESIS/OV_Analysis/data/data_sets/OVParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file)

# Exclude specific subjects
excluded_subs <- c(6)

# Filter for ES phase and exclude unwanted subjects
es_data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs & OV_num_2 != "" & !is.na(OV_num_2))


model_corr <- lmer(corr ~ OV_num_2 + AbsValueDiff_2 + (1 | sub_id), data = es_data)
summary(model_corr)  # Print model results
model_corr

```
```{r}

library(tidyverse)
library(lme4)
library(broom)

# Define file path
file <- "D:/Aberdeen_Uni_June24/cap/THESIS/OV_Analysis/data/data_sets/OVParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs_CCT.csv"

# Load dataset
data <- read.csv(file)

# Exclude specific subjects
excluded_subs <- c(6)

# Filter data for phase "ES" and remove missing values
es_data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs & !is.na(OV_num_2) & !is.na(AbsValueDiff_2) & !is.na(corr))

# Function to fit per-subject models and extract coefficients
get_subject_estimates <- function(sub_data) {
  model <- lm(corr ~ OV_num_2 + AbsValueDiff_2, data = sub_data)  # Fit per-subject model
  summary_model <- summary(model)
  
  # Extract coefficients, standard errors, t-statistics, and p-values
  coefs <- summary_model$coefficients
  results <- tibble(
    sub_id = unique(sub_data$sub_id),
    predictor = rownames(coefs),
    beta_value = coefs[, "Estimate"],
    standard_error = coefs[, "Std. Error"],
    t_stat = coefs[, "t value"],
    p_value = coefs[, "Pr(>|t|)"],
    lower_CI = beta_value - 1.96 * standard_error,  # Compute confidence intervals
    upper_CI = beta_value + 1.96 * standard_error
  )
  
  return(results)
}

# Apply function to each subject
subject_results <- es_data %>%
  group_split(sub_id) %>%
  map_dfr(get_subject_estimates)  # Combine results into a single dataframe

# Remove intercept rows (optional)
subject_results <- subject_results %>%
  filter(predictor != "(Intercept)")

# Save results to CSV
output_file <- "D:/Aberdeen_Uni_June24/cap/THESIS/OV_Analysis/stats_TingGluth/R_Code_ES_LME_Accuracy_SubjectLevel_Results.csv"
write.csv(subject_results, output_file, row.names = FALSE)

# Print summary table
print(subject_results)

cat("Saved subject-specific LME results to:", output_file)


```

```{r}
model_rtime <- lmer(rtime ~ OV_num_2 + AbsValueDiff_2 + (1 | sub_id), data = es_data)
summary(model_rtime)  # Print model results

```
```{r}
tab_model(model_corr)
#tab_model(model_rtime)

```


```{r}
library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)

# Fit the mixed model
model_corr <- lmer(corr ~ OV_num_2 + AbsValueDiff_2 + (1 | sub_id), data = es_data)

# Extract fixed effects coefficients
betas <- coef(summary(model_corr))  # Extract fixed effects
beta_df <- as.data.frame(betas)

# Add predictor names
beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL

# Rename columns for clarity
colnames(beta_df) <- c("Estimate", "SE", "df", "t", "p", "Predictor")

# Keep only relevant predictors (exclude intercept)
beta_df <- beta_df %>%
  filter(Predictor != "(Intercept)")

# Compute 95% Confidence Intervals
beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,
    CI_Upper = Estimate + 1.96 * SE
  )

# Print results
print(beta_df)


# Extract random slopes for each predictor
random_effects <- coef(model_corr)$sub_id[, c("OV_num_2", "AbsValueDiff_2")]

# Convert to tidy format for ggplot
random_effects_df <- as.data.frame(random_effects) %>%
  rownames_to_column(var = "sub_id") %>%
  pivot_longer(cols = c("OV_num_2", "AbsValueDiff_2"), names_to = "Predictor", values_to = "Beta")

print(random_effects_df)


```

```{r}
ggplot() +
  # Bar plot of fixed effects
  geom_bar(data = beta_df, aes(x = Predictor, y = Estimate, fill = Predictor), 
           stat = "identity", alpha = 0.7, color = "black", width = 0.5) +
  
  # Error bars for 95% CI
  geom_errorbar(data = beta_df, aes(x = Predictor, ymin = CI_Lower, ymax = CI_Upper), 
                width = 0.2, color = "black") +
  
  # Overlay individual participant estimates
  geom_jitter(data = random_effects_df, aes(x = Predictor, y = Beta), 
              width = 0.1, color = "black", size = 3, alpha = 0.8) +
  
  # Customize appearance
  labs(title = "Beta Coefficients for Accuracy Model",
       x = "", y = "Beta Coefficients") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("OV_num_2" = "purple", "AbsValueDiff_2" = "darkorchid"))

```
```{r}
library(ggplot2)
library(dplyr)

# Define file path
file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"

# Load dataset
data <- read.csv(file, na.strings = c("", "NA"))  # Convert "NA" strings to actual NA

# Exclude specific subjects
excluded_subs <- c(99, 6)

# Filter data for phase "ES" and remove missing values
ee_data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs) %>%
  drop_na(OVcate_2, Abscate_2, corr) %>%
  mutate(
    OVcate_2 = factor(OVcate_2, levels = c("low", "medium", "high")),  # Ensure correct order
    Abscate_2 = factor(Abscate_2, levels = c("low", "medium", "high"))
  ) %>%
  droplevels()  # Drop unused factor levels

# Verify there are no NAs left
print("Checking for NAs in the filtered dataset:")
print(colSums(is.na(ee_data)))



# Step 1: Summarize the data with SE
summary_df <- ee_data %>%
  group_by(OVcate_2, Abscate_2) %>%
  summarise(
    mean_accuracy = mean(corr, na.rm = TRUE),
    se_accuracy = sd(corr, na.rm = TRUE) / sqrt(n()), # Standard Error
    .groups = 'drop'
  )
#########################################################################################################################################

# Compute overall mean accuracy and SE per OV category
overall_summary <- ee_data %>%
  group_by(OVcate_2) %>%
  summarise(
    mean_accuracy = mean(corr, na.rm = TRUE),
    se_accuracy = sd(corr, na.rm = TRUE) / sqrt(n()), # Standard Error
    .groups = 'drop'
  )

# Compute overall accuracy and SE across all data
total_summary <- ee_data %>%
  group_by(OVcate_2) %>%
  summarise(
    mean_accuracy = mean(corr, na.rm = TRUE),
    se_accuracy = sd(corr, na.rm = TRUE) / sqrt(n()) # Standard Error
  )

# Print mean accuracy & SE for each OV category and overall accuracy
print("Mean Accuracy and SE for High, Medium, Low OV Categories:")
print(overall_summary)
print("Overall Accuracy and SE Across All Data:")
print(total_summary)


########################################################################################################################################

# Compute overall mean accuracy and SE per VD category
overall_summary_VD <- ee_data %>%
  group_by(Abscate_2) %>%
  summarise(
    mean_accuracy_VD = mean(corr, na.rm = TRUE),
    se_accuracy_VD = sd(corr, na.rm = TRUE) / sqrt(n()), # Standard Error
    .groups = 'drop'
  )

# Compute overall accuracy and SE across all data
total_summary_VD <- ee_data %>%
  group_by(Abscate_2) %>%
  summarise(
    mean_accuracy_VD = mean(corr, na.rm = TRUE),
    se_accuracy_VD = sd(corr, na.rm = TRUE) / sqrt(n()) # Standard Error
  )

# Print mean accuracy & SE for each OV category and overall accuracy
print("Mean Accuracy and SE for High, Medium, Low OV Categories:")
print(overall_summary_VD)
print("Overall Accuracy and SE Across All Data:")
print(total_summary_VD)

########################################################################################################################################




# Step 2: Plot
p <- ggplot(summary_df, aes(x = OVcate_2, y = mean_accuracy, group = Abscate_2, color = Abscate_2)) +
  geom_point(size = 4) +  # Larger mean points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = mean_accuracy - se_accuracy, ymax = mean_accuracy + se_accuracy), 
                width = 0.08, linewidth = 0.8) +  # Tighter error bars
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) + # 50% reference line
  scale_color_manual(values = c("darkorchid1", "darkorchid3", "darkmagenta")) + # Custom colors
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Add axis lines
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = "white") # White background
  ) +
  labs(
    title = "Accuracy by Overall Value and Absolute Value Difference - ES",
    x = "Overall Value (OVcate_2)",
    y = "Accuracy (%)",
    color = "AbsVD Category"
  )

# Step 3: Save as SVG with a white background
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_Accuracy_OV_Abs_dot_plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")

p


################################################


# Step 4: Statistical Comparison of OVcate_2 Levels
# Kruskal-Wallis test for OVcate_2 (since normality is unlikely)
kruskal_accuracy_ov <- ee_data %>%
  kruskal_test(corr ~ OVcate_2)

# Post-hoc Wilcoxon test for OVcate_2
posthoc_accuracy_ov <- ee_data %>%
  pairwise_wilcox_test(corr ~ OVcate_2, paired = FALSE, p.adjust.method = "bonferroni")

# Step 5: Statistical Comparison of Abscate_2 Levels
# Kruskal-Wallis test for Abscate_2
kruskal_accuracy_abs <- ee_data %>%
  kruskal_test(corr ~ Abscate_2)

# Post-hoc Wilcoxon test for Abscate_2
posthoc_accuracy_abs <- ee_data %>%
  pairwise_wilcox_test(corr ~ Abscate_2, paired = FALSE, p.adjust.method = "bonferroni")

# Print Results
print("Kruskal-Wallis Test for OVcate_2:")
print(kruskal_accuracy_ov)

print("Post-hoc Wilcoxon Test for OVcate_2:")
print(posthoc_accuracy_ov)

print("Kruskal-Wallis Test for Abscate_2:")
print(kruskal_accuracy_abs)

print("Post-hoc Wilcoxon Test for Abscate_2:")
print(posthoc_accuracy_abs)

```
```{r}

```


```{r}
library(ggplot2)
library(dplyr)

# Define file path
file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"

# Load dataset
data <- read.csv(file, na.strings = c("", "NA"))  # Convert "NA" strings to actual NA

# Exclude specific subjects
excluded_subs <- c(99, 6)

# Filter data for phase "ES" and remove missing values
ee_data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs) %>%
  drop_na(OVcate_2, Abscate_2, rtime) %>%  # Ensure rtime has no missing values
  mutate(
    OVcate_2 = factor(OVcate_2, levels = c("low", "medium", "high")),  # Ensure correct order
    Abscate_2 = factor(Abscate_2, levels = c("low", "medium", "high"))
  ) %>%
  droplevels()  # Drop unused factor levels

# Verify there are no NAs left
print("Checking for NAs in the filtered dataset:")
print(colSums(is.na(ee_data)))

# Step 1: Summarize the data with SE for Reaction Time (rtime)
summary_df <- ee_data %>%
  group_by(OVcate_2, Abscate_2) %>%
  summarise(
    mean_rtime = mean(rtime, na.rm = TRUE),
    se_rtime = sd(rtime, na.rm = TRUE) / sqrt(n()), # Standard Error
    .groups = 'drop'
  )
#####################################################################################################

# Compute overall mean reaction time and SE per OV category
overall_summary_OV <- ee_data %>%
  group_by(OVcate_2) %>%
  summarise(
    mean_rtime_OV = mean(rtime, na.rm = TRUE),
    se_rtime_OV = sd(rtime, na.rm = TRUE) / sqrt(n()), # Standard Error
    .groups = 'drop'
  )

# Compute overall reaction time and SE across all data
total_summary_OV <- ee_data %>%
  group_by(OVcate_2) %>%
  summarise(
    mean_rtime_OV = mean(rtime, na.rm = TRUE),
    se_rtime_OV = sd(rtime, na.rm = TRUE) / sqrt(n()) # Standard Error
  )

# Print mean reaction time & SE for each OV category and overall reaction time
print("Mean Reaction Time (rtime) and SE for High, Medium, Low OV Categories:")
print(overall_summary_OV)
print("Overall Reaction Time (rtime) and SE Across All Data:")
print(total_summary_OV)

####################################################################################################

# Compute overall mean reaction time and SE per OV category
overall_summary_VD <- ee_data %>%
  group_by(Abscate_2) %>%
  summarise(
    mean_rtime_VD = mean(rtime, na.rm = TRUE),
    se_rtime_VD = sd(rtime, na.rm = TRUE) / sqrt(n()), # Standard Error
    .groups = 'drop'
  )

# Compute overall reaction time and SE across all data
total_summary_VD <- ee_data %>%
  summarise(
    mean_rtime_VD = mean(rtime, na.rm = TRUE),
    se_rtime_VD = sd(rtime, na.rm = TRUE) / sqrt(n()) # Standard Error
  )

# Print mean reaction time & SE for each OV category and overall reaction time
print("Mean Reaction Time (rtime) and SE for High, Medium, Low VD Categories:")
print(overall_summary_VD)
print("Overall Reaction Time (rtime) and SE Across All Data:")
print(total_summary_VD)

#########################################################################################################

# Step 2: Plot Reaction Time
p <- ggplot(summary_df, aes(x = OVcate_2, y = mean_rtime, group = Abscate_2, color = Abscate_2)) +
  geom_point(size = 4) +  # Larger mean points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = mean_rtime - se_rtime, ymax = mean_rtime + se_rtime), 
                width = 0.08, linewidth = 0.8) +  # Tighter error bars
  geom_hline(yintercept = median(summary_df$mean_rtime, na.rm = TRUE), 
             linetype = "dotted", color = "gray50", linewidth = 1) +  # Reference line for median RT
  scale_color_manual(values = c("darkorchid1", "darkorchid3", "darkmagenta")) + # Custom colors
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Add axis lines
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = "white") # White background
  ) +
  labs(
    title = "RT by Overall Value and Absolute Value Difference - ES",
    x = "Overall Value",
    y = "Reaction Time (ms)",
    color = "Absolute Value"
  )

p

# Step 3: Save as SVG with a white background
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_RTime_OV_Abs_dot_plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")


################################################


# Step 4: Statistical Comparison of OVcate_2 Levels
# Kruskal-Wallis test for OVcate_2 (since normality is unlikely)
kruskal_accuracy_ov <- ee_data %>%
  kruskal_test(rtime ~ OVcate_2)

# Post-hoc Wilcoxon test for OVcate_2
posthoc_accuracy_ov <- ee_data %>%
  pairwise_wilcox_test(rtime ~ OVcate_2, paired = FALSE, p.adjust.method = "bonferroni")

# Step 5: Statistical Comparison of Abscate_2 Levels
# Kruskal-Wallis test for Abscate_2
kruskal_accuracy_abs <- ee_data %>%
  kruskal_test(rtime ~ Abscate_2)

# Post-hoc Wilcoxon test for Abscate_2
posthoc_accuracy_abs <- ee_data %>%
  pairwise_wilcox_test(rtime ~ Abscate_2, paired = FALSE, p.adjust.method = "bonferroni")

# Print Results
print("Kruskal-Wallis Test for OVcate_2:")
print(kruskal_accuracy_ov)

print("Post-hoc Wilcoxon Test for OVcate_2:")
print(posthoc_accuracy_ov)

print("Kruskal-Wallis Test for Abscate_2:")
print(kruskal_accuracy_abs)

print("Post-hoc Wilcoxon Test for Abscate_2:")
print(posthoc_accuracy_abs)


```
```{r}
library(ggplot2)
library(dplyr)

# Define file path
file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"

# Load dataset
data <- read.csv(file, na.strings = c("", "NA"))  # Convert "NA" strings to actual NA

# Exclude specific subjects
excluded_subs <- c(99, 6)

# Filter data for phase "ES" and remove missing values
ee_data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs) %>%
  drop_na(OVcate_2, Abscate_2, rtime) %>%  # Ensure rtime has no missing values
  mutate(
    OVcate_2 = factor(OVcate_2, levels = c("low", "medium", "high")),  # Ensure correct order
    Abscate_2 = factor(Abscate_2, levels = c("low", "medium", "high"))
  ) %>%
  droplevels()  # Drop unused factor levels

# Verify there are no NAs left
print("Checking for NAs in the filtered dataset:")
print(colSums(is.na(ee_data)))

# Step 1: Summarize the data with Median & MAD for Reaction Time (rtime)
summary_df <- ee_data %>%
  group_by(OVcate_2, Abscate_2) %>%
  summarise(
    median_rtime = median(rtime, na.rm = TRUE),
    mad_rtime = sd(rtime, na.rm = TRUE), # Median Absolute Deviation (MAD) as error bars
    .groups = 'drop'
  )

############################################################################################################
# Compute overall median reaction time and MAD per OV category
overall_summary_OV <- ee_data %>%
  group_by(OVcate_2) %>%
  summarise(
    median_rtime_OV = median(rtime, na.rm = TRUE),
    mad_rtime_OV = sd(rtime, na.rm = TRUE), # Median Absolute Deviation (MAD)
    .groups = 'drop'
  )

# Compute overall median reaction time and MAD across all data
total_summary_OV <- ee_data %>%
  group_by(OVcate_2) %>%
  summarise(
    median_rtime_OV = median(rtime, na.rm = TRUE),
    mad_rtime_OV = sd(rtime, na.rm = TRUE) # MAD
  )

# Print median reaction time & MAD for each OV category and overall RT
print("Median Reaction Time (rtime) and MAD for High, Medium, Low OV Categories:")
print(overall_summary_OV)
print("Overall Median Reaction Time (rtime) and MAD Across All Data:")
print(total_summary_OV)

############################################################################################################

# Compute overall median reaction time and MAD per OV category
overall_summary_VD <- ee_data %>%
  group_by(Abscate_2) %>%
  summarise(
    median_rtime_VD = median(rtime, na.rm = TRUE),
    mad_rtime_VD = sd(rtime, na.rm = TRUE), # Median Absolute Deviation (MAD)
    .groups = 'drop'
  )

# Compute overall median reaction time and MAD across all data
total_summary_VD <- ee_data %>%
  group_by(Abscate_2) %>%
  summarise(
    median_rtime_VD = median(rtime, na.rm = TRUE),
    mad_rtime_VD = sd(rtime, na.rm = TRUE) # MAD
  )

# Print median reaction time & MAD for each OV category and overall RT
print("Median Reaction Time (rtime) and MAD for High, Medium, Low VD Categories:")
print(overall_summary_VD)
print("Overall Median Reaction Time (rtime) and STD Across All Data:")
print(total_summary_VD)




# Step 2: Plot Median Reaction Time
p <- ggplot(summary_df, aes(x = OVcate_2, y = median_rtime, group = Abscate_2, color = Abscate_2)) +
  geom_point(size = 4) +  # Larger median points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = median_rtime - mad_rtime, ymax = median_rtime + mad_rtime), 
                width = 0.08, linewidth = 0.8) +  # Tighter error bars
  geom_hline(yintercept = median(summary_df$median_rtime, na.rm = TRUE), 
             linetype = "dotted", color = "gray50", linewidth = 1) +  # Reference line for median RT
  scale_color_manual(values = c("darkorchid1", "darkorchid3", "darkmagenta")) + # Custom colors
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Add axis lines
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = "white") # White background
  ) +
  labs(
    title = "Median Reaction Time by Overall Value and Absolute Value Difference",
    x = "Overall Value (OVcate_2)",
    y = "Median Reaction Time (ms)",
    color = "AbsVD Category"
  )

p
 #Step 3: Save as SVG with a white background
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_Median_RTime_OV_Abs_dot_plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")



# Step 4: Statistical Comparison of OVcate_2 Levels
# Kruskal-Wallis test for OVcate_2 (since normality is unlikely)
kruskal_accuracy_ov <- ee_data %>%
  kruskal_test(rtime ~ OVcate_2)

# Post-hoc Wilcoxon test for OVcate_2
posthoc_accuracy_ov <- ee_data %>%
  pairwise_wilcox_test(rtime ~ OVcate_2, paired = FALSE, p.adjust.method = "bonferroni")

# Step 5: Statistical Comparison of Abscate_2 Levels
# Kruskal-Wallis test for Abscate_2
kruskal_accuracy_abs <- ee_data %>%
  kruskal_test(rtime ~ Abscate_2)

# Post-hoc Wilcoxon test for Abscate_2
posthoc_accuracy_abs <- ee_data %>%
  pairwise_wilcox_test(rtime ~ Abscate_2, paired = FALSE, p.adjust.method = "bonferroni")

# Print Results
print("Kruskal-Wallis Test for OVcate_2:")
print(kruskal_accuracy_ov)

print("Post-hoc Wilcoxon Test for OVcate_2:")
print(posthoc_accuracy_ov)

print("Kruskal-Wallis Test for Abscate_2:")
print(kruskal_accuracy_abs)

print("Post-hoc Wilcoxon Test for Abscate_2:")
print(posthoc_accuracy_abs)


```


```{r}

# Fit the mixed model
# Load necessary libraries
library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)
library(sjPlot)

# Define file path
file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"

# Load dataset
data <- read.csv(file)

# Exclude specific subjects
excluded_subs <- c(99, 6)

# Filter data for phase "ES" and remove missing values
ee_data <- data %>%
  filter(phase == "EE" & !sub_id %in% excluded_subs & !is.na(OV_num_2) & !is.na(AbsValueDiff_2) & !is.na(corr) & !is.na(AttentionW) & !is.na(InattentionW))

# Z-score per subject
ee_data <- ee_data %>%
  group_by(sub_id) %>%
  mutate(
    AbsValueDiff_2 = scale(AbsValueDiff_2, center = TRUE, scale = TRUE)[,1],  
    OV_num_2 = scale(OV_num_2, center = TRUE, scale = TRUE)[,1],
    AttentionW = scale(AttentionW, center = TRUE, scale = TRUE)[,1],   
    InattentionW = scale(InattentionW, center = TRUE, scale = TRUE)[,1]   
  ) %>%
  ungroup()

# Fit the Logistic Mixed Model (Binary Outcome)
model_corr <- glmer(corr ~ AttentionW + OV_num_2:InattentionW + (1 | sub_id), 
                    data = ee_data, family = binomial(link = "logit"))

#Save model summary & tab_model() output
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

stats_file <- paste0(output_dir, "EE_OV_Att_Inatt_Accuracy.txt")

sink(stats_file)
cat("### Logistic Mixed Model for Accuracy (EE Phase) ###\n\n")
cat("#### Model Summary ####\n")
print(summary(model_corr))
cat("\n#### Tabulated Model Output ####\n")
print(tab_model(model_corr, transform = NULL))  # Keeps betas, not log-odds
sink()

#Extract Fixed Effects for Plot
beta_df <- as.data.frame(coef(summary(model_corr)))

# Add predictor names
beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL

# Rename columns correctly
colnames(beta_df) <- c("Estimate", "SE", "z", "p", "Predictor")

# Compute 95% Confidence Intervals
beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,  
    CI_Upper = Estimate + 1.96 * SE   
  ) %>%
  filter(Predictor != "(Intercept)")  

# extract random slopes for visualization
#random_effects <- coef(model_corr)$sub_id[, c("OV_num_2")]

# Convert to tidy format for ggplot
#random_effects_df <- as.data.frame(random_effects) %>%
#  rownames_to_column(var = "sub_id") %>%
#  pivot_longer(cols = c("OV_num_2", "AttentionW", "InattentionW"), names_to = #"Predictor", values_to = "Beta")

# Define significance labels based on p-values
beta_df <- beta_df %>%
  mutate(
    Significance = case_when(
      p < 0.001 ~ "***",
      p < 0.01 ~ "**",
      p < 0.05 ~ "*",
      TRUE ~ "n.s."
    )
  )

# Define output file path for plot
output_path <- paste0(output_dir, "EE_OV_Att_Inatt_Accuracy.svg")

# Reorder factor levels to show OV first, then VD
beta_df$Predictor <- factor(beta_df$Predictor, levels = c("OV_num_2", "AttentionW", "InattentionW"))
random_effects_df$Predictor <- factor(random_effects_df$Predictor, levels = c("OV_num_2", "AttentionW", "InattentionW"))

# ✅ Create Beta Coefficient Plot (without significance labels)
plot_figure <- ggplot() +
  geom_bar(data = beta_df, aes(x = Predictor, y = Estimate, fill = Predictor), 
           stat = "identity", alpha = 0.7, color = "black", width = 0.5, linewidth = 1) +
  geom_errorbar(data = beta_df, aes(x = Predictor, ymin = CI_Lower, ymax = CI_Upper), 
                width = 0.05, color = "black", linewidth = 1) +
  geom_jitter(data = random_effects_df, aes(x = Predictor, y = Beta), 
              width = 0.1, fill = "white", color = "black", shape = 21, size = 4.5, alpha = 0.8, stroke = 1) +
  geom_hline(yintercept = 0, color = "black", linewidth = 1) +
  labs(title = "Beta Coefficients for AttentionW and OV:InattentionW on Accuracy - EE Phase",
       x = "", y = "Beta Coefficients") +
  scale_x_discrete(labels = c("OV_num_2" = "OV", "AttentionW" = "AttentionW", "InattationW" = "InattentionW")) +
  theme_minimal() +
  theme(
    legend.position = "none", 
    panel.grid = element_blank(),  
    axis.line.y = element_line(color = "black", linewidth = 1),  
    axis.line.x = element_blank(),  
    axis.text = element_text(size = 14, color = "black"),  
    axis.title.y = element_text(size = 16, color = "black"),  
    plot.title = element_text(size = 18, hjust = 0.5, color = "black"),  
    panel.background = element_rect(fill = "white", color = "white"),  
    plot.background = element_rect(fill = "white", color = "white")  
  ) +
  scale_fill_manual(values = c("OV_num_2" = "deepskyblue", "AttentionW" = "deepskyblue", "InattentionW" = "deepskyblue"))

# ✅ Save plot
ggsave(output_path, plot = plot_figure, device = "svg", width = 8, height = 6, dpi = 300)

cat("Saved logistic regression plot at:", output_path, "\n")

# ✅ Show final summary & tabulated model
summary(model_corr)
tab_model(model_corr, transform = NULL)


```

```{r}
plot_figure
```





```{r}
# Load necessary libraries
# Load necessary libraries
library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)

# Exclude specific subjects
excluded_subs <- c(99, 6)

# Filter data for phase "ES" and remove missing values
ee_data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs & !is.na(OV_num_2) & !is.na(AbsValueDiff_2) & !is.na(rtime))

ee_data <- ee_data %>%
  group_by(sub_id) %>%
  mutate(
    AbsValueDiff_2 = scale(AbsValueDiff_2, center = TRUE, scale = TRUE)[,1],  # Z-score per subject
    OV_num_2 = scale(OV_num_2, center = TRUE, scale = TRUE)[,1]   # Z-score per subject
  ) %>%
  ungroup()


# Fit the mixed model for RTIME
model_rtime <- lmer(rtime ~ OV_num_2 + AbsValueDiff_2 + (1 | sub_id), data = ee_data)

# Extract fixed effects coefficients
betas <- coef(summary(model_rtime))  # Extract fixed effects
beta_df <- as.data.frame(betas)

# Add predictor names
beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL

# Rename columns for clarity
colnames(beta_df) <- c("Estimate", "SE", "df", "t", "p", "Predictor")

# Keep only relevant predictors (exclude intercept)
beta_df <- beta_df %>%
  filter(Predictor != "(Intercept)")

# Compute 95% Confidence Intervals
beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,
    CI_Upper = Estimate + 1.96 * SE
  )

# Extract random slopes for each predictor
random_effects <- coef(model_rtime)$sub_id[, c("OV_num_2", "AbsValueDiff_2")]

# Convert to tidy format for ggplot
random_effects_df <- as.data.frame(random_effects) %>%
  rownames_to_column(var = "sub_id") %>%
  pivot_longer(cols = c("OV_num_2", "AbsValueDiff_2"), names_to = "Predictor", values_to = "Beta")

# Define significance labels based on p-values
beta_df <- beta_df %>%
  mutate(
    Significance = case_when(
      p < 0.001 ~ "***",
      p < 0.01 ~ "**",
      p < 0.05 ~ "*",
      TRUE ~ "n.s."
    )
  )

# Reorder factor levels so OV is on the left, VD on the right
beta_df$Predictor <- factor(beta_df$Predictor, levels = c("OV_num_2", "AbsValueDiff_2"))
random_effects_df$Predictor <- factor(random_effects_df$Predictor, levels = c("OV_num_2", "AbsValueDiff_2"))

# Define output file path for RTIME model
output_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_RTime_Model_Plot.svg"

# ✅ Store the plot in a variable
plot_rtime <- ggplot() +
  # Bar plot of fixed effects with **thicker black borders**
  geom_bar(data = beta_df, aes(x = Predictor, y = Estimate, fill = Predictor), 
           stat = "identity", alpha = 0.7, color = "black", width = 0.5, linewidth = 1) +
  
  # Error bars for 95% CI with **tighter width**
  geom_errorbar(data = beta_df, aes(x = Predictor, ymin = CI_Lower, ymax = CI_Upper), 
                width = 0.05, color = "black", linewidth = 1) +
  
  # Overlay individual participant estimates **(White dots with black outline)**
  geom_jitter(data = random_effects_df, aes(x = Predictor, y = Beta), 
              width = 0.1, fill = "white", color = "black", shape = 21, size = 4.5, alpha = 0.8, stroke = 1) +
  
  # ✅ Move significance labels BELOW the lower CI
 # geom_text(data = beta_df, aes(x = Predictor, y = CI_Lower - 0.07, label = #Significance),
 #           color = "black", size = 9, fontface = "bold") +  # Increased size from 7 to 9
  
  # Add strong black horizontal line at y = 0 (ONLY this horizontal line)
  geom_hline(yintercept = 0, color = "black", linewidth = 1) +

  # Customize appearance
  labs(title = "Beta Coefficients for OV and VD on RT - ES Phase",
       x = "", y = "Beta Coefficients") +
  
  # Rename x-axis labels
  scale_x_discrete(labels = c("OV_num_2" = "OV", "AbsValueDiff_2" = "VD")) +
  
  # Theme modifications
  theme_minimal() +
  theme(
    legend.position = "none", 
    panel.grid = element_blank(),  # Remove grid
    axis.line.y = element_line(color = "black", linewidth = 1),  # Keep strong black y-axis
    axis.line.x = element_blank(),  # REMOVE the black x-axis line
    axis.text = element_text(size = 14, color = "black"),  # Black axis labels
    axis.title.y = element_text(size = 16, color = "black"),  # Black y-axis title
    plot.title = element_text(size = 18, hjust = 0.5, color = "black"),  # Centered & black title
    panel.background = element_rect(fill = "white", color = "white"),  # White background
    plot.background = element_rect(fill = "white", color = "white")  # White background
  ) +

  scale_fill_manual(values = c("OV_num_2" = "darkorchid", "AbsValueDiff_2" = "darkorchid"))   #mediumaquamarine

# ✅ Now call ggsave() with the stored plot
ggsave(output_path, plot = plot_rtime, device = "svg", width = 8, height = 6, dpi = 300)

cat("Saved RTIME plot as SVG at:", output_path)

summary(model_rtime)
tab_model(model_rtime)


# ✅ Save model summary and tab_model output to text file
rtime_stats_file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_RTime_Model_Summary.txt"

sink(rtime_stats_file)
cat("### Linear Mixed Model for Reaction Times (ES Phase) ###\n\n")
cat("#### Model Summary ####\n")
print(summary(model_rtime))
cat("\n#### Tabulated Model Output ####\n")
print(tab_model(model_rtime))
sink()


```
```{r}
plot_rtime
```

#####################################################################################################################

**Eye-tracking**

```{r}
# Load necessary libraries
library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)
library(sjPlot)

# Load dataset

file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file)

# Define dependent and predictor variables
dep_var <- "chose_right"  # Binary outcome (0/1)

eye_metrics <- c("GazeDiff", "FinalFixLoc", "FirstFixLoc", "FirstFixDur", "FinalFixDur", 
                 "MiddleFixDur", "eachMiddleFixDur", "GazeSwitch", "DwellTimeAdvantage", 
                 "LeftFixNR", "RightFixNR", "PropDwell_opt", "PropDwell_sub", "AttentionW", 
                 "InattentionW", "FixLocFirstCorr", "FixLocLastCorr", "DwellTimeAdvantage", 
                 "FixationAdvantage", "DwelltimeAdvantageCorrect","DwellPropAdvantageCorrect")

# Exclude specific subjects
excluded_subs <- c(1, 4, 5, 6, 14, 99)

# Filter dataset
data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs)

# Rename columns for consistency
data <- data %>%
  rename(OV = OV_2, VD = AbsValueDiff_2)

# ✅ Step 1: Z-score VD & Eye Metrics at the OV Level
data <- data %>%
  group_by(OV) %>%
  mutate(
    VD = scale(VD, center = TRUE, scale = TRUE)[,1],  # Z-score VD within OV
    across(all_of(eye_metrics), ~ scale(.x, center = TRUE, scale = TRUE)[,1]) # Z-score eye metrics within OV
  ) %>%
  ungroup()

# ✅ Step 2: Z-score VD & Eye Metrics within Each Individual (sub_id Level)
data <- data %>%
  group_by(sub_id) %>%
  mutate(
    VD = scale(VD, center = TRUE, scale = TRUE)[,1],  # Z-score VD again within sub_id
    across(all_of(eye_metrics), ~ scale(.x, center = TRUE, scale = TRUE)[,1]) # Z-score eye metrics within sub_id
  ) %>%
  ungroup()

# ✅ Logistic Regression with Beta Coefficients
# Output directory for saving results
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

# Loop through each eye-tracking metric
for (eye_metric in eye_metrics) {
  
  # Define interaction term name
  interaction_term <- paste0("OV:", eye_metric)

  # Define logistic regression formula
  model_formula <- as.formula(paste(dep_var, "~ OV *", eye_metric, "+ (1 + OV| sub_id)"))


  # Fit logistic mixed model (Multiple Logistic Regression)
  model <- glmer(model_formula, data = data, family = binomial(link = "logit"))

  # ✅ Define output file path for saving model results
  stats_file <- paste0(output_dir, "ES_Logistic_Model_", dep_var, "_", eye_metric, ".txt")

  # ✅ Save both `summary(model)` and `tab_model(model, transform = NULL)` in the same file
  sink(stats_file)
  cat("### Logistic Mixed Model (Betas, NOT Odds Ratios) - ES Phase ###\n\n")
  
  cat("#### Model Summary ####\n")
  print(summary(model))  # 🚀 This contains the beta coefficients

  cat("\n#### Tabulated Model Output ####\n")
  print(tab_model(model, transform = NULL))  # 🚀 Keeps raw betas, not odds ratios
  
  sink()  # ✅ Stops writing to file

  html_file <- paste0(output_dir, "ES_Logistic_TabModel_", dep_var, "_", eye_metric, ".html")
  html_content <- capture.output(tab_model(model, transform = NULL))
  writeLines(html_content, con = html_file)
  
  if (file.exists(html_file)) {
    cat("✅ HTML successfully saved at:", html_file, "\n")
  } else {
    cat("❌ HTML was NOT saved! Check your path:", html_file, "\n")
  }

  # ✅ Extract fixed effects properly
  beta_df <- as.data.frame(coef(summary(model)))

  # Add predictor names
  beta_df$Predictor <- rownames(beta_df)
  rownames(beta_df) <- NULL

  # ✅ Rename columns correctly
  colnames(beta_df) <- c("Estimate", "SE", "z", "p", "Predictor")

  # ✅ Compute 95% Confidence Intervals
  beta_df <- beta_df %>%
    mutate(
      CI_Lower = Estimate - 1.96 * SE,  # 95% CI Lower
      CI_Upper = Estimate + 1.96 * SE   # 95% CI Upper
    ) %>%
    filter(Predictor != "(Intercept)")  # Exclude intercept

  # ✅ Modify significance display (ONLY stars, NO numbers)
  beta_df <- beta_df %>%
    mutate(
      Significance = case_when(
        p < 0.001 ~ "***",
        p < 0.01 ~ "**",
        p < 0.05 ~ "*",
        TRUE ~ ""  # 🚀 If not significant, leave it blank (no text)
      )
    )

  # ✅ Ensure correct order: Veye-metric → OV:eye-metric
  # 1) Keep only the eye_metric and OV:eye_metric rows
  beta_df <- beta_df %>%
  filter(Predictor %in% c(eye_metric, interaction_term))

  # 2) Re-factor these two so that the eye_metric bar is always first
  beta_df$Predictor <- factor(beta_df$Predictor, levels = c(eye_metric, interaction_term))
  

  # ✅ Define output file path for plot
  output_path <- paste0(output_dir, "ES_Logistic_Plot_", dep_var, "_", eye_metric, ".svg")

  # ✅ Create plot with proper order
  plot_figure <- ggplot(beta_df, aes(x = Predictor, y = Estimate, fill = Predictor)) +
    geom_bar(stat = "identity", alpha = 0.7, color = "black", width = 0.5, linewidth = 1) +
    geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.05, color = "black", linewidth = 1) +

    # ✅ Add ONLY stars (no numbers)
    geom_text(aes(y = ifelse(Estimate < 0, CI_Lower - 0.09, CI_Upper + 0.09), 
                  label = Significance),
              color = "black", size = 10, fontface = "bold") +  

    geom_hline(yintercept = 0, color = "black", linewidth = 1) +

    labs(title = paste("Beta Coefficients for OV &", eye_metric, "on symbolic choice"),
         x = "", y = "Beta Coefficients") +
    
    scale_fill_manual(values = setNames(rep("darkorchid", 4), c("VD", "OV", eye_metric, interaction_term))) +    

    theme_minimal() +
    theme(
      legend.position = "none", 
      panel.grid = element_blank(), 
      axis.line.y = element_line(color = "black", linewidth = 1),  
      axis.line.x = element_blank(),  
      axis.text = element_text(size = 22, color = "black"), 
      axis.title = element_text(size = 20, color = "black"),  
      plot.title = element_text(size = 18, hjust = 0.5, color = "black"), 
      panel.background = element_rect(fill = "white", color = "white"),  
      plot.background = element_rect(fill = "white", color = "white") 
    )

  # ✅ Save plot
  ggsave(output_path, plot = plot_figure, device = "svg", width = 8, height = 6, dpi = 300)
  
  cat("Saved logistic regression plot for", eye_metric, "as SVG at:", output_path, "\n")
}

# ✅ Show final summary of last model
summary(model)
tab_model(model, transform = NULL)  # 🚀 Keeps betas, not log odds
  



```
```{r}
tab_model(model, transform = NULL)  # 🚀 Keeps betas, not log odds

```


## Regression plots only for OV:AttentionW and OV:InattentionW on accuracy ##

```{r}
# -----------------------------------------------------------------------------
# R regression that plots only OV:Inattention and AttentionW on correct choice
# with significance stars instead of numeric p-values
# -----------------------------------------------------------------------------

library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)
library(sjPlot)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Exclude specific subjects
excluded_subs <- c(1, 4, 5, 6, 14, 99)

# Filter dataset: Only EE phase and excluding specific subjects
data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs)

# Rename columns for consistency
data <- data %>%
  rename(OV = OV_2)

# Z-score OV & Attention Measures at Subject Level
data <- data %>%
  group_by(sub_id) %>%
  mutate(
    OV           = scale(OV,           center = TRUE, scale = TRUE)[,1],  
    AttentionW   = scale(AttentionW,   center = TRUE, scale = TRUE)[,1],  
    InattentionW = scale(InattentionW, center = TRUE, scale = TRUE)[,1]  
  ) %>%
  ungroup()

# Define logistic regression formula
model_formula <- as.formula("corr ~ InattentionW + OV:AttentionW + (1 | sub_id)")

# Fit logistic mixed model
model <- glmer(model_formula, data = data, family = binomial(link = "logit"))

# -----------------------------------------------------------------------------
# Extract fixed effects from model, compute CIs, significance stars
# -----------------------------------------------------------------------------
beta_df <- as.data.frame(coef(summary(model)))

# Add predictor names
beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL

# Rename columns
colnames(beta_df) <- c("Estimate", "SE", "z", "p", "Predictor")

# Compute 95% Confidence Intervals & filter to your 2 predictors
beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,  
    CI_Upper = Estimate + 1.96 * SE  
  ) %>%
  filter(Predictor %in% c("InattentionW", "OV:AttentionW"))

# Order predictors in desired order
beta_df$Predictor <- factor(beta_df$Predictor, 
                            levels = c("InattentionW", "OV:AttentionW"))

# Create column for significance stars
beta_df <- beta_df %>%
  mutate(
    Significance = case_when(
      p < 0.001 ~ "***",
      p < 0.01  ~ "**",
      p < 0.05  ~ "*",
      TRUE      ~ ""   # no stars if p >= .05
    )
  )

# -----------------------------------------------------------------------------
# Save model summary to text file
# -----------------------------------------------------------------------------
plot_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_OV_Attention_Inattention.svg"
summary_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_OV_Attention_Inattention_Summary.txt"

sink(summary_path)
cat("### Logistic Mixed Model Summary - ES Phase ###\n\n")
print(summary(model))
sink()

# -----------------------------------------------------------------------------
# Plot with significance stars
# -----------------------------------------------------------------------------
plot_figure <- ggplot(beta_df, aes(x = Predictor, y = Estimate, fill = Predictor)) +
  geom_bar(
    stat     = "identity", 
    alpha    = 0.7, 
    color    = "black", 
    width    = 0.5, 
    linewidth = 1
  ) +
  geom_errorbar(
    aes(ymin = CI_Lower, ymax = CI_Upper), 
    width    = 0.1, 
    color    = "black", 
    linewidth= 1
  ) +
  
  # Place significance stars above/below the bar
  geom_text(
    aes(
      y = ifelse(Estimate < 0, CI_Lower - 0.05, CI_Upper + 0.05),
      label = Significance
    ),
    color     = "black",
    size      = 8,
    fontface  = "bold"
  ) +
  
  geom_hline(yintercept = 0, color = "black", linewidth = 1) +
  
  labs(
    title = "InattentionW and OV:AttentionW on Accuracy",
    y     = "Beta Coefficients",
    x     = NULL
  ) +  
  
  scale_fill_manual(values = c("darkorchid", "darkorchid")) +
  
  theme_minimal() +
  theme(
    legend.position  = "none", 
    panel.grid       = element_blank(),
    axis.line.y      = element_line(color = "black", linewidth = 1),
    axis.line.x      = element_blank(),
    axis.text        = element_text(size = 20, color = "black"),
    axis.text.x      = element_text(size = 20, color = "black"),
    axis.title.y     = element_text(size = 20, color = "black"),
    plot.title       = element_text(size = 20, hjust = 0.5, color = "black", face = "bold"),
    panel.background = element_rect(fill = "white", color = "white"),
    plot.background  = element_rect(fill = "white", color = "white")
  )

# Save the plot
ggsave(plot_path, plot = plot_figure, device = "svg", width = 8, height = 6, dpi = 300)

# Print model summary for reference
print(summary(model))

plot_figure

```
```{r}
# -----------------------------------------------------------------------------
# R regression that plots only OV:Inattention and AttentionW on reaction time
# with significance stars instead of numeric p-values
# -----------------------------------------------------------------------------

library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)
library(sjPlot)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Exclude specific subjects
excluded_subs <- c(1, 4, 5, 6, 14, 99)

# Filter dataset: Only EE phase and excluding specific subjects
data <- data %>%
  filter(phase == "EE" & !sub_id %in% excluded_subs)

# Rename columns for consistency
data <- data %>%
  rename(OV = OV_2)

# Z-score OV & Attention Measures at Subject Level
data <- data %>%
  group_by(sub_id) %>%
  mutate(
    OV           = scale(OV,           center = TRUE, scale = TRUE)[,1],  
    AttentionW   = scale(AttentionW,   center = TRUE, scale = TRUE)[,1],  
    InattentionW = scale(InattentionW, center = TRUE, scale = TRUE)[,1],
    rtime        = scale(rtime,        center = TRUE, scale = TRUE)[,1]  # Z-score reaction time as well
  ) %>%
  ungroup()

# Define linear regression formula for reaction time
model_formula <- as.formula("rtime ~ AttentionW + OV:InattentionW + (1 | sub_id)")

# Fit linear mixed model
model <- lmer(model_formula, data = data)

# -----------------------------------------------------------------------------
# Extract fixed effects from model, compute CIs, significance stars
# -----------------------------------------------------------------------------
beta_df <- as.data.frame(coef(summary(model)))

# Add predictor names
beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL

# Rename columns
colnames(beta_df) <- c("Estimate", "SE", "df", "t", "p", "Predictor")

# Compute 95% Confidence Intervals & filter to your 2 predictors
beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,  
    CI_Upper = Estimate + 1.96 * SE  
  ) %>%
  filter(Predictor %in% c("AttentionW", "OV:InattentionW"))

# Order predictors in desired order
beta_df$Predictor <- factor(beta_df$Predictor, 
                            levels = c("AttentionW", "OV:InattentionW"))

# Create column for significance stars
beta_df <- beta_df %>%
  mutate(
    Significance = case_when(
      p < 0.001 ~ "***",
      p < 0.01  ~ "**",
      p < 0.05  ~ "*",
      TRUE      ~ ""   # no stars if p >= .05
    )
  )

# -----------------------------------------------------------------------------
# Save model summary to text file
# -----------------------------------------------------------------------------
plot_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/EE_OV_Attention_Inattention_rtime.svg"
summary_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/EE_OV_Attention_Inattention_rtime_Summary.txt"

sink(summary_path)
cat("### Linear Mixed Model Summary (Reaction Time) - EE Phase ###\n\n")
print(summary(model))
sink()

# -----------------------------------------------------------------------------
# Plot with significance stars
# -----------------------------------------------------------------------------
plot_figure <- ggplot(beta_df, aes(x = Predictor, y = Estimate, fill = Predictor)) +
  geom_bar(
    stat     = "identity", 
    alpha    = 0.7, 
    color    = "black", 
    width    = 0.5, 
    linewidth = 1
  ) +
  geom_errorbar(
    aes(ymin = CI_Lower, ymax = CI_Upper), 
    width    = 0.1, 
    color    = "black", 
    linewidth= 1
  ) +
  
  # Place significance stars above/below the bar
  geom_text(
    aes(
      y = ifelse(Estimate < 0, CI_Lower - 0.05, CI_Upper + 0.05),
      label = Significance
    ),
    color     = "black",
    size      = 8,
    fontface  = "bold"
  ) +
  
  geom_hline(yintercept = 0, color = "black", linewidth = 1) +
  
  labs(
    title = "AttentionW and OV:InattentionW on Reaction Time",
    y     = "Beta Coefficients",
    x     = NULL
  ) +  
  
  scale_fill_manual(values = c("deepskyblue", "deepskyblue")) +
  
  theme_minimal() +
  theme(
    legend.position  = "none", 
    panel.grid       = element_blank(),
    axis.line.y      = element_line(color = "black", linewidth = 1),
    axis.line.x      = element_blank(),
    axis.text        = element_text(size = 20, color = "black"),
    axis.text.x      = element_text(size = 20, color = "black"),
    axis.title.y     = element_text(size = 20, color = "black"),
    plot.title       = element_text(size = 20, hjust = 0.5, color = "black", face = "bold"),
    panel.background = element_rect(fill = "white", color = "white"),
    plot.background  = element_rect(fill = "white", color = "white")
  )

# Save the plot
ggsave(plot_path, plot = plot_figure, device = "svg", width = 8, height = 6, dpi = 300)

# Print model summary for reference
print(summary(model))

plot_figure
```



```{r}
##############################################################################
#   R script to fit random slopes for AttentionW & OV:InattentionW,
#   and plot only those two fixed effects + subject-level slopes
#   without the pivot_longer() error
##############################################################################

# 1) Load necessary libraries
library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)
library(sjPlot)

# 2) Read data and preprocess -------------------------------------------------

file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

excluded_subs <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == "EE" & !sub_id %in% excluded_subs) %>%
  rename(OV = OV_2)

# Z-score OV & Attention Measures at Subject Level
data <- data %>%
  group_by(sub_id) %>%
  mutate(
    OV           = scale(OV,           center = TRUE, scale = TRUE)[,1],
    AttentionW   = scale(AttentionW,   center = TRUE, scale = TRUE)[,1],
    InattentionW = scale(InattentionW, center = TRUE, scale = TRUE)[,1]
  ) %>%
  ungroup()

# 3) Fit logistic mixed model with random slopes for both effects -------------

# We include (1 + AttentionW + OV:InattentionW | sub_id) so each subject
# gets their own slope for AttentionW and for OV:InattentionW.

model_formula <- as.formula("corr ~ AttentionW + OV:InattentionW + (1 + AttentionW + OV:InattentionW | sub_id)")

model <- glmer(
  formula = model_formula,
  data    = data,
  family  = binomial(link = "logit"),
  control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5))
)

# 4) Extract fixed effects (beta_df) for the two bars --------------------------
beta_df <- as.data.frame(coef(summary(model)))

beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL
colnames(beta_df) <- c("Estimate", "SE", "z", "p", "Predictor")

beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,
    CI_Upper = Estimate + 1.96 * SE
  ) %>%
  # Keep only the two predictors we want: "AttentionW" and "OV:InattentionW"
  filter(Predictor %in% c("AttentionW", "OV:InattentionW"))

beta_df$Predictor <- factor(beta_df$Predictor, levels = c("AttentionW", "OV:InattentionW"))

# 5) Extract subject-level slopes ---------------------------------------------
fix_eff    <- fixef(model)          # fixed-effect estimates (named vector)
random_eff <- ranef(model)$sub_id   # random slopes by subject

# Each subject's total slope = fixed + random offset
# For "AttentionW"
sub_slope_attn <- fix_eff["AttentionW"] + random_eff[,"AttentionW"]

# For "OV:InattentionW"
sub_slope_ov_inattn <- fix_eff["OV:InattentionW"] + random_eff[,"OV:InattentionW"]

# 5A) Make a data frame with simpler column names (avoiding colons)
subject_slopes <- data.frame(
  sub_id           = rownames(random_eff),
  AttentionW       = sub_slope_attn,
  OV_InattentionW  = sub_slope_ov_inattn  # underscore, not colon
)

# 5B) Pivot to long format
subject_slopes_long <- subject_slopes %>%
  pivot_longer(
    cols      = c("AttentionW", "OV_InattentionW"),
    names_to  = "Predictor",
    values_to = "Slope"
  ) %>%
  # Rename "OV_InattentionW" to "OV:InattentionW" after pivoting
  mutate(
    Predictor = if_else(
      Predictor == "OV_InattentionW", 
      "OV:InattentionW", 
      Predictor
    )
  )

# 5C) Factor with the same 2 levels
subject_slopes_long$Predictor <- factor(
  subject_slopes_long$Predictor,
  levels = c("AttentionW", "OV:InattentionW")
)

# 6) Define output paths ------------------------------------------------------

plot_path    <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/EE_Logistic_Plot_OV_Attention_Inattention.svg"
summary_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/EE_Logistic_Model_Attention_Inattention_Summary.txt"

# 7) Save model summary -------------------------------------------------------
sink(summary_path)
cat("### Logistic Mixed Model Summary - EE Phase ###\n\n")
print(summary(model))
sink()

# 8) Plot the bar chart + overlay subject-level slopes ------------------------
plot_figure <- ggplot(beta_df, aes(x = Predictor, y = Estimate, fill = Predictor)) +
  
  # (A) Bars for the two fixed effects
  geom_bar(stat = "identity", alpha = 0.7, color = "black", width = 0.5, linewidth = 1) +
  
  # (B) Error bars
  geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper),
                width = 0.1, color = "black", linewidth = 1) +
  
  # (C) p-values
  geom_text(
    aes(
      y = ifelse(Estimate < 0, CI_Lower - 0.05, CI_Upper + 0.05),
      label = sprintf("p = %.3f", p)
    ),
    color     = "black",
    size      = 8,
    fontface  = "bold"
  ) +
  
  # (D) Reference line at 0
  geom_hline(yintercept = 0, color = "black", linewidth = 1) +
  
  # (E) Jitter each subject's slope
  geom_jitter(
    data  = subject_slopes_long,
    aes(x = Predictor, y = Slope),
    width = 0.1, 
    fill = "white", 
    color = "black",
    shape = 21, 
    size = 4.5, 
    alpha = 0.8,
    stroke = 1
  ) +
  
  labs(
    title = "AttentionW & OV:InattentionW on Accuracy",
    y     = "Beta Coefficients (Log-Odds)",
    x     = NULL
  ) +
  
  # Exactly 2 color values for 2 factor levels
  scale_fill_manual(values = c("deepskyblue", "deepskyblue")) +
  
  theme_minimal() +
  theme(
    legend.position  = "none",
    panel.grid       = element_blank(),
    axis.line.y      = element_line(color = "black", linewidth = 1),
    axis.line.x      = element_blank(),
    axis.text        = element_text(size = 20, color = "black"),
    axis.text.x      = element_text(size = 20, color = "black"),
    axis.title.y     = element_text(size = 20, color = "black"),
    plot.title       = element_text(size = 20, hjust = 0.5, color = "black", face = "bold"),
    panel.background = element_rect(fill = "white", color = "white"),
    plot.background  = element_rect(fill = "white", color = "white")
  )

# 9) Save plot and view -------------------------------------------------------
ggsave(
  filename = plot_path,
  plot     = plot_figure,
  device   = "svg",
  width    = 8,
  height   = 6,
  dpi      = 300
)

print(summary(model))
plot_figure


```



```{r}
# Load necessary libraries
library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Exclude specific subjects
excluded_subs <- c(1, 4, 5, 6, 14, 99)

# Filter dataset: Only EE phase and exclude specific subjects
data <- data %>%
  filter(phase == "EE" & !sub_id %in% excluded_subs)

# Rename OV column
data <- data %>%
  rename(OV = OV_2)

# Z-score OV & Attention Measures at Subject Level
data <- data %>%
  group_by(sub_id) %>%
  mutate(
    OV = scale(OV, center = TRUE, scale = TRUE)[,1],
    AttentionW = scale(AttentionW, center = TRUE, scale = TRUE)[,1],
    InattentionW = scale(InattentionW, center = TRUE, scale = TRUE)[,1],
  ) %>%
  ungroup()


data <- data %>%
  group_by(sub_id) %>%
  mutate(rtime = scale(log(rtime))[,1]) %>%
  ungroup()

# Define linear mixed model formula
#model_formula <- as.formula("rtime ~ OV + OV:AttentionW + OV:InattentionW + (1 | #sub_id)")
model_formula <- as.formula(paste(dep_var, "~ OV *", eye_metric, "+ (1 + OV +", eye_metric, " | sub_id)"))

# Fit the linear mixed model
model <- lmer(model_formula, data = data)

# Extract fixed effects from model
beta_df <- as.data.frame(coef(summary(model)))
beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL
colnames(beta_df) <- c("Estimate", "SE", "df", "t", "p", "Predictor")

# Compute 95% Confidence Intervals
beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,
    CI_Upper = Estimate + 1.96 * SE
  ) %>%
  filter(Predictor %in% c("OV:AttentionW", "OV:InattentionW"))

# Order predictors
beta_df$Predictor <- factor(beta_df$Predictor, levels = c("OV:AttentionW", "OV:InattentionW"))

# Output paths
plot_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/EE_RT_Plot_OV_Attention_Inattention.svg"
summary_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/EE_LinearRT_Model_Attention_Inattention_Summary.txt"

# Save model summary
sink(summary_path)
cat("### Linear Mixed Model Summary - EE Phase RT ###\n\n")
print(summary(model))
sink()

# Plotting the effects
plot_figure <- ggplot(beta_df, aes(x = Predictor, y = Estimate, fill = Predictor)) +
  geom_bar(stat = "identity", alpha = 0.7, color = "black", width = 0.5, linewidth = 1) +
  geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.1, color = "black", linewidth = 1) +
  geom_text(aes(y = ifelse(Estimate < 0, CI_Lower - 0.05, CI_Upper + 0.05),
                label = sprintf("p = %.3f", p)),
            color = "black", size = 8, fontface = "bold") +
  geom_hline(yintercept = 0, color = "black", linewidth = 1) +
  labs(title = "Overall Value, Attention, and Inattention on RT",
       y = "Beta Coefficients", x = NULL) +
  scale_fill_manual(values = c("deepskyblue", "deepskyblue")) +
  theme_minimal() +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.line.y = element_line(color = "black", linewidth = 1),
    axis.line.x = element_blank(),  # removes the x-axis line
    axis.text = element_text(size = 20, color = "black"),
    axis.title.y = element_text(size = 20, color = "black"),
    plot.title = element_text(size = 20, hjust = 0.5, color = "black", face = "bold"),
    panel.background = element_rect(fill = "white", color = "white"),
    plot.background = element_rect(fill = "white", color = "white")
  )

# Save the plot
ggsave(plot_path, plot = plot_figure, device = "svg", width = 8, height = 6, dpi = 300)

# ✅ Print summary for immediate feedback
print(summary(model))

```

```{r}
# Load necessary libraries
library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Exclude specific subjects
excluded_subs <- c(1, 4, 5, 6, 14, 99)

# Filter dataset: Only EE phase and exclude specific subjects
data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs)

# Rename OV column
data <- data %>%
  rename(OV = OV_2)

# Z-score OV & Attention Measures at Subject Level
data <- data %>%
  group_by(sub_id) %>%
  mutate(
    OV = scale(OV, center = TRUE, scale = TRUE)[,1],
    AttentionW = scale(AttentionW, center = TRUE, scale = TRUE)[,1],
    InattentionW = scale(InattentionW, center = TRUE, scale = TRUE)[,1],
  ) %>%
  ungroup()


data <- data %>%
  group_by(sub_id) %>%
  mutate(rtime = scale(log(rtime))[,1]) %>%
  ungroup()

# Define linear mixed model formula
model_formula <- as.formula("rtime ~ OV + OV:AttentionW + OV:InattentionW + (1 | sub_id)")

# Fit the linear mixed model
model <- lmer(model_formula, data = data)

# Extract fixed effects from model
beta_df <- as.data.frame(coef(summary(model)))
beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL
colnames(beta_df) <- c("Estimate", "SE", "df", "t", "p", "Predictor")

# Compute 95% Confidence Intervals
beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,
    CI_Upper = Estimate + 1.96 * SE
  ) %>%
  filter(Predictor %in% c("OV:AttentionW", "OV:InattentionW"))

# Order predictors
beta_df$Predictor <- factor(beta_df$Predictor, levels = c("OV:AttentionW", "OV:InattentionW"))

# Output paths
plot_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_RT_Plot_OV_Attention_Inattention.svg"
summary_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_LinearRT_Model_Attention_Inattention_Summary.txt"

# Save model summary
sink(summary_path)
cat("### Linear Mixed Model Summary - ES Phase RT ###\n\n")
print(summary(model))
sink()

# Plotting the effects
plot_figure <- ggplot(beta_df, aes(x = Predictor, y = Estimate, fill = Predictor)) +
  geom_bar(stat = "identity", alpha = 0.7, color = "black", width = 0.5, linewidth = 1) +
  geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.1, color = "black", linewidth = 1) +
  geom_text(aes(y = ifelse(Estimate < 0, CI_Lower - 0.05, CI_Upper + 0.05),
                label = sprintf("p = %.3f", p)),
            color = "black", size = 8, fontface = "bold") +
  geom_hline(yintercept = 0, color = "black", linewidth = 1) +
  labs(title = "Overall Value, Attention, and Inattention on RT",
       y = "Beta Coefficients", x = NULL) +
  scale_fill_manual(values = c("darkorchid", "darkorchid")) +
  theme_minimal() +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.line.y = element_line(color = "black", linewidth = 1),
    axis.line.x = element_blank(),  # removes the x-axis line
    axis.text = element_text(size = 20, color = "black"),
    axis.title.y = element_text(size = 20, color = "black"),
    plot.title = element_text(size = 20, hjust = 0.5, color = "black", face = "bold"),
    panel.background = element_rect(fill = "white", color = "white"),
    plot.background = element_rect(fill = "white", color = "white")
  )

# Save the plot
ggsave(plot_path, plot = plot_figure, device = "svg", width = 8, height = 6, dpi = 300)

# ✅ Print summary for immediate feedback
print(summary(model))

```

**Model Comparison**

```{r}
# 📦 Load Libraries
library(lme4)
library(lmerTest)
library(tidyverse)
library(ggplot2)
library(svglite)
#install.packages("performance")
library(performance)

# Define Paths
base_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_model_comparisons_ES/"
dir.create(base_path, showWarnings = FALSE)

# 📄 Load and Preprocess Data
data <- read.csv("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv") %>%
  filter(phase == "ES" & !sub_id %in% c(1, 4, 5, 6, 14, 99)) %>%
  rename(OV = OV_2) %>%
  group_by(sub_id) %>%
  mutate(across(c(OV, AttentionW, InattentionW), ~ scale(.)[,1]),
         rtime = scale(log(rtime))[,1]) %>%
  ungroup()

# 📦 Utility: Fit, save, and plot any model
process_model <- function(model, model_name, dv_type = c("accuracy", "rt")) {
  dv_type <- match.arg(dv_type)
  
  # 📄 Save model summary
  summary_path <- paste0(base_path, model_name, "_summary.txt")
  sink(summary_path)
  cat(paste("###", toupper(dv_type), "MODEL:", model_name, "###\n\n"))
  print(summary(model))
  cat("\nR² (marginal/conditional):\n")
  print(r2(model))  # ✅ from performance package

  sink()

  # 📊 Extract betas
 beta_df <- coef(summary(model)) %>%
  as.data.frame() %>%
  rownames_to_column("Predictor")

# Rename columns dynamically
if (dv_type == "accuracy") {
  beta_df <- beta_df %>%
    rename(Estimate = Estimate, SE = `Std. Error`, p = `Pr(>|z|)`)
} else {
  beta_df <- beta_df %>%
    rename(Estimate = Estimate, SE = `Std. Error`, p = `Pr(>|t|)`)
}


  beta_df <- beta_df %>%
    mutate(CI_Lower = Estimate - 1.96 * SE,
           CI_Upper = Estimate + 1.96 * SE) %>%
    filter(str_detect(Predictor, "OV:AttentionW|OV:InattentionW")) %>%
    mutate(Predictor = factor(Predictor, levels = c("OV:AttentionW", "OV:InattentionW")))

  # 📊 Plot
  plot_title <- ifelse(dv_type == "accuracy", "Accuracy", "Reaction Time")
  plot_path <- paste0(base_path, model_name, "_plot.svg")
  
  plot_figure <- ggplot(beta_df, aes(x = Predictor, y = Estimate, fill = Predictor)) +
    geom_bar(stat = "identity", alpha = 0.7, color = "black", width = 0.5, linewidth = 1) +
    geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.1, color = "black", linewidth = 1) +
    geom_text(aes(y = ifelse(Estimate < 0, CI_Lower - 0.05, CI_Upper + 0.05),
                  label = sprintf("p = %.3f", p)), color = "black", size = 8, fontface = "bold") +
    geom_hline(yintercept = 0, color = "black", linewidth = 1) +
    labs(title = paste("OV × (In)Attention on", plot_title), y = "Beta Coefficients", x = NULL) +
    scale_fill_manual(values = rep("darkorchid", 2)) +
    theme_minimal() +
    theme(
      legend.position = "none",
      panel.grid = element_blank(),
      axis.line.y = element_line(color = "black", linewidth = 1),
      axis.line.x = element_blank(),
      axis.text = element_text(size = 20, color = "black"),
      axis.title.y = element_text(size = 20, color = "black"),
      plot.title = element_text(size = 20, hjust = 0.5, color = "black", face = "bold"),
      panel.background = element_rect(fill = "white"),
      plot.background = element_rect(fill = "white")
    )

  ggsave(plot_path, plot = plot_figure, device = "svg", width = 8, height = 6, dpi = 300)
}

# 📈 Fit and Compare Models (Accuracy)
m1_corr <- glmer(corr ~ OV:AttentionW + OV:InattentionW + (1 | sub_id), data = data, family = binomial)
m2_corr <- glmer(corr ~ OV:AttentionW + InattentionW + (1 | sub_id), data = data, family = binomial)
m3_corr <- glmer(corr ~ AttentionW + OV:InattentionW + (1 | sub_id), data = data, family = binomial)

process_model(m1_corr, "m1_corr", "accuracy")
process_model(m2_corr, "m2_corr", "accuracy")
process_model(m3_corr, "m3_corr", "accuracy")

anova(m1_corr, m2_corr, m3_corr)  # Optional nested model test

# 📉 Fit and Compare Models (Reaction Time)
m1_rt <- lmer(rtime ~ OV:AttentionW + OV:InattentionW + (1 | sub_id), data = data)
m2_rt <- lmer(rtime ~ OV:AttentionW + InattentionW + (1 | sub_id), data = data)
m3_rt <- lmer(rtime ~ AttentionW + OV:InattentionW + (1 | sub_id), data = data)

process_model(m1_rt, "m1_rt", "rt")
process_model(m2_rt, "m2_rt", "rt")
process_model(m3_rt, "m3_rt", "rt")

anova(m1_rt, m2_rt, m3_rt)  # Optional nested model test

# 📊 Compare via AIC
print(AIC(m1_corr, m2_corr, m3_corr))
print(AIC(m1_rt, m2_rt, m3_rt))

```

```{r}
```






#################################################  ##################################################
```{r}

data <- read.csv(file_path)


# Rename relevant columns for consistency
data <- data %>%
  rename(OV = OV_2, VD = AbsValueDiff_2)

# Exclude specific subjects
excluded_subs <- c(1, 4, 5, 6, 14, 99)

# Filter dataset
data <- data %>%
  filter(phase == "ES" & !sub_id %in% excluded_subs)

# **Z-score OV and VD at the individual level (within each subject)**
data <- data %>%
  group_by(sub_id) %>%
  mutate(
    VD = scale(VD, center = TRUE, scale = TRUE)[,1],  # Z-score per subject
    OV = scale(OV, center = TRUE, scale = TRUE)[,1]   # Z-score per subject
  ) %>%
  ungroup()

# Define dependent variable
dep_var <- "InattentionW"  # Target variable

# Define output directory
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

# Fit the LMM: Predicting FirstFixDur using OV and VD
model_formula <- as.formula(paste(dep_var, "~ OV + VD + (1 | sub_id)"))
model <- lmer(model_formula, data = data)

# Extract fixed effects
betas <- coef(summary(model))
beta_df <- as.data.frame(betas)

# Add predictor names
beta_df$Predictor <- rownames(beta_df)
rownames(beta_df) <- NULL

# Rename columns
colnames(beta_df) <- c("Estimate", "SE", "df", "t", "p", "Predictor")

# Exclude intercept
beta_df <- beta_df %>%
  filter(Predictor != "(Intercept)")

# Compute 95% Confidence Intervals
beta_df <- beta_df %>%
  mutate(
    CI_Lower = Estimate - 1.96 * SE,
    CI_Upper = Estimate + 1.96 * SE
  )

# Extract random slopes for visualization
random_effects <- coef(model)$sub_id[, c("OV", "VD")]

# Convert to tidy format for ggplot
random_effects_df <- as.data.frame(random_effects) %>%
  rownames_to_column(var = "sub_id") %>%
  pivot_longer(cols = c("OV", "VD"), names_to = "Predictor", values_to = "Beta")

# Define significance labels based on p-values
beta_df <- beta_df %>%
  mutate(
    Significance = case_when(
      p < 0.001 ~ "***",
      p < 0.01 ~ "**",
      p < 0.05 ~ "*",
      TRUE ~ "n.s."
    )
  )

# Reorder factor levels
beta_df$Predictor <- factor(beta_df$Predictor, levels = c("OV", "VD"))
random_effects_df$Predictor <- factor(random_effects_df$Predictor, levels = c("OV", "VD"))

# Define output file path
output_path <- paste0(output_dir, "ES_", dep_var, "on_OV_VD.svg")

# Create plot
plot_figure <- ggplot() +
  geom_bar(data = beta_df, aes(x = Predictor, y = Estimate, fill = Predictor), 
           stat = "identity", alpha = 0.7, color = "black", width = 0.5, linewidth = 1) +
  
  geom_errorbar(data = beta_df, aes(x = Predictor, ymin = CI_Lower, ymax = CI_Upper), 
                width = 0.05, color = "black", linewidth = 1) +
  
  geom_jitter(data = random_effects_df, aes(x = Predictor, y = Beta), 
              width = 0.1, fill = "white", color = "black", shape = 21, size = 4.5, alpha = 0.8, stroke = 1) +
  
  geom_text(data = beta_df, aes(x = Predictor, y = ifelse(Estimate < 0, CI_Lower - 0.05, CI_Upper + 0.05), label = Significance),
            color = "black", size = 9, fontface = "bold") +  
  
  geom_hline(yintercept = 0, color = "black", linewidth = 1) +
  
  labs(title = paste("ES - Beta Coefficients for OV & VD on", dep_var),
       x = "", y = "Beta Coefficients") +
  
  scale_x_discrete(labels = c("OV", "VD")) +
  
  scale_fill_manual(values = setNames(rep("darkorchid", 2), c("OV", "VD"))) +    
  
  theme_minimal() +
  theme(
    legend.position = "none", 
    panel.grid = element_blank(), 
    axis.line.y = element_line(color = "black", linewidth = 1),  
    axis.line.x = element_blank(),  
    axis.text = element_text(size = 14, color = "black"), 
    axis.title.y = element_text(size = 16, color = "black"),  
    plot.title = element_text(size = 18, hjust = 0.5, color = "black"), 
    panel.background = element_rect(fill = "white", color = "white"),  
    plot.background = element_rect(fill = "white", color = "white") 
  )

# Save the plot
ggsave(output_path, plot = plot_figure, device = "svg", width = 8, height = 6, dpi = 300)

cat("Saved plot as SVG at:", output_path, "\n")

print(plot_figure)


```


```{r}
library(ggplot2)
library(dplyr)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE phase and exclude certain subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(DwellTimeAdvantage, OVcate_2, chose_right)  # ✅ Drop NAs in all relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# **Fix for Quantile Binning of `DwellTimeAdvantage`**
data <- data %>%
  group_by(sub_id, OVcate_2) %>%
  mutate(DwellTimeAdvantage_bin = cut(DwellTimeAdvantage, 
                                      breaks = unique(quantile(DwellTimeAdvantage, probs = seq(0, 1, length.out = 6), na.rm = TRUE)), 
                                      labels = 1:(length(unique(quantile(DwellTimeAdvantage, probs = seq(0, 1, length.out = 6), na.rm = TRUE))) - 1),
                                      include.lowest = TRUE)) %>%
  ungroup()


# Compute Mean & 95% CI for P(choose right)
summary_df <- data %>%
  group_by(DwellTimeAdvantage_bin, OVcate_2) %>%
  summarise(
    p_choose_right = mean(chose_right, na.rm = TRUE),
    ci = 1.96 * sd(chose_right, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Ensure bin order is correct
summary_df$DwellTimeAdvantage_bin <- factor(summary_df$DwellTimeAdvantage_bin, levels = 1:5, labels = c("L>>R", "L>R", "L ~ R", "R>L", "R>>L"))

# Define custom colors for OV levels (low, medium, high)
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")   # blue , deepskyblue navy

# Plot
p <- ggplot(summary_df, aes(x = DwellTimeAdvantage_bin, y = p_choose_right, group = OVcate_2, color = OVcate_2)) +
  geom_point(size = 4) +  # Larger points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = p_choose_right - ci, ymax = p_choose_right + ci), width = 0.2, linewidth = 0.8) +  # Error bars
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) + # Chance Level Line
  scale_color_manual(values = colors, name = "OV Level") + # Custom Colors
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Add axis lines
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = "white") # White background
  ) +
  labs(
    title = "Dwell-Time Advantage Effect on Choice - ES-Phase",
    x = "Dwell Time Advantage (Right > Left)",
    y = "P(Choose Right)"
  )
# Save as SVG
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_DwellTimeAdvantage_Plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")

# Show plot
print(p)
```




```{r}
library(ggplot2)
library(dplyr)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for ES phase and exclude specific subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(DwellTimeAdvantage, OVcate_2, chose_right)  # ✅ Drop NAs in relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# **Fix for Quantile Binning of `DwellTimeAdvantage`**
data <- data %>%
  group_by(sub_id, OVcate_2) %>%
  mutate(DwellTimeAdvantage_bin = cut(DwellTimeAdvantage, 
                                      breaks = unique(quantile(DwellTimeAdvantage, probs = seq(0, 1, length.out = 6), na.rm = TRUE)), 
                                      labels = 1:(length(unique(quantile(DwellTimeAdvantage, probs = seq(0, 1, length.out = 6), na.rm = TRUE))) - 1),
                                      include.lowest = TRUE)) %>%
  ungroup()

# Compute Mean & 95% CI for P(choose right)
summary_df <- data %>%
  group_by(DwellTimeAdvantage_bin, OVcate_2) %>%
  summarise(
    p_choose_right = mean(chose_right, na.rm = TRUE),
    ci = 1.96 * sd(chose_right, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Ensure bin order is correct
summary_df$DwellTimeAdvantage_bin <- factor(summary_df$DwellTimeAdvantage_bin, 
                                            levels = 1:5, 
                                            labels = c("E>>S", "E>S", "E~S", "S>E", "S>>E"))

# Define custom colors for OV levels (low, medium, high)
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")

# Plot with adjusted text sizes and black labels
p <- ggplot(summary_df, aes(x = DwellTimeAdvantage_bin, y = p_choose_right, 
                            group = OVcate_2, color = OVcate_2)) +
  geom_point(size = 4) +  # Larger points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = p_choose_right - ci, ymax = p_choose_right + ci), 
                width = 0.2, linewidth = 0.8) +  # Error bars
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) +  # Chance Level Line
  scale_color_manual(values = colors, name = "OV Level") +  # Custom Colors
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Axis lines
    legend.position = "top",
    legend.text = element_text(size = 16),  # ✅ Legend size set to 20
    axis.text = element_text(size = 19, color = "black"),  # ✅ X & Y axis tick labels size 20, in black
    axis.title = element_text(size = 20, color = "black"),  # ✅ X & Y axis titles size 20, in black
    plot.title = element_text(size = 19, hjust = 0.5, face="bold", color = "black"),  # ✅ Title size 20, centered, black
    plot.background = element_rect(fill = "white", color = "white")  # ✅ White background
  ) +
  labs(
    title = "Dwell-Time Advantage Effect on Choice - ES Phase",
    x = "Dwell Time Advantage (Symbolic > Experiential)",
    y = "P(Choose Symbolic)"
  )

# Save as SVG
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_NEW_DwellTimeAdvantage_Plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")

# Show plot
print(p)

```

## Chih-Chung Ting's suggestions for Analysis

## His question:

On the other hand, I am still confused about the Dwell-time advantage effect in page 6. I think it is helpful to see the proportion of dwell time on each option. Maybe participants had a tendency to look at something they are recalling (e.g., experiential ones) even if they want to choose Symbolic options. This raises another interesting question: how does memory influence attention-decision interaction?

Two papers are related to this concern:

Weilbächer, R. A., Krajbich, I., Rieskamp, J., & Gluth, S. (2021). The influence of visual attention on memory-based preferential choice. Cognition, 215, 104804.

Study2 and 3 in Shevlin, B. R., Smith, S. M., Hausfeld, J., & Krajbich, I. (2022). High-value decisions are fast and accurate, inconsistent with diminishing value sensitivity. Proceedings of the National Academy of Sciences, 119(6), e2101508119.

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

# get modified CCT data - the data is the same as before just that I scaled the option values (*100) like CCT suggested to make the algorithm converge faster in HDDM (has nothing to do with the eye-tracking bit - what changed: e.g. 0.3 -> 30)
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs_CCT.csv"
data <- read.csv(file_path)

# Filter for ES and exclude subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(PropDwell_Left, PropDwell_Right, chose_right)

# Assign Final Choice Labels
data <- data %>%
  mutate(final_choice = ifelse(chose_right == 1, "Chose Symbolic", "Chose Experiential"))

data_long <- data %>%
  pivot_longer(cols = c("PropDwell_Left", "PropDwell_Right"),
               names_to = "LookedAt",
               values_to = "Dwell_Proportion")


data_long$LookedAt <- factor(data_long$LookedAt,
                             levels = c("PropDwell_Left", "PropDwell_Right"),
                             labels = c("Looked at Experiential", "Looked at Symbolic"))

# Summarize by Final Choice and Option Looked At
summary_df <- data_long %>%
  group_by(final_choice, LookedAt) %>%
  summarise(
    mean_dwell = mean(Dwell_Proportion, na.rm = TRUE),
    ci = 1.96 * sd(Dwell_Proportion, na.rm = TRUE) / sqrt(n()),
    .groups = 'drop'
  )

# Define colors: Experiential (dark blue), Symbolic (dark red)
colors <- c("Looked at Experiential" = "darkblue", "Looked at Symbolic" = "darkred")

# Create the bar plot
p <- ggplot(summary_df, aes(x = final_choice, y = mean_dwell, fill = LookedAt)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.6), width = 0.5) +
  geom_errorbar(aes(ymin = mean_dwell - ci, ymax = mean_dwell + ci),
                position = position_dodge(width = 0.6), width = 0.2) +
  scale_fill_manual(values = colors, name = "Dwell Time On") +
  labs(
    title = "Proportion of Dwell Time by Final Choice (ES Phase)",
    x = "Final Choice",
    y = "Mean Proportion of Dwell Time",
    fill = "Looked At"
  ) +
  theme_minimal(base_size = 14) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +  
  theme(
    legend.position = "top",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black")
  )

# Show plot
print(p)

```



```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

# Load data
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs_CCT.csv"
data <- read.csv(file_path)

# Filter for ES phase and exclude subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(PropDwell_Left, PropDwell_Right, chose_right)

# Create Final Choice Labels
data <- data %>%
  mutate(final_choice = ifelse(chose_right == 1, "Chose Symbolic", "Chose Experiential"))

# Convert data from wide to long format
data_long <- data %>%
  pivot_longer(cols = c("PropDwell_Left", "PropDwell_Right"),
               names_to = "LookedAt",
               values_to = "Dwell_Proportion")

# Rename levels for clarity
data_long$LookedAt <- factor(data_long$LookedAt,
                             levels = c("PropDwell_Left", "PropDwell_Right"),
                             labels = c("Looked at Experiential", "Looked at Symbolic"))

# Aggregate so that each participant contributes one data point per (final_choice, LookedAt)
data_participant <- data_long %>%
  group_by(sub_id, final_choice, LookedAt) %>%
  summarise(Dwell_Proportion = mean(Dwell_Proportion, na.rm = TRUE), .groups = 'drop')

# Create summary statistics for the bar chart (mean and 95% CI per group)
summary_df <- data_participant %>%
  group_by(final_choice, LookedAt) %>%
  summarise(
    mean_dwell = mean(Dwell_Proportion, na.rm = TRUE),
    ci = 1.96 * sd(Dwell_Proportion, na.rm = TRUE) / sqrt(n()),
    .groups = 'drop'
  )

# Define muted colors for the bars (they differ by LookedAt)
bar_colors <- c("Looked at Experiential" = "darkblue",
                "Looked at Symbolic" = "darkred")

# Now plot
p <- ggplot(summary_df, aes(x = final_choice, y = mean_dwell * 100, fill = LookedAt)) +
  # Bar chart with dodge
  geom_bar(stat = "identity",
           position = position_dodge(width = 0.6),
           width = 0.5,
           alpha = 0.8,
           color = "black") +
  # Error bars
  geom_errorbar(aes(ymin = (mean_dwell - ci) * 100, ymax = (mean_dwell + ci) * 100),
                position = position_dodge(width = 0.6),
                width = 0.2,
                linewidth = 0.8) +
  # Overlay one data point per participant per LookedAt condition.
  # Here we map 'color' to LookedAt so the dodge is determined by that aesthetic,
  # then we set fill to white to get white points with black outlines.
  geom_point(data = data_participant,
             aes(x = final_choice, y = Dwell_Proportion * 100, group = LookedAt, color = LookedAt),
             position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.6),
             shape = 21,
             fill = "white",
             stroke = 1,
             size = 4,
             alpha = 0.8) +
  # Set bar colors (for fill) and remove the legend for the points
  scale_fill_manual(values = bar_colors, name = "Dwell Time On") +
  scale_color_manual(values = bar_colors, guide = "none") +
  # Add a thicker grey dotted line at 50%
  geom_hline(yintercept = 50, linetype = "dotted", color = "gray50", linewidth = 1.2) +
  # Y-axis from 0 to 100 with 10% increments
  scale_y_continuous(limits = c(0, 100),
                     breaks = seq(0, 100, 10),
                     labels = function(x) paste0(x, "%")) +
  labs(
    title = "Dwell Time by Choice - ES Phase",
    x = "Choice",
    y = "Mean Proportion - Dwell Time %",
    fill = "Looked At"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    legend.position = "top",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 1),
    axis.text = element_text(size = 16, color = "black"),
    axis.title = element_text(size = 18, face = "bold", color = "black"),
    plot.title = element_text(size = 20, hjust = 0.5, face = "bold", color = "black"),
    plot.background = element_rect(fill = "white", color = "white")
  )

print(p)

```

```{r}
# Filter to only dwell time on symbolic
symbolic_data <- data_participant %>%
  filter(LookedAt == "Looked at Symbolic")

# Summary for plot
summary_symbolic <- symbolic_data %>%
  group_by(final_choice) %>%
  summarise(
    mean_dwell = mean(Dwell_Proportion),
    ci = 1.96 * sd(Dwell_Proportion) / sqrt(n()),
    .groups = 'drop'
  )
# One-sample t-tests: is dwell time on symbolic different from 50%?
t_test_symbolic <- symbolic_data %>%
  group_by(final_choice) %>%
  summarise(
    t_result = list(t.test(Dwell_Proportion, mu = 0.5)),
    .groups = 'drop'
  )

# View results
t_test_symbolic$t_result



# Plot: Only symbolic dwell time
p_simple <- ggplot(summary_symbolic, aes(x = final_choice, y = mean_dwell * 100)) +
  geom_bar(stat = "identity",
           fill = "darkorchid",
           width = 0.5,
           alpha = 0.8,
           color = "black") +
  geom_errorbar(aes(ymin = (mean_dwell - ci) * 100, ymax = (mean_dwell + ci) * 100),
                width = 0.2,
                linewidth = 0.8) +
  geom_point(data = symbolic_data,
             aes(x = final_choice, y = Dwell_Proportion * 100),
             position = position_jitter(width = 0.1),
             shape = 21,
             fill = "white",
             color = "darkorchid",
             stroke = 1,
             size = 4,
             alpha = 0.8) +
  geom_hline(yintercept = 50, linetype = "dotted", color = "gray50", linewidth = 1.2) +
  scale_y_continuous(limits = c(0, 100),
                     breaks = seq(0, 100, 10),
                     labels = function(x) paste0(x, "%")) +
  labs(
    title = "Proportion of Dwell Time on Symbolic Option in ES",
    x = "Choice",
    y = "Dwell Time on Symbolic (%)"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    legend.position = "none",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 1),
    axis.text = element_text(size = 16, color = "black"),
    axis.title = element_text(size = 18, face = "bold", color = "black"),
    plot.title = element_text(size = 18, hjust = 0.5, face = "bold", color = "black"),
    plot.background = element_rect(fill = "white", color = "white")
  )

print(p_simple)

# Create summary table per group
# Create summary table per group, with Cohen's d computed manually
results_summary <- symbolic_data %>%
  group_by(final_choice) %>%
  summarise(
    mean_prop = mean(Dwell_Proportion),
    sd_prop = sd(Dwell_Proportion),
    n = n(),
    t_test = list(t.test(Dwell_Proportion, mu = 0.5)),
    cohen_d = (mean(Dwell_Proportion) - 0.5) / sd(Dwell_Proportion),
    .groups = 'drop'
  )

# Unpack the t-test results for each row
results_summary <- results_summary %>%
  rowwise() %>%
  mutate(
    t_value = t_test$statistic,
    df = t_test$parameter,
    p_value = t_test$p.value,
    ci_low = t_test$conf.int[1],
    ci_high = t_test$conf.int[2]
  ) %>%
  select(final_choice, mean_prop, sd_prop, n, t_value, df, p_value, ci_low, ci_high, cohen_d)
print(results_summary)

```

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

###############################################################################
### 1) Summarize by sub_id & LookedAt (Ignoring final_choice)
###############################################################################
# Instead of grouping by sub_id, final_choice, LookedAt,
# we only group by sub_id & LookedAt.
# This yields one dwell proportion per participant for each of the two "LookedAt" categories

# Starting from your 'data_long' or the original 'data':
# But let's build from 'data_long' to ensure we only keep ES-phase and the relevant columns

file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs_CCT.csv"
data <- read.csv(file_path)

phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(PropDwell_Left, PropDwell_Right, chose_right)

# Convert wide to long
data_long <- data %>%
  pivot_longer(cols = c("PropDwell_Left","PropDwell_Right"),
               names_to = "LookedAt",
               values_to = "Dwell_Proportion") %>%
  mutate(LookedAt = factor(LookedAt,
                           levels = c("PropDwell_Left","PropDwell_Right"),
                           labels = c("Looked at Experiential", "Looked at Symbolic")))

# Summarize by (sub_id, LookedAt)
data_participant2 <- data_long %>%
  group_by(sub_id, LookedAt) %>%
  summarise(Dwell_Proportion = mean(Dwell_Proportion, na.rm=TRUE), .groups="drop")

###############################################################################
### 2) Print numeric means & standard deviations for each LookedAt
###############################################################################
stats_df <- data_participant2 %>%
  group_by(LookedAt) %>%
  summarise(
    n = n(),
    mean = mean(Dwell_Proportion, na.rm=TRUE),
    sd   = sd(Dwell_Proportion, na.rm=TRUE)
  )

cat("\n=== Descriptive Stats (Ignoring Final Choice) ===\n")
print(stats_df)

###############################################################################
### 3) Simple Plot: 2 Bars (Experiential vs. Symbolic)
###############################################################################
# 3a) Summarize means & 95% CI for the plot
summary_plot <- data_participant2 %>%
  group_by(LookedAt) %>%
  summarise(
    mean_dwell = mean(Dwell_Proportion, na.rm=TRUE),
    ci = 1.96 * sd(Dwell_Proportion, na.rm=TRUE) / sqrt(n()),
    .groups="drop"
  )

# 3b) Build bar chart with 2 bars
p_2bars <- ggplot(summary_plot, aes(x=LookedAt, y=mean_dwell*100, fill=LookedAt)) +
  geom_bar(stat="identity", width=0.5, alpha=0.8, color="black") +
  geom_errorbar(aes(ymin=(mean_dwell-ci)*100, ymax=(mean_dwell+ci)*100),
                width=0.2, linewidth=0.8) +
  # overlay raw data points
  geom_point(data=data_participant2,
             aes(x=LookedAt, y=Dwell_Proportion*100),
             position=position_jitter(width=0.1, height=0, seed=123),
             shape=21, fill="white", color="black", stroke=1, size=3, alpha=0.7) +
  scale_y_continuous(limits=c(0,100), breaks=seq(0,100,10), labels=function(x) paste0(x,"%")) +
  scale_fill_manual(values=c("Looked at Experiential"="darkblue", "Looked at Symbolic"="darkred")) +
  labs(title="Dwell Time: Experiential vs. Symbolic",
       x="",
       y="Mean Dwell Proportion (%)") +
  theme_minimal(base_size=16) +
  theme(legend.position="none",
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        axis.line=element_line(color="black", linewidth=1),
        axis.text=element_text(size=14, color="black"),
        axis.title=element_text(size=16, face="bold", color="black"))

print(p_2bars)

###############################################################################
### 4) Nonparametric test (paired) for difference
###############################################################################
# We assume each participant has both "Looked at Experiential" and "Looked at Symbolic."
# Pivot wide to get 2 columns per sub_id
df_wide <- data_participant2 %>%
  pivot_wider(
    names_from = LookedAt,
    values_from = Dwell_Proportion
  ) %>%
  drop_na(`Looked at Experiential`,`Looked at Symbolic`)

# if either or is missing, we remove
if(nrow(df_wide)==0) {
  cat("\nNo participants with both categories -> cannot test.\n")
} else {
  # Check difference normality
  diff_vec <- df_wide$`Looked at Experiential` - df_wide$`Looked at Symbolic`
  p_shap <- shapiro.test(diff_vec)$p.value
  
  cat("\n=== Paired Comparison: Experiential vs. Symbolic ===\n")
  cat("Shapiro-Wilk for difference: p =", p_shap, "\n")
  
  if(p_shap < 0.05) {
    cat("Data is non-normal -> Wilcoxon signed-rank\n")
    test_res <- wilcox.test(df_wide$`Looked at Experiential`,
                            df_wide$`Looked at Symbolic`,
                            paired=TRUE, exact=FALSE)
    test_name <- "Wilcoxon signed-rank"
  } else {
    cat("Data is normal -> Paired T-test\n")
    test_res <- t.test(df_wide$`Looked at Experiential`,
                       df_wide$`Looked at Symbolic`,
                       paired=TRUE)
    test_name <- "Paired T"
  }
  
  # Show results
  print(test_res)
  cat("\nMethod used:", test_name, "\n")
}

```




```{r}
###############################################################################
### 3) Normality Check
###############################################################################
# We do Shapiro test for each (final_choice x LookedAt) group
normality_res <- data_participant %>%
  group_by(final_choice, LookedAt) %>%
  summarise(
    n = n(),
    shapiro_p = shapiro.test(Dwell_Proportion)$p.value,
    .groups = "drop"
  )

cat("\n==== Shapiro-Wilk Normality Results ====\n")
print(normality_res)

###############################################################################
### 4) One-Sample Tests vs. 50%
###############################################################################
cat("\n==== One-Sample Tests vs. 50% ====\n")
groups_4 <- data_participant %>%
  group_by(final_choice, LookedAt) %>%
  group_split()

one_sample_list <- list()

for(gdf in groups_4) {
  # identify group label
  fc  <- unique(gdf$final_choice)
  la  <- unique(gdf$LookedAt)
  lab <- paste(fc, la, sep="_")

  # check normality p-value
  p_norm <- normality_res %>%
    filter(final_choice==fc, LookedAt==la) %>%
    pull(shapiro_p)

  if(p_norm < 0.05) {
    # use Wilcoxon
    test_res <- wilcox.test(gdf$Dwell_Proportion, mu=0.5, exact=FALSE)
    test_name <- "Wilcoxon"
  } else {
    # use t-test
    test_res <- t.test(gdf$Dwell_Proportion, mu=0.5)
    test_name <- "One-sample T"
  }

  # store
  one_sample_list[[lab]] <- list(
    group = lab,
    method = test_name,
    estimate = mean(gdf$Dwell_Proportion),
    statistic = test_res$statistic,
    p_value = test_res$p.value
  )
}

one_sample_df <- do.call(rbind, lapply(one_sample_list, as.data.frame))
print(one_sample_df)

cat("\n>>> You may want to adjust p-values for multiple comparisons (4 tests) <<<\n")

###############################################################################
### 5) Within Each Final Choice: Compare E vs. S
###############################################################################
cat("\n==== Within Each Final Choice: Compare E vs S ====\n")

paired_list <- list()

for(choice_val in c("Chose Experiential", "Chose Symbolic")) {

  # 1) If you want to handle duplicates by summarising:
  df_wide <- data_participant %>%
    filter(final_choice == choice_val) %>%
    group_by(sub_id, LookedAt) %>%
    summarise(Dwell_Proportion = mean(Dwell_Proportion), .groups="drop") %>%
    pivot_wider(
      names_from  = LookedAt,
      values_from = Dwell_Proportion
    )

  # or use pivot_wider(..., values_fn=mean)...

  if(ncol(df_wide) < 3) {
    cat("\nNo data for both categories in", choice_val, "\n")
    next
  }

  diff_vec <- df_wide$`Looked at Experiential` - df_wide$`Looked at Symbolic`
  p_shap_diff <- shapiro.test(diff_vec)$p.value

  if(p_shap_diff < 0.05) {
    test_res <- wilcox.test(df_wide$`Looked at Experiential`,
                            df_wide$`Looked at Symbolic`,
                            paired = TRUE, exact = FALSE)
    test_name <- "Wilcoxon paired"
  } else {
    test_res <- t.test(df_wide$`Looked at Experiential`,
                       df_wide$`Looked at Symbolic`,
                       paired = TRUE)
    test_name <- "Paired T"
  }

  paired_list[[choice_val]] <- list(
    final_choice = choice_val,
    method       = test_name,
    statistic    = test_res$statistic,
    p_value      = test_res$p.value
  )
}
paired_df <- do.call(rbind, lapply(paired_list, as.data.frame))
print(paired_df)

###############################################################################
### 6) Friedman Test for All 4 Conditions
###############################################################################
cat("\n==== Friedman Test for 4 repeated combos (ExpExp,ExpSym,SymExp,SymSym) ====\n")

# 6a) pivot data to wide: columns = (EE, ES, SE, SS)
df_fried <- data_participant %>%
  mutate(cond = case_when(
    final_choice=="Chose Experiential" & LookedAt=="Looked at Experiential" ~ "EE",
    final_choice=="Chose Experiential" & LookedAt=="Looked at Symbolic"     ~ "ES",
    final_choice=="Chose Symbolic"     & LookedAt=="Looked at Experiential" ~ "SE",
    final_choice=="Chose Symbolic"     & LookedAt=="Looked at Symbolic"     ~ "SS",
    TRUE ~ NA_character_
  )) %>%
  select(sub_id, cond, Dwell_Proportion) %>%
  pivot_wider(names_from=cond, values_from=Dwell_Proportion)

# omit sub_id missing any of the 4 columns
df_fried <- df_fried %>%
  drop_na(EE, ES, SE, SS)

if(nrow(df_fried)==0) {
  cat("No participants have all 4 combos -> cannot run Friedman.\n")
} else {
  # run Friedman test
  fr_res <- friedman.test(as.matrix(df_fried[,c("EE","ES","SE","SS")]))
  print(fr_res)
  cat("If p<0.05, do post-hoc pairwise comparisons. E.g. 'pairwise.wilcox.test' on these 4 columns.\n")
}

###############################################################################
### (Optional) 7) ARTool or LMM
###############################################################################
cat("\n==== (Optional) ARTool for 2×2 nonparametric repeated measures ====\n")
cat("You can do something like:\n\n")
cat('library(ARTool)\n\nm_art <- art(Dwell_Proportion ~ final_choice*LookedAt + (1|sub_id), data=data_participant)\nanova(m_art)\n\n')

cat("\n==== (Optional) Linear Mixed Model if unbalanced or prefer LMM. ====\n")
cat("library(lme4)\nlibrary(lmerTest)\nm <- lmer(Dwell_Proportion ~ final_choice*LookedAt + (1|sub_id), data=data_participant)\nsummary(m)\n")

cat("\n==== Done! ====\n")

```

```{r}
###############################################################################
### LMM for final_choice * LookedAt, random intercept by sub_id
###############################################################################
library(lme4)
library(lmerTest)
library(emmeans)

# 1) Fit the model
m_lmm <- lmer(
  Dwell_Proportion ~ final_choice * LookedAt + (1 | sub_id),
  data = data_participant
)

# 2) Summarize
summary(m_lmm)
anova(m_lmm)  # for Type III ANOVA table if you want F-tests

# 3) Post-hoc pairwise across the 4 combos
em_mod  <- emmeans(m_lmm, ~ final_choice * LookedAt)
posthoc <- pairs(em_mod, adjust = "bonferroni")
print(posthoc)

# optional main-effect pairwise
em_fc   <- emmeans(m_lmm, ~ final_choice)
pairs(em_fc)

em_la   <- emmeans(m_lmm, ~ LookedAt)
pairs(em_la)

###############################################################################
### Check residual distribution
###############################################################################
par(mfrow=c(1,2))
qqnorm(resid(m_lmm), main="QQ plot of LMM residuals")
qqline(resid(m_lmm))
plot(fitted(m_lmm), resid(m_lmm), main="Residual vs. Fitted")
par(mfrow=c(1,1))


```
```{r}
df_sub <- data_participant %>%
  filter(final_choice == "Chose Symbolic",
         LookedAt == "Looked at Symbolic")

wilcox.test(df_sub$Dwell_Proportion, mu = 0.5,
            alternative = "two.sided", exact = FALSE)

```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

# 1) Load data
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs_CCT.csv"
data <- read.csv(file_path)

# 2) Filter for ES phase and exclude subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(PropDwell_Left, PropDwell_Right, chose_right, OVcate_2)

# 3) Create final choice labels
data <- data %>%
  mutate(final_choice = ifelse(chose_right == 1, "Chose Symbolic", "Chose Experiential"))

# 4) Convert from wide to long for dwell time
data_long <- data %>%
  pivot_longer(
    cols = c("PropDwell_Left", "PropDwell_Right"),
    names_to = "LookedAt",
    values_to = "Dwell_Proportion"
  ) %>%
  mutate(
    LookedAt = factor(
      LookedAt,
      levels = c("PropDwell_Left", "PropDwell_Right"),
      labels = c("Looked at Experiential", "Looked at Symbolic")
    )
  )

# 5) Aggregate so each participant has exactly one row per (final_choice × OVcate_2 × LookedAt)
data_participant <- data_long %>%
  group_by(sub_id, final_choice, OVcate_2, LookedAt) %>%
  summarise(
    Dwell_Proportion = mean(Dwell_Proportion, na.rm = TRUE),
    .groups = "drop"
  )

# 6) Summarize for the bar chart
summary_df <- data_participant %>%
  group_by(final_choice, OVcate_2, LookedAt) %>%
  summarise(
    mean_dwell = mean(Dwell_Proportion, na.rm = TRUE),
    ci = 1.96 * sd(Dwell_Proportion, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# 7) Create a combined factor for the X axis (Choice × OV)
summary_df <- summary_df %>%
  mutate(Choice_OV = paste0(final_choice, "-", OVcate_2))

data_participant <- data_participant %>%
  mutate(Choice_OV = paste0(final_choice, "-", OVcate_2))

# Optional: set factor levels in a nice order:
# (Chose Experiential-low, -medium, -high, then Chose Symbolic-low, -medium, -high)
all_levels <- c(
  "Chose Experiential-low",
  "Chose Experiential-medium",
  "Chose Experiential-high",
  "Chose Symbolic-low",
  "Chose Symbolic-medium",
  "Chose Symbolic-high"
)
summary_df$Choice_OV <- factor(summary_df$Choice_OV, levels = all_levels)
data_participant$Choice_OV <- factor(data_participant$Choice_OV, levels = all_levels)

# 8) Define bar colors for LookedAt
bar_colors <- c("Looked at Experiential" = "darkblue",
                "Looked at Symbolic"     = "darkred")

# 9) Plot
p <- ggplot(summary_df, aes(x = Choice_OV, y = mean_dwell * 100, fill = LookedAt)) +
  # Bar chart with dodge
  geom_bar(
    stat = "identity",
    position = position_dodge(width = 0.6),
    width = 0.5,
    alpha = 0.8,
    color = "black"
  ) +
  # Error bars
  geom_errorbar(
    aes(
      ymin = (mean_dwell - ci) * 100,
      ymax = (mean_dwell + ci) * 100
    ),
    position = position_dodge(width = 0.6),
    width = 0.2,
    linewidth = 0.8
  ) +
  # Overlay one data point per participant per (Choice × OV × LookedAt)
  geom_point(
    data = data_participant,
    aes(
      x = Choice_OV,
      y = Dwell_Proportion * 100,
      group = LookedAt,
      color = LookedAt
    ),
    position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.6),
    shape = 21,
    fill = "white",
    stroke = 1,
    size = 4,
    alpha = 0.8
  ) +
  # Map fill color for bars, remove color legend for the points
  scale_fill_manual(values = bar_colors, name = "Dwell Time On") +
  scale_color_manual(values = bar_colors, guide = "none") +
  # 50% reference line
  geom_hline(
    yintercept = 50,
    linetype = "dotted",
    color = "gray50",
    linewidth = 1.2
  ) +
  # Y-axis from 0 to 100 with 10% increments
  scale_y_continuous(
    limits = c(0, 100),
    breaks = seq(0, 100, 10),
    labels = function(x) paste0(x, "%")
  ) +
  labs(
    title = "Dwell Time by Choice & OV - ES Phase",
    x = "Choice & OV Category",
    y = "Mean Proportion of Dwell Time (%)",
    fill = "Looked At"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    legend.position = "top",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 1),
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 16, face = "bold", color = "black"),
    plot.title = element_text(size = 18, hjust = 0.5, face = "bold", color = "black"),
    plot.background = element_rect(fill = "white", color = "white")
  )

print(p)

```



```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

# ... your data pre-processing ...
# We'll assume you already have data_participant and summary_df,
# but haven't combined final_choice with OVcate_2 into a single factor.

# We keep final_choice and OVcate_2 as separate columns
# and let facet_wrap handle final_choice

p_facet <- ggplot(summary_df, aes(x = OVcate_2, 
                                  y = mean_dwell * 100, 
                                  fill = LookedAt)) +
  geom_bar(stat = "identity",
           position = position_dodge(width = 0.6),
           width = 0.5,
           alpha = 0.8,
           color = "black") +
  geom_errorbar(aes(
    ymin = (mean_dwell - ci)*100,
    ymax = (mean_dwell + ci)*100
  ),
  position = position_dodge(width = 0.6),
  width = 0.2,
  linewidth = 0.8) +
  geom_point(data = data_participant,
             aes(x = OVcate_2, 
                 y = Dwell_Proportion * 100, 
                 group = LookedAt, 
                 color = LookedAt),
             position = position_jitterdodge(jitter.width = 0.1, 
                                             dodge.width = 0.6),
             shape = 21,
             fill = "white",
             stroke = 1,
             size = 4,
             alpha = 0.8) +
  facet_wrap(~ final_choice, nrow = 1) +  # 1 row, 2 panels
  scale_fill_manual(values = c("Looked at Experiential" = "darkblue",
                               "Looked at Symbolic"     = "darkred"),
                    name = "Dwell Time On") +
  scale_color_manual(values = c("darkblue", "darkred"), guide = "none") +
  geom_hline(yintercept = 50, linetype = "dotted", 
             color = "gray50", linewidth = 1.2) +
  scale_y_continuous(
    limits = c(0,100),
    breaks = seq(0,100,10),
    labels = function(x) paste0(x, "%")
  ) +
  labs(
    title = "Dwell Time by Choice & OV - ES Phase",
    x = "OV Category",
    y = "Mean Proportion of Dwell Time (%)",
    fill = "Looked At"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    legend.position = "top",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 1),
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 16, face = "bold", color = "black"),
    plot.title = element_text(size = 18, hjust = 0.5, 
                              face = "bold", color = "black"),
    plot.background = element_rect(fill = "white", color = "white"),
    strip.text = element_text(size = 14, face = "bold")  # facet label style
  )

print(p_facet)

```


```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

# 1) Load data
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs_CCT.csv"
data <- read.csv(file_path)

# 2) Filter for ES phase and exclude subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(PropDwell_Left, PropDwell_Right, chose_right, OVcate_2)

# 3) Create final choice labels
data <- data %>%
  mutate(final_choice = ifelse(chose_right == 1, "Chose Symbolic", "Chose Experiential"))

# Reorder OVcate_2 to c("high","medium","low")
data$OVcate_2 <- factor(data$OVcate_2, levels = c("high", "medium", "low"))


# 4) Convert from wide to long
data_long <- data %>%
  pivot_longer(
    cols = c("PropDwell_Left", "PropDwell_Right"),
    names_to = "LookedAt",
    values_to = "Dwell_Proportion"
  ) %>%
  mutate(
    LookedAt = factor(
      LookedAt,
      levels = c("PropDwell_Left", "PropDwell_Right"),
      labels = c("Looked at Experiential", "Looked at Symbolic")
    )
  )

# 5) One row per participant × final_choice × OVcate_2 × LookedAt
data_participant <- data_long %>%
  group_by(sub_id, final_choice, OVcate_2, LookedAt) %>%
  summarise(Dwell_Proportion = mean(Dwell_Proportion, na.rm = TRUE), .groups = "drop")

# 6) Summaries for bar chart
summary_df <- data_participant %>%
  group_by(final_choice, OVcate_2, LookedAt) %>%
  summarise(
    mean_dwell = mean(Dwell_Proportion, na.rm = TRUE),
    ci = 1.96 * sd(Dwell_Proportion, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Define bar colors
bar_colors <- c("Looked at Experiential" = "darkblue",
                "Looked at Symbolic"     = "darkred")

## Plot
p_facet <- ggplot() +
  # Bar layer (summary_df)
  geom_bar(
    data = summary_df,
    aes(x = OVcate_2,
        y = mean_dwell * 100,
        fill = LookedAt),
    stat = "identity",
    position = position_dodge(width = 0.6),
    width = 0.5,
    alpha = 0.8,
    color = "black"
  ) +
  # Error bars (summary_df)
  geom_errorbar(
    data = summary_df,
    aes(x = OVcate_2,
        ymin = (mean_dwell - ci) * 100,
        ymax = (mean_dwell + ci) * 100,
        fill = LookedAt),
    position = position_dodge(width = 0.6),
    width = 0.2,
    linewidth = 0.8
  ) +
  # Points layer (data_participant)
  geom_point(
    data = data_participant,
    aes(x = OVcate_2,
        y = Dwell_Proportion * 100,
        group = LookedAt,
        color = LookedAt),
    position = position_jitterdodge(jitter.width = 0.1,
                                    dodge.width = 0.6),
    shape = 21,
    fill = "white",
    stroke = 1,
    size = 4,
    alpha = 0.8
  ) +
  # Facet by final_choice
  facet_wrap(~ final_choice, nrow = 1) +
  # Fill & color scales
  scale_fill_manual(values = bar_colors, name = "Dwell Time On") +
  scale_color_manual(values = bar_colors, guide = "none") +
  # 50% reference line
  geom_hline(yintercept = 50, linetype = "dotted",
             color = "gray50", linewidth = 1.2) +
  # Ticks from 30% to 100% but do NOT set limits here
  scale_y_continuous(
    breaks = seq(30, 90, 10),
    labels = function(x) paste0(x, "%")
  ) +
  # Zoom in from 30% to 100% without discarding data
  coord_cartesian(ylim = c(30, 90)) +
  labs(
    title = "Dwell Time by Choice & OV - ES Phase",
    x = "OV Category",
    y = "Mean Proportion of Dwell Time (%)"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    legend.position = "top",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 1),
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 16, face = "bold", color = "black"),
    plot.title = element_text(size = 18, hjust = 0.5,
                              face = "bold", color = "black"),
    plot.background = element_rect(fill = "white", color = "white"),
    strip.text = element_text(size = 14, face = "bold")
  )

print(p_facet)

```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

# 1) Load data
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs_CCT.csv"
data <- read.csv(file_path)

# 2) Filter for ES phase and exclude subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(PropDwell_Left, PropDwell_Right, chose_right, OVcate_2)

# 3) Reorder OVcate_2 so it’s in c("high", "medium", "low")
data$OVcate_2 <- factor(data$OVcate_2, levels = c("high","medium","low"))

# 4) Create final choice labels
data <- data %>%
  mutate(final_choice = ifelse(chose_right == 1, "Chose Symbolic", "Chose Experiential"))

# 5) Convert from wide to long
data_long <- data %>%
  pivot_longer(
    cols = c("PropDwell_Left","PropDwell_Right"),
    names_to = "LookedAt",
    values_to = "Dwell_Proportion"
  ) %>%
  mutate(
    LookedAt = factor(
      LookedAt,
      levels = c("PropDwell_Left","PropDwell_Right"),
      labels = c("Experiential","Symbolic")
    )
  )

# 6) Create participant-level data
data_participant <- data_long %>%
  group_by(sub_id, final_choice, OVcate_2, LookedAt) %>%
  summarise(
    Dwell_Proportion = mean(Dwell_Proportion, na.rm=TRUE),
    .groups = "drop"
  )

# 7) Summaries for bars
summary_df <- data_participant %>%
  group_by(final_choice, OVcate_2, LookedAt) %>%
  summarise(
    mean_dwell = mean(Dwell_Proportion, na.rm=TRUE),
    ci = 1.96 * sd(Dwell_Proportion, na.rm=TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Define bar colors
bar_colors <- c("Experiential" = "darkblue",
                "Symbolic"     = "darkred")

# Plot
p_facet <- ggplot() +
  # 1) BAR LAYER (below everything else)
  geom_bar(
    data = summary_df,
    aes(x = OVcate_2, y = mean_dwell * 100, fill = LookedAt),
    stat = "identity",
    position = position_dodge(width=0.6),
    width = 0.5,
    alpha = 0.8,
    color = "black"
  ) +
  # 2) POINT LAYER (above bars)
  geom_point(
    data = data_participant,
    aes(x = OVcate_2, y = Dwell_Proportion * 100, color = LookedAt),
    position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.6),
    shape = 21,
    fill = "white",
    stroke = 1,
    size = 4,
    alpha = 0.8
  ) +
  # 3) ERROR-BAR LAYER (on top of both bars & points)
  geom_errorbar(
    data = summary_df,
    aes(x = OVcate_2,
        ymin = (mean_dwell - ci)*100,
        ymax = (mean_dwell + ci)*100,
        fill = LookedAt),
    position = position_dodge(width=0.6),
    width = 0.2,
    linewidth = 1
  ) +
  facet_wrap(~ final_choice, nrow = 1) +
  scale_fill_manual(values = bar_colors, name = "Dwell Time") +
  scale_color_manual(values = bar_colors, guide = "none") +
  # 50% reference line
  geom_hline(
    yintercept = 50,
    linetype = "dotted",
    color = "gray50",
    linewidth = 1.2
  ) +
  # Ticks from 30% → 100%, no data removal
  scale_y_continuous(
    breaks = seq(30, 100, 10),
    labels = function(x) paste0(x, "%")
  ) +
  coord_cartesian(ylim = c(30, 100)) +
  labs(
    title = "Dwell Time by Choice & OV - ES Phase",
    x = "OV Category",
    y = "Mean Proportion of Dwell Time (%)"
  ) +
  theme_minimal(base_size=16) +
  theme(
    legend.position = "top",
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color="black", linewidth=1),
    axis.text = element_text(size=14, color="black"),
    axis.title = element_text(size=16, face="bold", color="black"),
    plot.title = element_text(size=18, hjust=0.5, face="bold", color="black"),
    strip.text = element_text(size=14, face="bold"),
    plot.background = element_rect(fill="white", color="white")
  )

print(p_facet)

```

```{r}
###############################################################################
### 0) Load Packages
###############################################################################
# Make sure you have these installed:
# install.packages(c("lme4","lmerTest","emmeans"))

library(lme4)
library(lmerTest)  # for p-values in summary
library(emmeans)   # for post-hoc pairwise comparisons

###############################################################################
### 1) Fit a 3-way LMM
###############################################################################
# data_participant should have columns:
#   sub_id, final_choice, LookedAt, OVcate_2, Dwell_Proportion
# And each is a factor except Dwell_Proportion (numeric).
# Example:
#   data_participant <- data_participant %>%
#     mutate(
#       final_choice = factor(final_choice),
#       LookedAt     = factor(LookedAt),
#       OVcate_2     = factor(OVcate_2, levels=c("high","medium","low"))  # if not done yet
#     )

m_lmm <- lmer(
  Dwell_Proportion ~ final_choice * LookedAt * OVcate_2 + (1 | sub_id),
  data = data_participant
)

# 2) Summaries
cat("\n=== Model Summary ===\n")
summary(m_lmm)

cat("\n=== Type III ANOVA Table ===\n")
anova(m_lmm)  # default from lmerTest is a Type III table

###############################################################################
### 2) Post-hoc with emmeans
###############################################################################
# We'll get the estimated means for all combos of final_choice x LookedAt x OVcate_2
em_3way <- emmeans(m_lmm, ~ final_choice * LookedAt * OVcate_2)

cat("\n=== Post-hoc: all pairwise across 2x2x3 combos ===\n")
pairs_3way <- pairs(em_3way, adjust = "bonferroni")
pairs_3way

# Or, if you specifically want to compare "high, medium, low" within each final_choice x LookedAt:
cat("\n=== Pairwise OVcate_2 within each final_choice x LookedAt ===\n")
posthoc_OV <- contrast(
  em_3way,
  method = "pairwise",
  by = c("final_choice","LookedAt"),
  adjust = "bonferroni"
)
summary(posthoc_OV)

###############################################################################
### 3) Additional Examples
###############################################################################
# Example: If you only want to see how "OVcate_2" differs within e.g. "Chose Symbolic" & "LookedAt=Symbolic":
# We can do something like:
# em_sub <- emmeans(m_lmm, ~ OVcate_2 | (final_choice="Chose Symbolic", LookedAt="Symbolic"))
# pairs(em_sub, adjust="bonferroni")

# But the code above with 'by=c("final_choice","LookedAt")' is usually simpler.

cat("\n=== Done! ===\n")

```



```{r}
install.packages("ez")       # For within-subjects ANOVA
install.packages("emmeans")  # For post-hoc tests
install.packages("dplyr")    # For data wrangling
library(ez)
library(emmeans)
library(dplyr)


# Aggregate by sub_id: Compute mean P(choose right) per bin for each participant
agg_data <- data %>%
  group_by(sub_id, DwellTimeAdvantage_bin) %>%
  summarise(mean_p_choose_right = mean(chose_right, na.rm = TRUE), .groups = 'drop')

anova_result <- ezANOVA(
  data = agg_data,
  dv = mean_p_choose_right,  # Dependent variable: Mean P(Choose Right)
  wid = sub_id,              # Within-subjects factor: Participant ID
  within = DwellTimeAdvantage_bin,  # Independent variable (within-subjects)
  type = 3,                  # Type III SS for unbalanced data
  detailed = TRUE
)

# Print ANOVA results
anova_result

# Run post-hoc pairwise comparisons with Bonferroni adjustment
posthoc_result1 <- emmeans(
  lm(mean_p_choose_right ~ factor(DwellTimeAdvantage_bin), data = agg_data),  # Linear model for pairwise tests
  pairwise ~ DwellTimeAdvantage_bin,  # Compare all bins
  adjust = "bonferroni"  # Correct for multiple comparisons
)

# Print post-hoc test results
posthoc_result1

```
```{r}
library(ez)
library(emmeans)
library(dplyr)

# Aggregate by sub_id: Compute mean P(Choose Right) per bin per OV level per participant
agg_data <- data %>%
  group_by(sub_id, DwellTimeAdvantage_bin, OVcate_2) %>%
  summarise(mean_p_choose_right = mean(chose_right, na.rm = TRUE), .groups = 'drop')
anova_results <- list()  # Store ANOVA results



library(lmerTest)
library(emmeans)

# Run a linear mixed model with subject as a random effect
lmm_model <- lmer(mean_p_choose_right ~ OVcate_2 * DwellTimeAdvantage_bin + (1 | sub_id),
                  data = agg_data)

# Get ANOVA table
anova(lmm_model)

# Post-hoc pairwise comparisons for OVcate_2 within each DwellTimeAdvantage_bin
posthoc_results <- emmeans(lmm_model, pairwise ~ OVcate_2 | DwellTimeAdvantage_bin, adjust = "bonferroni")
print(posthoc_results)


# Define file path for saving results (same folder as the SVG)
results_file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_Analysis_Results.txt"

# Open a connection to the file
sink(results_file)

# === Print ANOVA Results for Overall Dwell Time Advantage Effect ===
cat("\n===== ANOVA: Effect of DwellTimeAdvantage_bin on P(Choose Right) =====\n")
print(anova_result)

# === Print Post-hoc Pairwise Comparisons for DwellTimeAdvantage_bin ===
cat("\n===== Post-hoc Tests: Pairwise Comparisons for DwellTimeAdvantage_bin =====\n")
print(posthoc_result1)


# === Print Linear Mixed Model Results ===
cat("\n===== Linear Mixed Model: OVcate_2 * DwellTimeAdvantage_bin Effect =====\n")
print(anova(lmm_model))

# === Print Post-hoc Tests for Mixed Model ===
cat("\n===== Post-hoc Comparisons for OV Levels within Each Bin (LMM) =====\n")
print(posthoc_results)

# Close the file connection
sink()

# Confirm that results were saved
cat("\n✅ Analysis results saved to:", results_file, "\n")



```


```{r}
library(ggplot2)
library(dplyr)
library(ez)
library(emmeans)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE phase and exclude certain subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(DwellTimeAdvantage, OVcate_2, chose_right)  # ✅ Drop NAs in all relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# **Fix for Quantile Binning of `DwellTimeAdvantage`**
data <- data %>%
  group_by(sub_id, OVcate_2) %>%
  mutate(DwellTimeAdvantage_bin = cut(DwellTimeAdvantage, 
                                      breaks = unique(quantile(DwellTimeAdvantage, probs = seq(0, 1, length.out = 6), na.rm = TRUE)), 
                                      labels = 1:(length(unique(quantile(DwellTimeAdvantage, probs = seq(0, 1, length.out = 6), na.rm = TRUE))) - 1),
                                      include.lowest = TRUE)) %>%
  ungroup()


# Compute Mean & 95% CI for P(choose right)
summary_df <- data %>%
  group_by(DwellTimeAdvantage_bin, OVcate_2) %>%
  summarise(
    p_choose_right = mean(chose_right, na.rm = TRUE),
    ci = 1.96 * sd(chose_right, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Ensure bin order is correct
summary_df$DwellTimeAdvantage_bin <- factor(summary_df$DwellTimeAdvantage_bin, levels = 1:5, labels = c("L>>R", "L>R", "L ~ R", "R>L", "R>>L"))

# Define custom colors for OV levels (low, medium, high)
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")   # blue , deepskyblue navy

# Plot
p <- ggplot(summary_df, aes(x = DwellTimeAdvantage_bin, y = p_choose_right, group = OVcate_2, color = OVcate_2)) +
  geom_point(size = 4) +  # Larger points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = p_choose_right - ci, ymax = p_choose_right + ci), width = 0.2, linewidth = 0.8) +  # Error bars
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) + # Chance Level Line
  scale_color_manual(values = colors, name = "OV Level") + # Custom Colors
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Add axis lines
    legend.position = "top",
    legend.text = element_text(size = 19),  # Legend text size set to 20
    axis.text = element_text(size = 22, color = "black"),  # Axis tick labels size 20, in black
    axis.title = element_text(size = 22, color = "black"),  # X and Y axis labels size 20, in black
    plot.title = element_text(size = 22, hjust = 0.5, face="bold", color = "black"),  # Title size 20, centered, black
    plot.background = element_rect(fill = "white", color = "white") # White background
  ) +
  labs(
    title = "Dwell-Time Advantage on Choice - ES-Phase",
    x = "Dwell Time Advantage (Right > Left)",
    y = "P(Choose Right)"
  )

# Save as SVG
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_DwellTimeAdvantage_Plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")


# Show plot
print(p)

```
```{r}
# Aggregate by sub_id: Compute mean P(choose right) per bin for each participant
agg_data <- data %>%
  group_by(sub_id, DwellTimeAdvantage_bin) %>%
  summarise(mean_p_choose_right = mean(chose_right, na.rm = TRUE), .groups = 'drop')

anova_result <- ezANOVA(
  data = agg_data,
  dv = mean_p_choose_right,  # Dependent variable: Mean P(Choose Right)
  wid = sub_id,              # Within-subjects factor: Participant ID
  within = DwellTimeAdvantage_bin,  # Independent variable (within-subjects)
  type = 3,                  # Type III SS for unbalanced data
  detailed = TRUE
)

# Print ANOVA results
anova_result

# Run post-hoc pairwise comparisons with Bonferroni adjustment
posthoc_result <- emmeans(
  lm(mean_p_choose_right ~ factor(DwellTimeAdvantage_bin), data = agg_data),  # Linear model for pairwise tests
  pairwise ~ DwellTimeAdvantage_bin,  # Compare all bins
  adjust = "bonferroni"  # Correct for multiple comparisons
)

# Print post-hoc test results
posthoc_result

```
```{r}
# Define file path for saving results (same folder as the SVG)
results_file <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/EE_Analysis_Results.txt"

# Open a connection to the file
sink(results_file)

# === Print ANOVA Results for Overall Dwell Time Advantage Effect ===
cat("\n===== ANOVA: Effect of DwellTimeAdvantage_bin on P(Choose Right) - EE Phase =====\n")
print(anova_result)

# === Print Post-hoc Pairwise Comparisons for DwellTimeAdvantage_bin ===
cat("\n===== Post-hoc Tests: Pairwise Comparisons for DwellTimeAdvantage_bin - EE Phase =====\n")
print(posthoc_result)

# === Print ANOVA Results for Each Bin (OVcate_2 within bins) ===
cat("\n===== ANOVA: Effect of OVcate_2 within Each DwellTimeAdvantage_bin - EE Phase =====\n")
for (bin in unique(agg_data$DwellTimeAdvantage_bin)) {
  cat("\n=== ANOVA for Bin:", bin, "===\n")
  print(anova_results[[as.character(bin)]])
}

# === Print Post-hoc Pairwise Comparisons for Each Bin ===
cat("\n===== Post-hoc Tests: Pairwise Comparisons for OV Levels within Each Bin - EE Phase =====\n")
for (bin in unique(agg_data$DwellTimeAdvantage_bin)) {
  cat("\n=== Post-hoc for Bin:", bin, "===\n")
  print(posthoc_results[[as.character(bin)]])
}

# === Print Linear Mixed Model Results ===
cat("\n===== Linear Mixed Model: OVcate_2 * DwellTimeAdvantage_bin Effect - EE Phase =====\n")
print(anova(lmm_model))

# === Print Post-hoc Tests for Mixed Model ===
cat("\n===== Post-hoc Comparisons for OV Levels within Each Bin (LMM) - EE Phase =====\n")
print(posthoc_results)

# Close the file connection
sink()

# Confirm that results were saved
cat("\n✅ EE Phase Analysis results saved to:", results_file, "\n")

```
############################################################################################################################################

```{r}
library(ggplot2)
library(dplyr)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE phase and exclude certain subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(DwelltimeAdvantageCorrect, OVcate_2, corr)  # ✅ Drop NAs in all relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# **Fix for Quantile Binning of `DwellTimeAdvantage`**
data <- data %>%
  group_by(sub_id, OVcate_2) %>%
  mutate(DwelltimeAdvantageCorrect_bin = cut(DwelltimeAdvantageCorrect, 
                                      breaks = unique(quantile(DwelltimeAdvantageCorrect, probs = seq(0, 1, length.out = 6), na.rm = TRUE)), 
                                      labels = 1:(length(unique(quantile(DwelltimeAdvantageCorrect, probs = seq(0, 1, length.out = 6), na.rm = TRUE))) - 1),
                                      include.lowest = TRUE)) %>%
  ungroup()


# Compute Mean & 95% CI for P(choose right)
summary_df <- data %>%
  group_by(DwelltimeAdvantageCorrect_bin, OVcate_2) %>%
  summarise(
    p_choose_corr = mean(corr, na.rm = TRUE),
    ci = 1.96 * sd(corr, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Ensure bin order is correct
summary_df$DwelltimeAdvantageCorrect_bin <- factor(summary_df$DwelltimeAdvantageCorrect_bin, levels = 1:5, labels = c("I>>C", "I>C", "C ~ I", "C>I", "C>>I"))

# Define custom colors for OV levels (low, medium, high)
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")   # blue , deepskyblue navy

# Plot
p <- ggplot(summary_df, aes(x = DwelltimeAdvantageCorrect_bin, y = p_choose_corr, group = OVcate_2, color = OVcate_2)) +
  geom_point(size = 4) +  # Larger points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = p_choose_corr - ci, ymax = p_choose_corr + ci), width = 0.2, linewidth = 0.8) +  # Error bars
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) + # Chance Level Line
  scale_color_manual(values = colors, name = "OV Level") + # Custom Colors
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Add axis lines
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = "white") # White background
  ) +
  labs(
    title = "Effect of Dwell Time on Correct Option on Choice - ES Phase",
    x = "Dwell Time Advantage (Better - Worse Option)",
    y = "P(Choose Correct)"
)

# Save as SVG
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_DwellTimeCORRECT_Plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")
library(ez)


# Show plot
print(p)
##################################################################################################
# Aggregate by sub_id: Compute mean P(choose right) per bin for each participant
agg_data <- data %>%
  group_by(sub_id, DwelltimeAdvantageCorrect_bin, OVcate_2) %>%  # ✅ Keep OVcate_2 in the grouping
  summarise(mean_p_choose_corr = mean(corr, na.rm = TRUE), .groups = 'drop')

library(lme4)
library(lmerTest)
library(emmeans)

# Fit the LMM: Predict P(Choose Correct) using Dwell Time and OV level
lmm_model <- lmer(
  mean_p_choose_corr ~ DwelltimeAdvantageCorrect_bin * OVcate_2 +   # Fixed effects (interaction)
    (1 | sub_id),  # Random intercept for subjects
  data = agg_data
)

# Print model summary
summary(lmm_model)

emmeans_lmm <- emmeans(lmm_model, pairwise ~ DwelltimeAdvantageCorrect_bin | OVcate_2, adjust = "bonferroni")
emmeans_OV <- emmeans(lmm_model, pairwise ~ OVcate_2 | DwelltimeAdvantageCorrect_bin, adjust = "bonferroni")

# Print results
print(emmeans_OV)

# Print results
print(emmeans_lmm)

lmm_no_OV <- lmer(
  mean_p_choose_corr ~ DwelltimeAdvantageCorrect_bin +  # No interaction with OV
    (1 | sub_id), 
  data = agg_data
)

anova(lmm_no_OV, lmm_model)  # Compare models


lmm_continuous <- lmer(corr ~ DwelltimeAdvantageCorrect * OVcate_2 + (1 | sub_id), data = data)
summary(lmm_continuous)

##################################

# Define output directory (same as where the SVG is saved)
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"

# Define file name
stats_file <- paste0(output_dir, phase_filter, "_DwellTimeCORRECT_LMM_Results.txt")

# Start saving output to the file
sink(stats_file)

cat("### Linear Mixed Model: Predicting P(Choose Correct) ###\n")
print(summary(lmm_model))

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - Dwell Time Bins Within OV Levels ###\n")
print(emmeans_lmm)

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - OV Levels Within Each Bin ###\n")
print(emmeans_OV)

cat("\n### Model Comparison: Does OV Level Influence Dwell Time Effects? ###\n")
print(anova(lmm_no_OV, lmm_model))

cat("\n### Linear Mixed Model (Continuous Dwell Time) ###\n")
print(summary(lmm_continuous))

# Stop saving to file
sink()

# Confirm output
print(paste("Statistics saved to:", stats_file))



```

```{r}
library(ggplot2)
library(dplyr)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE phase and exclude certain subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(DwellPropAdvantageCorrect, OVcate_2, corr)  # ✅ Drop NAs in all relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# **Fix for Quantile Binning of `DwellTimeAdvantage`**
data <- data %>%
  group_by(sub_id, OVcate_2) %>%
  mutate(DwellPropAdvantageCorrect_bin = cut(DwellPropAdvantageCorrect, 
                                      breaks = unique(quantile(DwellPropAdvantageCorrect, probs = seq(0, 1, length.out = 6), na.rm = TRUE)), 
                                      labels = 1:(length(unique(quantile(DwellPropAdvantageCorrect, probs = seq(0, 1, length.out = 6), na.rm = TRUE))) - 1),
                                      include.lowest = TRUE)) %>%
  ungroup()


# Compute Mean & 95% CI for P(choose right)
summary_df <- data %>%
  group_by(DwellPropAdvantageCorrect_bin, OVcate_2) %>%
  summarise(
    p_choose_corr = mean(corr, na.rm = TRUE),
    ci = 1.96 * sd(corr, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Ensure bin order is correct
summary_df$DwellPropAdvantageCorrect_bin <- factor(summary_df$DwellPropAdvantageCorrect_bin, levels = 1:5, labels = c("I>>C", "I>C", "C ~ I", "C>I", "C>>I"))

# Define custom colors for OV levels (low, medium, high)
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")   # blue , deepskyblue navy

# Plot
p <- ggplot(summary_df, aes(x = DwellPropAdvantageCorrect_bin, y = p_choose_corr, group = OVcate_2, color = OVcate_2)) +
  geom_point(size = 4) +  # Larger points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = p_choose_corr - ci, ymax = p_choose_corr + ci), width = 0.2, linewidth = 0.8) +  # Error bars
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) + # Chance Level Line
  scale_color_manual(values = colors, name = "OV Level") + # Custom Colors
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Add axis lines
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = "white") # White background
  ) +
  labs(
    title = "Effect of Proportion on Correct Option on Choice - ES Phase",
    x = "Dwell Time Proportion (Better - Worse Option)",
    y = "P(Choose Correct)"
)

# Save as SVG
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_DwellPropCORRECT_Plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")
library(ez)


# Show plot
print(p)
##################################################################################################
# Aggregate by sub_id: Compute mean P(choose right) per bin for each participant
agg_data <- data %>%
  group_by(sub_id, DwellPropAdvantageCorrect_bin, OVcate_2) %>%  # ✅ Keep OVcate_2 in the grouping
  summarise(mean_p_choose_corr = mean(corr, na.rm = TRUE), .groups = 'drop')

library(lme4)
library(lmerTest)
library(emmeans)

# Fit the LMM: Predict P(Choose Correct) using Dwell Time and OV level
lmm_model <- lmer(
  mean_p_choose_corr ~ DwellPropAdvantageCorrect_bin * OVcate_2 +   # Fixed effects (interaction)
    (1 | sub_id),  # Random intercept for subjects
  data = agg_data
)

# Print model summary
summary(lmm_model)

emmeans_lmm <- emmeans(lmm_model, pairwise ~ DwellPropAdvantageCorrect_bin | OVcate_2, adjust = "bonferroni")
emmeans_OV <- emmeans(lmm_model, pairwise ~ OVcate_2 | DwellPropAdvantageCorrect_bin, adjust = "bonferroni")

# Print results
print(emmeans_OV)

# Print results
print(emmeans_lmm)

lmm_no_OV <- lmer(
  mean_p_choose_corr ~ DwellPropAdvantageCorrect_bin +  # No interaction with OV
    (1 | sub_id), 
  data = agg_data
)

anova(lmm_no_OV, lmm_model)  # Compare models


lmm_continuous <- lmer(corr ~ DwellPropAdvantageCorrect * OVcate_2 + (1 | sub_id), data = data)
summary(lmm_continuous)

##################################

# Define output directory (same as where the SVG is saved)
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"

# Define file name
stats_file <- paste0(output_dir, phase_filter, "_DwellPropCORRECT_LMM_Results.txt")

# Start saving output to the file
sink(stats_file)

cat("### Linear Mixed Model: Predicting P(Choose Correct) ###\n")
print(summary(lmm_model))

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - Dwell Time Bins Within OV Levels ###\n")
print(emmeans_lmm)

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - OV Levels Within Each Bin ###\n")
print(emmeans_OV)

cat("\n### Model Comparison: Does OV Level Influence Dwell Proportion Effects? ###\n")
print(anova(lmm_no_OV, lmm_model))

cat("\n### Linear Mixed Model (Continuous Dwell Time) ###\n")
print(summary(lmm_continuous))

# Stop saving to file
sink()

# Confirm output
print(paste("Statistics saved to:", stats_file))
```

```{r}
# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE phase and exclude certain subjects
phase_filter <- "ES"
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(InattentionW, OVcate_2, corr)  # ✅ Drop NAs in all relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# **Fix for Quantile Binning of `AttentionW`**
data <- data %>%
  group_by(sub_id, OVcate_2) %>%
  mutate(InattentionW_bin = cut(InattentionW, 
                                      breaks = unique(quantile(InattentionW, probs = seq(0, 1, length.out = 6), na.rm = TRUE)), 
                                      labels = 1:(length(unique(quantile(InattentionW, probs = seq(0, 1, length.out = 6), na.rm = TRUE))) - 1),
                                      include.lowest = TRUE)) %>%
  ungroup()


# Compute Mean & 95% CI for P(choose right)
summary_df <- data %>%
  group_by(InattentionW_bin, OVcate_2) %>%
  summarise(
    p_choose_corr = mean(corr, na.rm = TRUE),
    ci = 1.96 * sd(corr, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Ensure bin order is correct
summary_df$InattentionW_bin <- factor(summary_df$InattentionW_bin, levels = 1:5, labels = c("C>>I", "C>I", "C ~ I", "I>C", "I>>C"))

# Define custom colors for OV levels (low, medium, high)
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")   # blue , deepskyblue navy

# Plot
p <- ggplot(summary_df, aes(x = InattentionW_bin, y = p_choose_corr, group = OVcate_2, color = OVcate_2)) +
  geom_point(size = 4) +  # Larger points
  geom_line(linewidth = 1.2) +  # Thicker lines
  geom_errorbar(aes(ymin = p_choose_corr - ci, ymax = p_choose_corr + ci), width = 0.2, linewidth = 0.8) +  # Error bars
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) + # Chance Level Line
  scale_color_manual(values = colors, name = "OV Level") + # Custom Colors
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Add axis lines
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = "white") # White background
  ) +
  labs(
    title = "Effect of Inattentional weight on Correct Option on Choice - EE Phase",
    x = "Inattention Weight",
    y = "P(Choose Correct)"
)

# Save as SVG
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/ES_InattentionW_Plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")
library(ez)


# Show plot
print(p)
##################################################################################################
# Aggregate by sub_id: Compute mean P(choose right) per bin for each participant
agg_data <- data %>%
  group_by(sub_id, InattentionW_bin, OVcate_2) %>%  # ✅ Keep OVcate_2 in the grouping
  summarise(mean_p_choose_corr = mean(corr, na.rm = TRUE), .groups = 'drop')

library(lme4)
library(lmerTest)
library(emmeans)

# Fit the LMM: Predict P(Choose Correct) using Dwell Time and OV level
lmm_model <- lmer(
  mean_p_choose_corr ~ InattentionW_bin * OVcate_2 +   # Fixed effects (interaction)
    (1 | sub_id),  # Random intercept for subjects
  data = agg_data
)

# Print model summary
summary(lmm_model)

emmeans_lmm <- emmeans(lmm_model, pairwise ~ InattentionW_bin | OVcate_2, adjust = "bonferroni")
emmeans_OV <- emmeans(lmm_model, pairwise ~ OVcate_2 | InattentionW_bin, adjust = "bonferroni")

# Print results
print(emmeans_OV)

# Print results
print(emmeans_lmm)

lmm_no_OV <- lmer(
  mean_p_choose_corr ~ InattentionW_bin +  # No interaction with OV
    (1 | sub_id), 
  data = agg_data
)

anova(lmm_no_OV, lmm_model)  # Compare models


lmm_continuous <- lmer(corr ~ InattentionW_bin * OVcate_2 + (1 | sub_id), data = data)
summary(lmm_continuous)

#####################################################################################################################

# Define output directory (same as where the SVG is saved)
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"

# Define file name
stats_file <- paste0(output_dir, phase_filter, "_InattentionW_LMM_Results.txt")

# Start saving output to the file
sink(stats_file)

cat("### Linear Mixed Model: Predicting P(Choose Correct) ###\n")
print(summary(lmm_model))

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - Inattention Weight Bins Within OV Levels ###\n")
print(emmeans_lmm)

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - OV Levels Within Each Bin ###\n")
print(emmeans_OV)

cat("\n### Model Comparison: Does OV Level Influence InattentionW Weight Effects? ###\n")
print(anova(lmm_no_OV, lmm_model))

cat("\n### Linear Mixed Model (Continuous InattentionW Weight) ###\n")
print(summary(lmm_continuous))

# Stop saving to file
sink()

# Confirm output
print(paste("Statistics saved to:", stats_file))
```



```{r}
library(ggplot2)
library(dplyr)
library(lme4)
library(lmerTest)
library(emmeans)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE phase and exclude certain subjects
phase_filter <- "ES"  # Change as needed
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(FixationAdvantage, OVcate_2, chose_right)  # ✅ Drop NAs in relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# **Fix for Quantile Binning of `FixationAdvantage`**
data <- data %>%
  group_by(sub_id, OVcate_2) %>%
  mutate(FixationAdvantage_bin = cut(FixationAdvantage, 
                                     breaks = unique(quantile(FixationAdvantage, probs = seq(0, 1, length.out = 6), na.rm = TRUE)), 
                                     labels = 1:(length(unique(quantile(FixationAdvantage, probs = seq(0, 1, length.out = 6), na.rm = TRUE))) - 1),
                                     include.lowest = TRUE)) %>%
  ungroup()

# Compute Mean & 95% CI for P(choose right)
summary_df <- data %>%
  group_by(FixationAdvantage_bin, OVcate_2) %>%
  summarise(
    p_choose_right = mean(chose_right, na.rm = TRUE),
    ci = 1.96 * sd(chose_right, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Ensure bin order is correct
summary_df$FixationAdvantage_bin <- factor(summary_df$FixationAdvantage_bin, levels = 1:5, labels = c("L>>R", "L>R", "L ~ R", "R>L", "R>>L"))

# Define custom colors for OV levels (low, medium, high)
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")

# Plot
p <- ggplot(summary_df, aes(x = FixationAdvantage_bin, y = p_choose_right, group = OVcate_2, color = OVcate_2)) +
  geom_point(size = 4) +  
  geom_line(linewidth = 1.2) +  
  geom_errorbar(aes(ymin = p_choose_right - ci, ymax = p_choose_right + ci), width = 0.2, linewidth = 0.8) +  
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) +  
  scale_color_manual(values = colors, name = "OV Level") +  
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 0.8),
    legend.position = "top",
    plot.background = element_rect(fill = "white", color = "white")
  ) +
  labs(
    title = "Effect of Fixation Advantage on Choice - ES Phase",
    x = "Fixation Advantage (Right - Left)",
    y = "P(Choose Right)"
)

# Save as SVG
ggsave("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/EE_FixationAdvantage_Plot.svg", 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")

# Show plot
print(p)


# Aggregate by sub_id: Compute mean P(choose right) per bin for each participant
agg_data <- data %>%
  group_by(sub_id, FixationAdvantage_bin, OVcate_2) %>%
  summarise(mean_p_choose_right = mean(chose_right, na.rm = TRUE), .groups = 'drop')

# Fit the LMM: Predict P(Choose Right) using Fixation Advantage and OV level
lmm_model <- lmer(
  mean_p_choose_right ~ FixationAdvantage_bin * OVcate_2 +  
    (1 | sub_id),  
  data = agg_data
)

# Print model summary
summary(lmm_model)

# Post-hoc tests
emmeans_lmm <- emmeans(lmm_model, pairwise ~ FixationAdvantage_bin | OVcate_2, adjust = "bonferroni")
emmeans_OV <- emmeans(lmm_model, pairwise ~ OVcate_2 | FixationAdvantage_bin, adjust = "bonferroni")

# Print results
print(emmeans_OV)
print(emmeans_lmm)

# Model comparison
lmm_no_OV <- lmer(
  mean_p_choose_right ~ FixationAdvantage_bin +  
    (1 | sub_id), 
  data = agg_data
)

anova(lmm_no_OV, lmm_model)  # Compare models

# Fit LMM with Continuous Fixation Advantage
lmm_continuous <- lmer(chose_right ~ FixationAdvantage * OVcate_2 + (1 | sub_id), data = data)
summary(lmm_continuous)

##################################

# Define output directory
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"

# Define file name
stats_file <- paste0(output_dir, phase_filter, "_FixationAdvantage_LMM_Results.txt")

# Save results
sink(stats_file)

cat("### Linear Mixed Model: Predicting P(Choose Right) ###\n")
print(summary(lmm_model))

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - Fixation Advantage Bins Within OV Levels ###\n")
print(emmeans_lmm)

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - OV Levels Within Each Fixation Bin ###\n")
print(emmeans_OV)

cat("\n### Model Comparison: Does OV Level Influence Fixation Effects? ###\n")
print(anova(lmm_no_OV, lmm_model))

cat("\n### Linear Mixed Model (Continuous Fixation Advantage) ###\n")
print(summary(lmm_continuous))

# Stop saving to file
sink()

# Confirm output
print(paste("Statistics saved to:", stats_file))


```


```{r}
library(ggplot2)
library(dplyr)
library(ez)
library(emmeans)
library(lmerTest)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE or ES phase and exclude certain subjects
phase_filter <- "EE"  # Change to "ES" if needed
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(FinalFixLoc, OVcate_2, chose_right, p1, p2)  # Drop NAs in relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# Convert FinalFixLoc to categorical: "Right" or "Left"
data$FinalFixLocBinary <- ifelse(data$FinalFixLoc == 2, "Right", "Left")
data$FinalFixLocBinary <- factor(data$FinalFixLocBinary, levels = c("Left", "Right"))

# Compute Value Difference (Right - Left)
data$ValueDifference <- round(data$p2 - data$p1, 1)

# Bin Value Difference into quantiles
data <- data %>%
  group_by(sub_id) %>%
  mutate(ValueDifference_bin = cut(ValueDifference, breaks = unique(quantile(ValueDifference, probs = seq(0, 1, length.out = 6), na.rm = TRUE)),
                                   labels = c("L>>R", "L>R", "L ~ R", "R>L", "R>>L"),
                                   include.lowest = TRUE)) %>%
  ungroup()


# Compute Mean & 95% CI for P(Choose Right)
summary_df <- data %>%
  group_by(ValueDifference_bin, OVcate_2, FinalFixLocBinary) %>%
  summarise(
    p_choose_right = mean(chose_right, na.rm = TRUE),
    ci = 1.96 * sd(chose_right, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Print the summary
print(summary_df)


library(dplyr)
library(ggplot2)

# Define custom colors for OV levels 
colors <- c("low" = "blue", "medium" = "deepskyblue", "high" = "navy")  

# Define line types with explicit labels
line_types <- c("Line: Left" = "solid", "Dotted: Right" = "dashed")  

# Rename factor levels in data to match legend labels
summary_df$FinalFixLocBinary <- factor(summary_df$FinalFixLocBinary, levels = c("Left", "Right")
                                       )

# Plot
p <- ggplot(summary_df, aes(x = ValueDifference_bin, y = p_choose_right, 
                            group = interaction(FinalFixLocBinary, OVcate_2), 
                            color = OVcate_2, linetype = FinalFixLocBinary)) +
  geom_point(size = 3, position = position_dodge(width = 0.2)) +  
  geom_line(position = position_dodge(width = 0.2), linewidth = 1.2) +  
  geom_errorbar(aes(ymin = p_choose_right - ci, ymax = p_choose_right + ci),
                width = 0.2, linewidth = 0.8, position = position_dodge(width = 0.2)) +  
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) +  
  scale_color_manual(values = colors, name = "OV Level") +  
  scale_linetype_manual(values = line_types, name = "Final Fixation") +  
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 0.8),
    legend.position = "top",
    legend.text = element_text(size = 12),  
    plot.background = element_rect(fill = "white", color = "white")
  ) +
  labs(
    title = paste("Final Fixation Effect on Choice -", phase_filter, "Phase"),
    x = "Value Difference (Right - Left)",
    y = "P(Choose Right)"
  )

# Save the plot
ggsave(paste0("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/", phase_filter, "_NEW_FinalFixation_ValueDiff_Plot.svg"), 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")

# Show plot
print(p)



```

```{r}
library(ggplot2)
library(dplyr)
library(ez)
library(emmeans)
library(lmerTest)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE or ES phase and exclude certain subjects
phase_filter <- "EE"  # Change to "ES" if needed
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(FinalFixLoc, OVcate_2, chose_right, p1, p2)  # Drop NAs in relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# Convert FinalFixLoc to categorical: "Right" or "Left"
data$FinalFixLocBinary <- ifelse(data$FinalFixLoc == 2, "Right", "Left")
data$FinalFixLocBinary <- factor(data$FinalFixLocBinary, levels = c("Left", "Right"))

# Compute Value Difference (Right - Left)
data$ValueDifference <- round(data$p2 - data$p1, 1)

# Bin Value Difference into quantiles
data <- data %>%
  group_by(sub_id) %>%
  mutate(ValueDifference_bin = cut(ValueDifference, 
                                   breaks = unique(quantile(ValueDifference, probs = seq(0, 1, length.out = 6), na.rm = TRUE)),
                                   labels = c("L>>R", "L>R", "L ~ R", "R>L", "R>>L"),
                                   include.lowest = TRUE)) %>%
  ungroup()

# Compute Mean & 95% CI for P(Choose Right)
summary_df <- data %>%
  group_by(ValueDifference_bin, OVcate_2, FinalFixLocBinary) %>%
  summarise(
    p_choose_right = mean(chose_right, na.rm = TRUE),
    ci = 1.96 * sd(chose_right, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Print the summary
print(summary_df)

# Define custom colors for OV levels 
colors <- c("low" = "blue", "medium" = "deepskyblue", "high" = "navy")  

# Define line types
line_types <- c("Left" = "solid", "Right" = "dashed")  

# Rename factor levels in data to match legend labels
summary_df$FinalFixLocBinary <- factor(summary_df$FinalFixLocBinary, levels = c("Left", "Right"))

# Plot
p <- ggplot(summary_df, aes(x = ValueDifference_bin, y = p_choose_right, 
                            group = interaction(FinalFixLocBinary, OVcate_2), 
                            color = OVcate_2, linetype = FinalFixLocBinary)) +  # Ensure correct line type mapping
  geom_point(size = 3, position = position_dodge(width = 0.2)) +  
  geom_line(position = position_dodge(width = 0.2), linewidth = 1.2) +  
  geom_errorbar(aes(ymin = p_choose_right - ci, ymax = p_choose_right + ci),
                width = 0.2, linewidth = 0.8, position = position_dodge(width = 0.2)) +  
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) +  
  scale_color_manual(values = colors, name = "OV Level") +  
  scale_linetype_manual(values = line_types, name = "Final Fixation") +  
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 0.8),
    legend.position = "top",
    legend.text = element_text(size = 19),  # Legend text size set to 20
    axis.text = element_text(size = 22, color = "black"),  # Axis tick labels size 20, in black
    axis.title = element_text(size = 22, color = "black"),  # X and Y axis labels size 20, in black
    plot.title = element_text(size = 22, hjust = 0.5, face="bold", color = "black"),  # Title size 20, centered, black
    plot.background = element_rect(fill = "white", color = "white")
  ) +
  labs(
    title = paste("Final Fixation Effect on Choice -", phase_filter, "Phase"),
    x = "Value Difference (Right - Left)",
    y = "P(Choose Right)"
  )

# Save the plot
ggsave(paste0("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/", phase_filter, "_NEW_FinalFixation_ValueDiff_Plot.svg"), 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")





# Show plot
print(p)

```



```{r}
library(ggplot2)
library(dplyr)
library(ez)
library(emmeans)
library(lmerTest)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE or ES phase and exclude certain subjects
phase_filter <- "ES"  # Change to "ES" if needed
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(FinalFixLoc, OVcate_2, chose_right, p1, p2)  # Drop NAs in relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# Convert FinalFixLoc to categorical: "Right" or "Left"
data$FinalFixLocBinary <- ifelse(data$FinalFixLoc == 2, "Right", "Left")
data$FinalFixLocBinary <- factor(data$FinalFixLocBinary, levels = c("Left", "Right"))

# Compute Value Difference (Right - Left)
data$ValueDifference <- round(data$p2 - data$p1, 1)

# Bin Value Difference into quantiles
data <- data %>%
  group_by(sub_id) %>%
  mutate(ValueDifference_bin = cut(ValueDifference, breaks = unique(quantile(ValueDifference, probs = seq(0, 1, length.out = 6), na.rm = TRUE)),
                                   labels = c("E>>S", "E>S", "E ~ S", "S>E", "S>>E"),
                                   include.lowest = TRUE)) %>%
  ungroup()


# Compute Mean & 95% CI for P(Choose Right)
summary_df <- data %>%
  group_by(ValueDifference_bin, OVcate_2, FinalFixLocBinary) %>%
  summarise(
    p_choose_right = mean(chose_right, na.rm = TRUE),
    ci = 1.96 * sd(chose_right, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Print the summary
print(summary_df)


library(dplyr)
library(ggplot2)

# Define custom colors for OV levels 
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")  

summary_df$FinalFixLocBinary <- factor(summary_df$FinalFixLocBinary,
                                        levels = c("Left", "Right"),
                                        labels = c("Line: Left", "Dotted: Right"))
line_types <- c("Line: Left" = "solid", "Dotted: Right" = "dashed")


# Plot
p <- ggplot(summary_df, aes(x = ValueDifference_bin, y = p_choose_right, 
                            group = interaction(FinalFixLocBinary, OVcate_2), 
                            color = OVcate_2, linetype = FinalFixLocBinary)) +
  geom_point(size = 3, position = position_dodge(width = 0.2)) +  
  geom_line(position = position_dodge(width = 0.2), linewidth = 1.2) +  
  geom_errorbar(aes(ymin = p_choose_right - ci, ymax = p_choose_right + ci),
                width = 0.2, linewidth = 0.8, position = position_dodge(width = 0.2)) +  
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) +  
  scale_color_manual(values = colors, name = "OV Level") +  
  scale_linetype_manual(values = line_types, name = "Final Fixation") +  
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black", linewidth = 0.8),  # Axis lines
    legend.position = "top",
    legend.text = element_text(size = 14),  # ✅ Legend size set to 20
    axis.text = element_text(size = 19, color = "black"),  # ✅ X & Y axis tick labels size 20, in black
    axis.title = element_text(size = 20, color = "black"),  # ✅ X & Y axis titles size 20, in black
    plot.title = element_text(size = 19, hjust = 0.5, face="bold", color = "black"),  # ✅ Title size 20, centered, black
    plot.background = element_rect(fill = "white", color = "white")  # ✅ White background
  ) +
  labs(
    title = paste("Final Fixation Effect on Choice -", phase_filter, "Phase"),
    x = "Value Difference (Symbol - Experiential)",
    y = "P(Choose Symbol)"
  )

# Save the plot
ggsave(paste0("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/", phase_filter, "_NEW_FinalFixation_ValueDiff_Plot.svg"), 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")

# Show plot
p
```



```{r}
library(lme4)
library(lmerTest)
library(dplyr)
library(emmeans)

# List to store results
results_list <- list()

# Unique bins in your data
bins <- levels(data$ValueDifference_bin)

# Loop over each ValueDifference_bin
for(bin in bins){
  # Subset the data for the current bin
  data_bin <- data %>% filter(ValueDifference_bin == bin)
  
  # 1. Test: Within this bin, does Final Fixation (Left vs. Right) affect choice?
  # Here we use a logistic regression with subject as a random effect
  model_fix <- glmer(chose_right ~ FinalFixLocBinary + (1 | sub_id), 
                     data = data_bin, family = binomial, 
                     control = glmerControl(optimizer="bobyqa"))
  
  results_list[[paste(bin, "Fixation", sep="_")]] <- summary(model_fix)
  
  # 2. For each final fixation within this bin, test for differences between OV levels
  for(fix in levels(data_bin$FinalFixLocBinary)){
    data_bin_fix <- data_bin %>% filter(FinalFixLocBinary == fix)
    
    # Check if you have enough data to run the model
    if(nrow(data_bin_fix) > 0){
      model_OV <- glmer(chose_right ~ OVcate_2 + (1 | sub_id), 
                        data = data_bin_fix, family = binomial,
                        control = glmerControl(optimizer="bobyqa"))
      
      results_list[[paste(bin, fix, "OV", sep="_")]] <- summary(model_OV)
      
      # Optional: Post-hoc pairwise comparisons using emmeans:
      emm <- emmeans(model_OV, pairwise ~ OVcate_2)
      results_list[[paste(bin, fix, "OV_pairwise", sep="_")]] <- emm$contrasts
    }
  }
}

# Print the summary results for inspection
results_list


```
```{r}
#AbsValueDiff_2

# Extended model including OVcate_2 and its interaction with FinalFixLocBinary and ValueDifference
global_model2 <- glmer(chose_right ~ FinalFixLocBinary * AbsValueDiff_2 * OVcate_2 + (1 | sub_id),
                       data = data, 
                       family = binomial, 
                       control = glmerControl(optimizer = "bobyqa"))

# View the summary of the extended model
summary(global_model2)

# Compute estimated marginal means for FinalFixLocBinary at ValueDifference = 0, separately for each OVcate_2 level
emm_global2 <- emmeans(global_model2, ~ FinalFixLocBinary | OVcate_2, 
                       at = list(AbsValueDiff_2 = 0))

# Display the pairwise comparisons for the effect of final fixation within each OVcate_2 category
pairs(emm_global2)

```

```{r}
library(lme4)
library(emmeans)
library(dplyr)

# Ensure the bin factor levels are ordered as desired
data$ValueDifference_bin <- factor(data$ValueDifference_bin, 
                                   levels = c("L>>R", "L>R", "L ~ R", "R>L", "R>>L"))

# Get the list of bins
bins <- levels(data$ValueDifference_bin)

# Loop over bins
for(bin in bins) {
  cat("\n===========================\n")
  cat("Results for bin:", bin, "\n")
  # Subset data to the current bin
  bin_data <- subset(data, ValueDifference_bin == bin)
  
  ### 1. Test for fixation effect (Right vs. Left) ###
  # Use a generalized linear mixed model (logistic regression) with subject as random intercept
  model_fix <- glmer(chose_right ~ FinalFixLocBinary + (1 | sub_id),
                     data = bin_data, family = binomial)
  cat("\n--- Final Fixation Effect ---\n")
  print(summary(model_fix))
  
  # Use emmeans for pairwise comparisons (contrast between Right and Left)
  emm_fix <- emmeans(model_fix, ~ FinalFixLocBinary)
  print(pairs(emm_fix))
  
  ### 2. Test for overall value effect (OVcate_2) within the bin ###
  # Here we include an interaction so that you can see both the main effect of OVcate_2 
  # and whether it interacts with FinalFixLocBinary.
  model_ov <- glmer(chose_right ~ FinalFixLocBinary * OVcate_2 + (1 | sub_id),
                    data = bin_data, family = binomial)
  cat("\n--- Overall Value (OVcate_2) Effect and Interaction ---\n")
  print(summary(model_ov))
  
  # Post hoc pairwise comparisons for OVcate_2 (averaged over fixation conditions)
  emm_ov <- emmeans(model_ov, ~ OVcate_2)
  print(pairs(emm_ov))
}


```

`



```{r}
library(lmerTest)
library(emmeans)
library(dplyr)
```{r}
```


```{r}
```


```{r}

# Aggregate data: Compute mean P(Choose Right) per Final Fixation per OV level per Value Difference per participant
agg_data <- data %>%
  group_by(sub_id, ValueDifference_bin, FinalFixLocBinary, OVcate_2) %>%
  summarise(mean_p_choose_right = mean(chose_right, na.rm = TRUE), .groups = 'drop')


# Fit the LMM with only the necessary interaction effects
lmm_model <- lmer(mean_p_choose_right ~ ValueDifference_bin * FinalFixLocBinary + 
                  (1 | sub_id),  # Random intercept for participants
                  data = agg_data, REML = FALSE)

# Print model summary
summary(lmm_model)

# Fit LMM including OVcate_2
lmm_model_OV <- lmer(mean_p_choose_right ~ ValueDifference_bin * FinalFixLocBinary * OVcate_2 + 
                     (1 | sub_id),  # Random intercept for participants
                     data = agg_data, REML = FALSE)

# Print model summary
summary(lmm_model_OV)

# Test if OV Levels differ in their influence on fixation effects
anova(lmm_model, lmm_model_OV)  # Compare models with and without OV levels
```


```{r}
library(lmerTest)
library(emmeans)
library(dplyr)

# Filter for the L~R bin (assuming it's the third bin)
agg_data_LR <- data %>%
  filter(ValueDifference_bin == "L ~ R") %>%  # Adjust if the bin name is different
  group_by(sub_id, FinalFixLocBinary, OVcate_2) %>%
  summarise(mean_p_choose_right = mean(chose_right, na.rm = TRUE), .groups = 'drop')

# Fit the LMM testing only Final Fixation effect
lmm_LR <- lmer(mean_p_choose_right ~ FinalFixLocBinary + 
               (1 | sub_id),  # Random intercept for participants
               data = agg_data_LR, REML = FALSE)

# Print model summary
summary(lmm_LR)

# Fit the LMM testing Final Fixation * OV interaction
lmm_LR_OV <- lmer(mean_p_choose_right ~ FinalFixLocBinary * OVcate_2 + 
                  (1 | sub_id),  # Random intercept for participants
                  data = agg_data_LR, REML = FALSE)

# Print model summary
summary(lmm_LR_OV)

# Test if OV Levels differ in their influence on fixation effects
anova(lmm_LR, lmm_LR_OV)  # Compare models with and without OV levels

# Post-hoc tests: Pairwise comparisons of fixation effects within OV levels
emmeans_lmm <- emmeans(lmm_LR_OV, pairwise ~ FinalFixLocBinary | OVcate_2, adjust = "bonferroni")

# Print post-hoc results
print(emmeans_lmm)





#####
# Define the directory where the SVG is saved
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"

# Save the plot
plot_file <- paste0(output_dir, phase_filter, "_FirstFixation_ValueDiff_Plot.svg")
ggsave(plot_file, plot = p, width = 8, height = 6, device = "svg", bg = "white")

# Define the path for the statistics file
stats_file <- paste0(output_dir, phase_filter, "_FirstFixation_ValueDiff_Stats.txt")

# Capture statistical outputs and save to text file
sink(stats_file)

cat("### LMM Model (Without OV levels) ###\n")
print(summary(lmm_model))

cat("\n### LMM Model (With OV levels) ###\n")
print(summary(lmm_model_OV))

cat("\n### Model Comparison: Does OV Influence Fixation Effects? ###\n")
print(anova(lmm_model, lmm_model_OV))

cat("\n### LMM for L ~ R Bin: Fixation Effect ###\n")
print(summary(lmm_LR))

cat("\n### LMM for L ~ R Bin: Fixation * OV Interaction ###\n")
print(summary(lmm_LR_OV))

cat("\n### Model Comparison for L ~ R Bin: OV Effects on Fixation ###\n")
print(anova(lmm_LR, lmm_LR_OV))

cat("\n### Post-hoc Pairwise Comparisons (Bonferroni Adjusted) ###\n")
print(emmeans_lmm)

sink()  # Close the connection to the file

# Confirm output
print(paste("Statistics saved to:", stats_file))
print(paste("Plot saved to:", plot_file))

```
```{r}

library(dplyr)
library(ggplot2)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE or ES phase and exclude certain subjects
phase_filter <- "ES"  # Change to "ES" if needed
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(FirstFixLoc, OVcate_2, corr, p1, p2, BetterOption)  # Drop NAs in relevant columns

# Ensure OVcate_2 is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# Compute Value Difference (Right - Left)
data$ValueDifference <- round(data$p2 - data$p1, 1)

# Bin Value Difference into quantiles
data <- data %>%
  group_by(sub_id) %>%
  mutate(ValueDifference_bin = cut(ValueDifference, 
                                   breaks = unique(quantile(ValueDifference, probs = seq(0, 1, length.out = 6), na.rm = TRUE)),
                                   labels = c("L>>R", "L>R", "L ~ R", "R>L", "R>>L"),
                                   include.lowest = TRUE)) %>%
  ungroup()

# ✅ Create column for First Fixation correctness
data$FirstFix_Correct <- ifelse(data$FirstFixLoc == data$BetterOption, "Dotted: Correct", "Line: Incorrect")

# Compute Mean & 95% CI for P(Correct)
summary_df <- data %>%
  group_by(ValueDifference_bin, OVcate_2, FirstFix_Correct) %>%
  summarise(
    p_correct = mean(corr, na.rm = TRUE),  # Probability of choosing the correct option
    ci = 1.96 * sd(corr, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Print the summary
print(summary_df)

# Define custom colors for OV levels 
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")  

# Define line types with explicit labels
line_types <- c("Line: Incorrect" = "solid", "Dotted: Correct" = "dashed")  

# Convert factor levels in data to match legend labels
summary_df$FirstFix_Correct <- factor(summary_df$FirstFix_Correct, levels = c("Line: Incorrect", "Dotted: Correct"))

# Plot
p <- ggplot(summary_df, aes(x = ValueDifference_bin, y = p_correct, 
                            group = interaction(FirstFix_Correct, OVcate_2), 
                            color = OVcate_2, linetype = FirstFix_Correct)) +
  geom_point(size = 3, position = position_dodge(width = 0.2)) +  
  geom_line(position = position_dodge(width = 0.2), linewidth = 1.2) +  
  geom_errorbar(aes(ymin = p_correct - ci, ymax = p_correct + ci),
                width = 0.2, linewidth = 0.8, position = position_dodge(width = 0.2)) +  
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) +  
  scale_color_manual(values = colors, name = "OV Level") +  
  scale_linetype_manual(values = line_types, name = "First Fixation") +  
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 0.8),
    legend.position = "top",
    legend.text = element_text(size = 12),  
    plot.background = element_rect(fill = "white", color = "white")
  ) +
  labs(
    title = paste("First Fixation to Correct vs Incorrect Option -", phase_filter, "Phase"),
    x = "Value Difference (Right - Left)",
    y = "P(Correct)"  # Updated y-axis label
  )

# Save the plot
ggsave(paste0("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/", phase_filter, "_FirstFixation_Correctness_Plot.svg"), 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")

# Show plot
print(p)

library(lme4)
library(lmerTest)
library(emmeans)
library(dplyr)

# ✅ Aggregate by subject: Compute mean P(correct) per bin, OV level & fixation correctness
agg_data <- data %>%
  group_by(sub_id, ValueDifference_bin, OVcate_2, FirstFix_Correct) %>%
  summarise(mean_p_correct = mean(corr, na.rm = TRUE), .groups = 'drop')

# Fit the LMM: Predict P(Correct) using Value Difference Bin, OV Level & Fixation Correctness
lmm_model <- lmer(
  mean_p_correct ~ ValueDifference_bin * OVcate_2 * FirstFix_Correct + (1 | sub_id),  
  data = agg_data
)

# Print model summary
summary(lmm_model)

# ✅ Pairwise comparisons for OV levels within each Value Difference bin
emmeans_OV <- emmeans(lmm_model, pairwise ~ OVcate_2 | ValueDifference_bin, adjust = "bonferroni")

# ✅ Pairwise comparisons for Fixation Correctness within each Value Difference bin
emmeans_fixation <- emmeans(lmm_model, pairwise ~ FirstFix_Correct | ValueDifference_bin, adjust = "bonferroni")

# ✅ Interaction comparisons: Does OV influence Fixation Correctness effect?
emmeans_interaction <- emmeans(lmm_model, pairwise ~ OVcate_2 * FirstFix_Correct | ValueDifference_bin, adjust = "bonferroni")

# Print results
print(emmeans_OV)
print(emmeans_fixation)
print(emmeans_interaction)

# Fit a null model without OV level & Fixation Correctness for comparison
lmm_no_OV_fix <- lmer(
  mean_p_correct ~ ValueDifference_bin + (1 | sub_id),  
  data = agg_data
)

# Compare models: Does OV Level & Fixation Correctness significantly predict P(Correct)?
anova(lmm_no_OV_fix, lmm_model)  


# Define output directory
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"

# Define file name
stats_file <- paste0(output_dir, phase_filter, "_LMM_OV_First_Fixation_Correctness_Results.txt")

# Save results
sink(stats_file)

cat("### Linear Mixed Model: Predicting P(Correct) Across All Bins ###\n")
print(summary(lmm_model))

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - OV Levels Within Each Bin ###\n")
print(emmeans_OV)

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - Fixation Correctness Within Each Bin ###\n")
print(emmeans_fixation)

cat("\n### Interaction Effect: OV Levels x Fixation Correctness Within Each Bin ###\n")
print(emmeans_interaction)

cat("\n### Model Comparison: Do OV & Fixation Correctness Improve Model Fit? ###\n")
print(anova(lmm_no_OV_fix, lmm_model))

# Stop saving to file
sink()

# Confirm output
print(paste("Statistics saved to:", stats_file))


```



```{r}
library(dplyr)
library(ggplot2)

# Load dataset
file_path <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/data/data_sets/GarciaParticipants_Eye_Response_Feed_Allfix_addm_OV_Abs.csv"
data <- read.csv(file_path)

# Filter for EE or ES phase and exclude certain subjects
phase_filter <- "ES"  # Change to "ES" if needed
excluded_subjects <- c(1, 4, 5, 6, 14, 99)

data <- data %>%
  filter(phase == phase_filter & !sub_id %in% excluded_subjects) %>%
  drop_na(FinalFixLoc, OVcate_2, corr, p1, p2, BetterOption)  # Drop NAs in relevant columns

# Ensure `OVcate_2` is a factor with correct levels
data$OVcate_2 <- factor(data$OVcate_2, levels = c("low", "medium", "high"))

# Compute Value Difference (Right - Left)
data$ValueDifference <- round(data$p2 - data$p1, 1)

# Bin Value Difference into quantiles
data <- data %>%
  group_by(sub_id) %>%
  mutate(ValueDifference_bin = cut(ValueDifference, 
                                   breaks = unique(quantile(ValueDifference, probs = seq(0, 1, length.out = 6), na.rm = TRUE)),
                                   labels = c("L>>R", "L>R", "L ~ R", "R>L", "R>>L"),
                                   include.lowest = TRUE)) %>%
  ungroup()

# ✅ Create column for Final Fixation correctness
data$FinalFix_Correct <- ifelse(data$FinalFixLoc == data$BetterOption, "Dotted: Correct", "Line: Incorrect")

# Compute Mean & 95% CI for P(Correct)
summary_df <- data %>%
  group_by(ValueDifference_bin, OVcate_2, FinalFix_Correct) %>%
  summarise(
    p_correct = mean(corr, na.rm = TRUE),  # Probability of choosing the correct option
    ci = 1.96 * sd(corr, na.rm = TRUE) / sqrt(n()),  # 95% Confidence Interval
    .groups = 'drop'
  )

# Print the summary
print(summary_df)

# Define custom colors for OV levels 
colors <- c("low" = "darkorchid1", "medium" = "darkorchid3", "high" = "darkmagenta")  

# Define line types with explicit labels
line_types <- c("Line: Incorrect" = "solid", "Dotted: Correct" = "dashed")  

# Convert factor levels in data to match legend labels
summary_df$FinalFix_Correct <- factor(summary_df$FinalFix_Correct, levels = c("Line: Incorrect", "Dotted: Correct"))

# Plot
p <- ggplot(summary_df, aes(x = ValueDifference_bin, y = p_correct, 
                            group = interaction(FinalFix_Correct, OVcate_2), 
                            color = OVcate_2, linetype = FinalFix_Correct)) +
  geom_point(size = 3, position = position_dodge(width = 0.2)) +  
  geom_line(position = position_dodge(width = 0.2), linewidth = 1.2) +  
  geom_errorbar(aes(ymin = p_correct - ci, ymax = p_correct + ci),
                width = 0.2, linewidth = 0.8, position = position_dodge(width = 0.2)) +  
  geom_hline(yintercept = 0.5, linetype = "dotted", color = "gray50", linewidth = 1) +  
  scale_color_manual(values = colors, name = "OV Level") +  
  scale_linetype_manual(values = line_types, name = "Final Fixation") +  
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black", linewidth = 0.8),
    legend.position = "top",
    legend.text = element_text(size = 12),  
    plot.background = element_rect(fill = "white", color = "white")
  ) +
  labs(
    title = paste("Final Fixation to Correct vs Incorrect Option -", phase_filter, "Phase"),
    x = "Value Difference (Right - Left)",
    y = "P(Correct)"  # Updated y-axis label
  )

# Save the plot
ggsave(paste0("D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/", phase_filter, "_FinalFixation_Correctness_Plot.svg"), 
       plot = p, width = 8, height = 6, device = "svg", bg = "white")

# Show plot
print(p)

```


```{r}
library(lme4)
library(lmerTest)
library(emmeans)
library(dplyr)

# ✅ Aggregate by subject: Compute mean P(correct) per bin, OV level & fixation correctness
agg_data <- data %>%
  group_by(sub_id, ValueDifference_bin, OVcate_2, FinalFix_Correct) %>%
  summarise(mean_p_correct = mean(corr, na.rm = TRUE), .groups = 'drop')

# Fit the LMM: Predict P(Correct) using Value Difference Bin, OV Level & Fixation Correctness
lmm_model <- lmer(
  mean_p_correct ~ ValueDifference_bin * OVcate_2 * FinalFix_Correct + (1 | sub_id),  
  data = agg_data
)

# Print model summary
summary(lmm_model)

# ✅ Pairwise comparisons for OV levels within each Value Difference bin
emmeans_OV <- emmeans(lmm_model, pairwise ~ OVcate_2 | ValueDifference_bin, adjust = "bonferroni")

# ✅ Pairwise comparisons for Fixation Correctness within each Value Difference bin
emmeans_fixation <- emmeans(lmm_model, pairwise ~ FinalFix_Correct | ValueDifference_bin, adjust = "bonferroni")

# ✅ Interaction comparisons: Does OV influence Fixation Correctness effect?
emmeans_interaction <- emmeans(lmm_model, pairwise ~ OVcate_2 * FinalFix_Correct | ValueDifference_bin, adjust = "bonferroni")

# Print results
print(emmeans_OV)
print(emmeans_fixation)
print(emmeans_interaction)

# Fit a null model without OV level & Fixation Correctness for comparison
lmm_no_OV_fix <- lmer(
  mean_p_correct ~ ValueDifference_bin + (1 | sub_id),  
  data = agg_data
)

# Compare models: Does OV Level & Fixation Correctness significantly predict P(Correct)?
anova(lmm_no_OV_fix, lmm_model)  


# Define output directory
output_dir <- "D:/Aberdeen_Uni_June24/cap/THESIS/Garcia_Analysis/stats_TingGluth/R_regression_OV_Abs/"

# Define file name
stats_file <- paste0(output_dir, phase_filter, "_LMM_OV_Final_Fixation_Correctness_Results.txt")

# Save results
sink(stats_file)

cat("### Linear Mixed Model: Predicting P(Correct) Across All Bins ###\n")
print(summary(lmm_model))

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - OV Levels Within Each Bin ###\n")
print(emmeans_OV)

cat("\n### Pairwise Comparisons (Bonferroni-adjusted) - Fixation Correctness Within Each Bin ###\n")
print(emmeans_fixation)

cat("\n### Interaction Effect: OV Levels x Fixation Correctness Within Each Bin ###\n")
print(emmeans_interaction)

cat("\n### Model Comparison: Do OV & Fixation Correctness Improve Model Fit? ###\n")
print(anova(lmm_no_OV_fix, lmm_model))

# Stop saving to file
sink()

# Confirm output
print(paste("Statistics saved to:", stats_file))

```

